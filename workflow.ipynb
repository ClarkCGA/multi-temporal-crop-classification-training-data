{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e493cc-09bc-4d70-8316-c8aa4021de9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rioxarray \n",
    "import xarray\n",
    "import rasterio\n",
    "import nasa_hls\n",
    "import os\n",
    "import geopandas\n",
    "import urllib.request as urlreq\n",
    "import pandas as pd\n",
    "import fiona\n",
    "import numpy as np\n",
    "import json\n",
    "import shutil\n",
    "import datetime\n",
    "from glob import glob\n",
    "from rasterio.enums import Resampling\n",
    "from rasterio import Affine\n",
    "from rasterio.crs import CRS\n",
    "import matplotlib.pyplot as plt\n",
    "from subprocess import Popen, PIPE\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17b27be-7dfe-43b1-a775-efe885235127",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### START OPTIONS #####\n",
    "yoi = [2021]\n",
    "#toi = ['15STT']\n",
    "cloud_thres = 5\n",
    "valid_months = [3,4,5,6,7,8,9]\n",
    "root_path = \"/data/\"\n",
    "\n",
    "## file paths\n",
    "spath = root_path + f\"CDL_HLS_dataframe{yoi[0]}\"\n",
    "image_index_file = root_path + f\"image_index{yoi[0]}\"\n",
    "chip_file =  root_path + \"chip_bbox.geojson\"\n",
    "chip_csv = root_path + \"chip_tracker.csv\"\n",
    "kml_file = root_path + 'sentinel_tile_grid.kml'\n",
    "cdl_reclass_csv = root_path + \"cdl_freq.csv\"\n",
    "tile_tracker_csv = root_path + \"tile_tracker.csv\"\n",
    "\n",
    "## folder paths\n",
    "hdf_dir = root_path + \"hdf/\"\n",
    "chip_dir = root_path + 'chips/'\n",
    "tif_dir = root_path + 'tif/'\n",
    "chip_dir_binary = root_path + 'chips_binary/'\n",
    "chip_dir_multi = root_path + 'chips_multi/'\n",
    "\n",
    "chip_dir_filt = root_path + 'chips_filtered/'\n",
    "chip_dir_binary_filt = root_path + 'chips_binary_filtered/'\n",
    "chip_dir_multi_filt = root_path + 'chips_multi_filtered/'\n",
    "\n",
    "chip_qa_dir = root_path + 'chips_qa/'\n",
    "\n",
    "#####  END OPTIONS  #####"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61d21b7-d5a1-468f-ae9b-36a6aaa7f0f1",
   "metadata": {},
   "source": [
    "make folders if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4eee91-56f0-43f7-98a9-75a9c10aaf1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs_to_make = [hdf_dir, chip_dir, chip_dir_binary, chip_qa_dir, chip_dir_binary, chip_dir_multi, chip_dir_binary_filt, chip_dir_filt, chip_dir_multi_filt]\n",
    "for folder in dirs_to_make:\n",
    "    try:\n",
    "        os.makedirs(folder)\n",
    "    except FileExistsError:\n",
    "        # directory already exists\n",
    "        print('pass')\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38a44b2-43b7-40f6-b03d-67a5a8a3035b",
   "metadata": {},
   "source": [
    "0 determine HLS tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9b6751-52c3-4fe8-b38e-1721dd7db78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/cdl_training_data/data/chip_bbox.geojson\", \"r\") as file:\n",
    "    chips = json.load(file)\n",
    "    \n",
    "chip_ids = []\n",
    "chip_x = []\n",
    "chip_y = []\n",
    "for item in chips['features']:\n",
    "    #print(item)\n",
    "    chip_ids.append(item['properties']['id'])\n",
    "    chip_x.append(item['properties']['center'][0])\n",
    "    chip_y.append(item['properties']['center'][1])\n",
    "\n",
    "\n",
    "#chip_ids = a.fea\n",
    "#print(a['features'][0]['properties']['center'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca25ef44-9574-43e0-84bb-8349699bfb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the HLS tiles and place there coordinates into a numpy array for processing later\n",
    "\n",
    "fiona.drvsupport.supported_drivers['KML'] = 'rw'\n",
    "tile_src = geopandas.read_file(kml_file, driver='KML')\n",
    "tile_name = []\n",
    "tile_x = []\n",
    "tile_y = []\n",
    "for tile_ind in range(tile_src.shape[0]):\n",
    "    tile_name.append(tile_src.iloc[tile_ind].Name)\n",
    "    tile_x.append(tile_src.iloc[tile_ind].geometry.centroid.x)\n",
    "    tile_y.append(tile_src.iloc[tile_ind].geometry.centroid.y)\n",
    "tile_name = np.array(tile_name)\n",
    "tile_x = np.array(tile_x)\n",
    "tile_y = np.array(tile_y)\n",
    "tile_src = pd.concat([tile_src, tile_src.bounds], axis = 1)\n",
    "#del tile_src\n",
    "tile_src.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec16f55-ba54-49a9-816e-bb7dfc740b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_tile(x,y):\n",
    "# Identify closest tile\n",
    "    s = (tile_x - x)**2+(tile_y - y)**2\n",
    "    tname = tile_name[np.argmin(s)]\n",
    "    return(tname)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f78d885-c7ce-41e7-94c7-374d51cb4003",
   "metadata": {},
   "source": [
    "initialize chip tracker csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1cbe8e0-e2b7-4cc0-b970-2bb85eb41948",
   "metadata": {},
   "outputs": [],
   "source": [
    "chip_df = pd.DataFrame({\"chip_id\" : chip_ids, \"chip_x\" : chip_x, \"chip_y\" : chip_y})\n",
    "chip_df['tile'] = chip_df.apply(lambda row : find_tile(row['chip_x'], row['chip_y']), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416d62fa-c766-417f-ac34-aac72600b20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## write to csv\n",
    "check_file = glob(chip_csv)\n",
    "if len(check_file) == 0:\n",
    "    chip_df.to_csv(chip_csv, index=False)\n",
    "else:\n",
    "    print('file exists')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c938ca81-9f17-494e-97c7-4d55bd66a7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tiles = chip_df.tile.unique().tolist()\n",
    "tiles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e306e5-a77b-4d54-b970-20f1985f07a8",
   "metadata": {},
   "source": [
    "0a. manually chack and remove \"bad\" tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d437a0bd-bdd3-4fae-ad06-01a11279bb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "chip_df[chip_df.tile == '01SBU'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5081f11f-f7fd-476c-8d40-5eb1ccd1bed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tiles.remove('01SBU')\n",
    "tiles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ecb92b-8468-478f-b7a4-5ca4cf347cc8",
   "metadata": {},
   "source": [
    "0b. Make tile tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78409c49-71c7-40cb-b091-6760c0da04d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_tracker = pd.DataFrame({\"tile\":tiles})\n",
    "tile_tracker['exclude'] = False\n",
    "tile_tracker['hdf_download'] = False\n",
    "tile_tracker['tif_convert'] = False\n",
    "tile_tracker['tif_reproject'] = False\n",
    "tile_tracker['chip'] = False\n",
    "tile_tracker['filter_chips'] = False\n",
    "#tile_tracker.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9350fd8-40a2-4e71-b18d-9cc746212575",
   "metadata": {},
   "outputs": [],
   "source": [
    "## update tracker\n",
    "tiles_already_downloaded = glob(hdf_dir + '*')\n",
    "tiles_already_downloaded = set([i[19:24] for i in tiles_already_downloaded])\n",
    "tiles_already_downloaded\n",
    "tile_tracker.loc[tile_tracker.tile.isin(tiles_already_downloaded) , 'hdf_download'] = True\n",
    "\n",
    "tiles_already_converted = glob(tif_dir + '*')\n",
    "tiles_already_converted = set([i[19:24] for i in tiles_already_converted])\n",
    "tiles_already_converted\n",
    "tile_tracker.loc[tile_tracker.tile.isin(tiles_already_converted) , 'tif_convert'] = True\n",
    "\n",
    "chips_already_chipped = glob(chip_dir + '*')\n",
    "chips_already_chipped = set([i[17:24] for i in chips_already_chipped])\n",
    "#print(chips_already_chipped)\n",
    "tiles_already_chipped = chip_df[chip_df.chip_id.isin(chips_already_chipped)].tile.unique()\n",
    "#print(tiles_already_chipped)\n",
    "tile_tracker.loc[tile_tracker.tile.isin(tiles_already_chipped) , 'tif_reproject'] = True\n",
    "tile_tracker.loc[tile_tracker.tile.isin(tiles_already_chipped) , 'chip'] = True\n",
    "                                        \n",
    "chips_already_filtered = glob(chip_dir_filt + '*')\n",
    "chips_already_filtered = set([i[26:33] for i in chips_already_filtered])\n",
    "tiles_already_filtered = chip_df[chip_df.chip_id.isin(chips_already_filtered)].tile.unique()\n",
    "tile_tracker.loc[tile_tracker.tile.isin(tiles_already_filtered), 'filter_chips'] = True\n",
    "\n",
    "tile_tracker.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fad3d6c-74a0-499a-8f37-a99b1cce8480",
   "metadata": {},
   "outputs": [],
   "source": [
    "## write to csv\n",
    "check_file = glob(tile_tracker_csv)\n",
    "if len(check_file) == 0:\n",
    "    tile_tracker.to_csv(tile_tracker_csv, index=False)\n",
    "else:\n",
    "    print('file exists')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad736731-d5a5-4f32-b2fb-8580427c76f3",
   "metadata": {},
   "source": [
    "1. query and download hdf files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4fff5c-4768-4dbc-9ea8-590869e7aa53",
   "metadata": {},
   "outputs": [],
   "source": [
    "toi = tile_tracker[(tile_tracker.exclude == False) & (tile_tracker.hdf_download == False)].tile.unique()\n",
    "toi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38cea45c-e07f-4813-91f6-47401f1d2277",
   "metadata": {},
   "source": [
    "1a. get URLs of hdf to download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8c67cc-5e3f-4c79-9b97-5d32b9cbab41",
   "metadata": {},
   "outputs": [],
   "source": [
    "HLSdf = nasa_hls.get_available_datasets(\n",
    "        years = yoi,\n",
    "        products = [\"S30\"],\n",
    "        tiles = toi,\n",
    "        return_list = False)\n",
    "\n",
    "#HLSdf.to_csv(spath, mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede76c7d-78ef-4c89-ae9b-6853fe45e209",
   "metadata": {},
   "outputs": [],
   "source": [
    "HLSdf['month'] = pd.DatetimeIndex(HLSdf['date']).month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8fc7289-52ae-474c-b8d5-e1efc13b0965",
   "metadata": {},
   "outputs": [],
   "source": [
    "## filter by month\n",
    "HLSdf = HLSdf[HLSdf.month.isin(valid_months)].reset_index(drop = True)\n",
    "HLSdf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c21e9b4-5602-46af-85bd-da878fb8cf32",
   "metadata": {},
   "outputs": [],
   "source": [
    "## download hdf\n",
    "for k in range(len(HLSdf)):\n",
    "    url = HLSdf.at[k, \"url\"]\n",
    "    local_name = url.split('/')[-1].replace(\"\\n\", \"\").replace('.hdf', '')\n",
    "    HLSdf.at[k, \"image_id\"] = local_name\n",
    "    try:\n",
    "        urlreq.urlretrieve(url, filename = hdf_dir+local_name + '.hdf')\n",
    "    except:\n",
    "        print(local_name + \" failed\")\n",
    "        continue\n",
    "\n",
    "tile_tracker = pd.read_csv(tile_tracker_csv)\n",
    "tile_tracker.loc[tile_tracker.tile.isin(toi) , 'hdf_download'] = True\n",
    "tile_tracker.to_csv(tile_tracker_csv, index=False)\n",
    "#ct = datetime.datetime.now()\n",
    "#HLSdf.to_csv(spath + \"_\" + str(ct) + \".csv\", mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266c403d-4845-487e-bddb-de50eab83548",
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_tracker.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b07887-edf0-4076-bd16-a8173cc098ca",
   "metadata": {},
   "source": [
    "2. extract hdf metadata, filter to 3 scenes per tile, convert to tif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0afa7935-6c59-437b-b7db-a126599ac27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metadata_from_hdf_mine(src, fields=[\"cloud_cover\", \"spatial_coverage\"]):\n",
    "    \"\"\"Get metadata from a nasa-hls hdf file. See HLS user guide for valid fields.\n",
    "    \n",
    "    HLS User Guide - see Section 6.6: \n",
    "    \n",
    "    https://hls.gsfc.nasa.gov/wp-content/uploads/2019/01/HLS.v1.4.UserGuide_draft_ver3.1.pdf\n",
    "    \"\"\"\n",
    "    band=\"QA\"\n",
    "    cmd = f'gdalinfo HDF4_EOS:EOS_GRID:\"{src}\":Grid:{band}'\n",
    "#    print(cmd)\n",
    "    p = Popen(cmd, stdout=PIPE, shell=True)\n",
    "    output, err = p.communicate()\n",
    "    output = str(output)[2:-1].replace(\"\\\\n\", \"\\n\")\n",
    "    rc = p.returncode\n",
    "    metadata = {}\n",
    "    for line in output.split(\"\\n\"):\n",
    "        for field in fields:\n",
    "            if field in line:\n",
    "                metadata[field] = line.split(\"=\")[1].strip()\n",
    "                try:\n",
    "                    metadata[field] = float(metadata[field])\n",
    "                except:\n",
    "                    pass\n",
    "    for field in fields:\n",
    "        if field not in metadata.keys():\n",
    "            warnings.warn(f\"Could not find metadata for field '{field}'.\")\n",
    "    return metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35173684-e5bc-42cf-8ba9-47623fa093c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_index = pd.DataFrame(columns = ['image_id', 'tile', 'date', 'month', 'cloud_coverage', 'spatial_coverage'])\n",
    "\n",
    "candidate_hdf = sorted(glob(hdf_dir + '*.hdf'))\n",
    "\n",
    "for img in candidate_hdf:\n",
    "   # print(img)\n",
    "    local_name = img.split('/')[-1]\n",
    "    try:\n",
    "      #  print(hdf_dir+local_name)\n",
    "        md = get_metadata_from_hdf_mine(hdf_dir+local_name)\n",
    "    except:\n",
    "        print(img + ' skipped')\n",
    "        continue\n",
    "   # print(md)\n",
    "    cloud_cover = int(md['cloud_cover'])\n",
    "    spatial_coverage = int(md['spatial_coverage'])\n",
    "    image_id = local_name.replace('.hdf', '')\n",
    "    tname = local_name.split('.')[2][1:]\n",
    "    date = local_name.split('.')[3]\n",
    "    image_date_string = image_id.split('.')[3]\n",
    "    image_date = pd.to_datetime(image_date_string, format=\"%Y%j\").date()\n",
    "    image_month = image_date.month\n",
    "    \n",
    "    new_row = pd.DataFrame({'image_id':  [image_id],\n",
    "               'tile': [tname],\n",
    "               'date': [image_date],\n",
    "               'month': [image_month],\n",
    "               'cloud_coverage': [cloud_cover],\n",
    "               'spatial_coverage': [spatial_coverage]})\n",
    "    image_index = pd.concat([image_index, new_row], ignore_index = True)\n",
    "\n",
    "ct = datetime.datetime.now()\n",
    "image_index.to_csv(image_index_file + \"_\" + str(ct) + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6899c71-6d74-4c41-8901-b31eff2990fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#image_index.sort_values(['cloud_coverage']).head(300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47e0aad-c5d4-4c91-865b-de028ecd1d20",
   "metadata": {},
   "source": [
    "Select 3 best images (need to loop this over tiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4a40f7-fedc-4dda-b90e-af5ffbd88ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_tracker = pd.read_csv(tile_tracker_csv)\n",
    "#tiles_already_converted = set([i[19:24] for i in tiles_already_converted])\n",
    "tiles_to_process = tile_tracker[(tile_tracker.exclude == False) & (tile_tracker.tif_convert == False) & (tile_tracker.hdf_download == True)].tile.unique()\n",
    "tiles_to_process\n",
    "#tile_tracker.to_csv(tile_tracker_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381de00f-9871-4fb9-a61b-712ea5a81c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_hdf_to_cog(scene_id, product = \"S30\"):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function receives the scene_id of an HLS scene (in a format similar to \"HLS.S30.T14RNS.2020005.v1.4\"\n",
    "    and converts the scene from HDF format to COG. \n",
    "    \n",
    "    Assumptions:\n",
    "    - The corresponding HDF file for the scene is located at `/data/hdf/scene_id.hdf`\n",
    "    - The output will be written to `/data/tif/scene_id/*.tif` and contains all the bands. \n",
    "    \n",
    "    Inputs:\n",
    "    - scene_id: The scene ID of the HLS scene\n",
    "    - product: the HLS product ID. Default is S30, but it can be S30, L30, S30_ANGLES, L30_ANGLES\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    import os\n",
    "    cmd = f\"python3 /hls-hdf_to_cog/hls_hdf_to_cog/hls_hdf_to_cog.py --product {product} /data/hdf/{scene_id}.hdf --output-dir /data/tif/{scene_id}/\"\n",
    "    os.system(cmd)\n",
    "    image_folder = '/data/tif/' + scene_id + '/'\n",
    "    tif_count = len(glob(image_folder + '*.tif'))\n",
    "    if(tif_count == 14):\n",
    "        return(True)\n",
    "    else:\n",
    "        shutil.rmtree(image_folder)\n",
    "        return(False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d66cb1-f0b3-4cfb-bb73-1aa2f46ea386",
   "metadata": {},
   "source": [
    "convert selected hdf to cog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b812826-7328-4a05-a005-8e3f6e2f6215",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_first_date(cand_images):\n",
    "    \"\"\"\n",
    "    Converts first date image from data frame. \n",
    "    If conversion fails, the image is removed and the next \"first\" image is tried.\n",
    "    Returns the converted image row, the image id, and the data frame with any failed images removed.\n",
    "    \"\"\"\n",
    "    process_first = False\n",
    "    while process_first == False:\n",
    "        first_image = cand_images.head(1)\n",
    "        first_image_id = (first_image.image_id.tolist())[0]\n",
    "        print(first_image_id)\n",
    "        process_first = convert_hdf_to_cog(first_image_id)\n",
    "        print(process_first)\n",
    "        if(process_first == False):\n",
    "            cand_images = cand_images[cand_images.image_id != first_image_id]\n",
    "    return(first_image, first_image_id, cand_images)\n",
    "\n",
    "def convert_last_date(cand_images):\n",
    "    \"\"\"\n",
    "    Converts last date image from data frame. \n",
    "    If conversion fails, the image is removed and the next \"last\" image is tried.\n",
    "    Returns the converted image row, the image id, and the data frame with any failed images removed.\n",
    "    \"\"\"\n",
    "    process_last = False\n",
    "    while process_last == False:\n",
    "        last_image = cand_images.tail(1)\n",
    "        last_image_id = (last_image.image_id.tolist())[0]\n",
    "        print(last_image_id)\n",
    "        process_last = convert_hdf_to_cog(last_image_id)\n",
    "        print(process_last)\n",
    "        if(process_last == False):\n",
    "            cand_images = cand_images[cand_images.image_id != last_image_id]\n",
    "    return(last_image, last_image_id, cand_images)\n",
    "\n",
    "def convert_middle_date(cand_images):\n",
    "    \"\"\"\n",
    "    Converts middle date image from data frame. \n",
    "    If conversion fails, the image is removed and the next \"middle\" image is tried.\n",
    "    Returns the converted image row, the image id, and the data frame with any failed images removed.\n",
    "    \"\"\"\n",
    "    process_middle = False\n",
    "    cand_image_count = len(cand_images)\n",
    "    while process_middle == False:\n",
    "        middle_image = cand_images.head((cand_image_count // 2)+1).tail(1)\n",
    "        middle_image_id = (middle_image.image_id.tolist())[0]\n",
    "        print(middle_image_id)\n",
    "        process_middle = convert_hdf_to_cog(middle_image_id)\n",
    "        print(process_middle)\n",
    "        if(process_middle == False):\n",
    "            cand_images = cand_images[cand_images.image_id != middle_image_id]\n",
    "    return(middle_image, middle_image_id, cand_images)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5bf9ee-c425-4d94-bb33-1c00cd6df882",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_hdf(image_id):\n",
    "    hdf = glob(hdf_dir + '*' + image_id + '*')\n",
    "    for h in hdf:\n",
    "        os.remove(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624a7b2e-fcc0-4bab-aed4-876542110373",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_index['converted'] = False\n",
    "\n",
    "for tile in tiles_to_process:\n",
    "    print(tile)\n",
    "    if tile == \"15SVR\": ## remove edge case\n",
    "        continue\n",
    "        \n",
    "    ## set initial spatial threshold\n",
    "    temp_thres = 100\n",
    "\n",
    "    cand_images = image_index[(image_index.tile == tile) &(image_index.spatial_coverage == 100) & (image_index.cloud_coverage <= cloud_thres)]\n",
    "    print(cand_images)\n",
    "    print(len(cand_images))\n",
    "    if len(cand_images) < 3:\n",
    "        temp_thres = 90\n",
    "        cand_images = image_index[(image_index.tile == tile) &(image_index.spatial_coverage >= temp_thres) & (image_index.cloud_coverage <= cloud_thres)]\n",
    "        print(len(cand_images))\n",
    "    if len(cand_images) < 3:\n",
    "        temp_thres = 80\n",
    "        cand_images = image_index[(image_index.tile == tile) &(image_index.spatial_coverage >= temp_thres) & (image_index.cloud_coverage <= cloud_thres)]\n",
    "        print(len(cand_images))\n",
    "    if len(cand_images) < 3:\n",
    "        temp_thres = 70\n",
    "        cand_images = image_index[(image_index.tile == tile) &(image_index.spatial_coverage >= temp_thres) & (image_index.cloud_coverage <= cloud_thres)]\n",
    "        print(len(cand_images))\n",
    "    if len(cand_images) < 3:\n",
    "        temp_thres = 60\n",
    "        cand_images = image_index[(image_index.tile == tile) &(image_index.spatial_coverage >= temp_thres) & (image_index.cloud_coverage <= cloud_thres)]\n",
    "        print(len(cand_images))\n",
    "    if len(cand_images) < 3:\n",
    "        temp_thres = 50\n",
    "        cand_images = image_index[(image_index.tile == tile) &(image_index.spatial_coverage >= temp_thres) & (image_index.cloud_coverage <= cloud_thres)]\n",
    "        print(len(cand_images))\n",
    "    if len(cand_images) < 3:\n",
    "        print(tile + ' skipped')\n",
    "        continue\n",
    "    print('final spatial threshold ' + str(temp_thres))\n",
    "\n",
    "    # if len(cand_images) < 4:\n",
    "    #     print(tile + ' skipped')\n",
    "    #     continue\n",
    "    first_image, first_image_id, cand_images = convert_first_date(cand_images)\n",
    "    last_image, last_image_id, last_images = convert_last_date(cand_images)\n",
    "    middle_image, middle_image_id, middle_images = convert_middle_date(cand_images)\n",
    "\n",
    "    selected_images = pd.concat([first_image, middle_image, last_image], ignore_index = True)\n",
    "    #print(selected_images)\n",
    "    \n",
    "    image_index.loc[image_index.image_id == first_image_id  , 'converted'] = True\n",
    "    image_index.loc[image_index.image_id == middle_image_id  , 'converted'] = True\n",
    "    image_index.loc[image_index.image_id == last_image_id  , 'converted'] = True\n",
    "\n",
    "\n",
    "    assert len(selected_images) == 3\n",
    "    assert len(selected_images.image_id.unique()) == 3\n",
    "    \n",
    "    ## update tile tracker\n",
    "    tile_tracker = pd.read_csv(tile_tracker_csv)\n",
    "    tile_tracker.loc[tile_tracker.tile == tile , 'tif_convert'] = True\n",
    "    tile_tracker.loc[tile_tracker.tile == tile , 'spatial_cov'] = temp_thres\n",
    "\n",
    "    tile_tracker.to_csv(tile_tracker_csv, index=False)\n",
    "    \n",
    "    # images_to_delete = image_index[(image_index.tile == tile) & (~image_index.image_id.isin([first_image_id, middle_image_id, last_image_id]))]\n",
    "    # a = images_to_delete.image_id.tolist()    \n",
    "    # for x in a:\n",
    "    #     delete_hdf(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e51d72-a722-41ba-8fb9-facb4ae50f7a",
   "metadata": {},
   "source": [
    "3. reproject selected cog to cdl crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2bb1f9b1-649d-4e25-84d4-8d76b1e2f4f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def reproject_hls_to_cdl(scene_folder,\n",
    "                         bands = [\"B02\", \"B03\", \"B04\", \"B8A\", \"B11\", \"B12\", \"QA\"],\n",
    "                         cdl_file = \"/data/2021_30m_cdls_clipped.tif\"):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function receives the path to a folder that contains all GeoTIFF files (for various bands)\n",
    "    of a HLS scene, and reprojects those to the target CDL CRS and grid. \n",
    "    \n",
    "    Assumptions:\n",
    "    - scene_folder has a file structure like: \".../<scene_id>/<scene_id>.<band_id>.tiff\n",
    "    - scene_folder should not have a \"/\" at the end\n",
    "    \n",
    "    Inputs:\n",
    "    - scene_folder: is the path to the folder that contains HLS GeoTIFF files for all bands of HLS\n",
    "    - bands: list of bands of HLS that should be reprojected (default is all bands)\n",
    "    - cdl_file: contains the path to the clipped CDL GeoTIFF file\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    for band in bands:\n",
    "        xds = xarray.open_rasterio(f\"{scene_folder}/{scene_folder.split('/')[-1]}.{band}.tif\")\n",
    "        cdl = xarray.open_rasterio(cdl_file)\n",
    "        xds_new = xds.rio.reproject_match(cdl, resampling = Resampling.bilinear)\n",
    "        xds_new.rio.to_raster(raster_path = f\"{scene_folder}/{scene_folder.split('/')[-1]}.{band}.5070.tif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "94bdb835-d28d-49c1-a9ea-7b3d27d0bbfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['14SMC', '14SMB', '14SMA', '14SNC', '14SNB', '14SNA', '14SNE',\n",
       "       '14SND', '14SNF', '14SPA', '14SPC', '14SPE', '14SPD', '14SPF',\n",
       "       '14SQA', '14SQC', '14SQF', '14SQE', '14SQD', '15STA', '15STV',\n",
       "       '15STU', '15STT', '15STS', '15STR', '15SUA', '15SUV', '15SUU',\n",
       "       '15SUS', '15SUR', '15SVA', '15SVV', '15SVU', '15SVT', '15SVS'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tile_tracker = pd.read_csv(tile_tracker_csv)\n",
    "#tiles_already_converted = set([i[19:24] for i in tiles_already_converted])\n",
    "tiles_to_reproject = tile_tracker[(tile_tracker.exclude == False) & (tile_tracker.tif_convert == True) & (tile_tracker.tif_reproject == False) ].tile.unique()\n",
    "#tiles_to_reproject = tiles_to_reproject[0:3]\n",
    "tiles_to_reproject\n",
    "\n",
    "# (image_index[image_index.converted == True]).reset_index(drop = True)\n",
    "# print(selected_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9ce62131-921c-468a-b655-63d516f9f073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bad_columns = tile_tracker.columns.tolist()\n",
    "# bad_columns = [column for column in bad_columns if 'Unnamed' in column]\n",
    "# print(bad_columns)\n",
    "# tile_tracker = tile_tracker.drop(bad_columns, axis=1)\n",
    "# tile_tracker.to_csv(tile_tracker_csv, index=False)\n",
    "# tile_tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "97b9a698-3ebf-43e8-8ddc-4b36662413c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chip_df = pd.read_csv(chip_csv)\n",
    "# bad_columns = chip_df.columns.tolist()\n",
    "# bad_columns = [column for column in bad_columns if 'Unnamed' in column]\n",
    "# print(bad_columns)\n",
    "# chip_df = chip_df.drop(bad_columns, axis=1)\n",
    "# chip_df.to_csv(chip_df_csv, index=False)\n",
    "# chip_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f85d47ed-80dc-4a91-861e-8c7795957ae8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tile</th>\n",
       "      <th>exclude</th>\n",
       "      <th>hdf_download</th>\n",
       "      <th>tif_convert</th>\n",
       "      <th>tif_reproject</th>\n",
       "      <th>chip</th>\n",
       "      <th>filter_chips</th>\n",
       "      <th>spatial_cov</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14SMF</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14SME</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14SMD</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14SMC</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14SMB</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>14SMA</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>14SNC</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>14SNB</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>14SNA</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>14SNE</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>14SND</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>14SNF</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>14SPA</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14SPC</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14SPB</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>14SPE</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>14SPD</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>14SPF</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>14SQA</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>14SQC</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>14SQB</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>14SQF</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>14SQE</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>14SQD</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>15STA</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>15STV</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>15STU</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>15STT</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>15STS</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>15STR</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>15SUA</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>15SUV</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>15SUU</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>15SUT</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>15SUS</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>15SUR</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>15SVA</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>15SVV</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>15SVU</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>15SVT</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>15SVS</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>15SVR</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     tile  exclude  hdf_download  tif_convert  tif_reproject   chip  \\\n",
       "0   14SMF    False          True         True           True   True   \n",
       "1   14SME    False          True         True           True   True   \n",
       "2   14SMD    False          True         True           True   True   \n",
       "3   14SMC    False          True         True          False  False   \n",
       "4   14SMB    False          True         True          False  False   \n",
       "5   14SMA    False          True         True          False  False   \n",
       "6   14SNC    False          True         True          False  False   \n",
       "7   14SNB    False          True         True          False  False   \n",
       "8   14SNA    False          True         True          False  False   \n",
       "9   14SNE    False          True         True          False  False   \n",
       "10  14SND    False          True         True          False  False   \n",
       "11  14SNF    False          True         True          False  False   \n",
       "12  14SPA    False          True         True          False  False   \n",
       "13  14SPC    False          True         True          False  False   \n",
       "14  14SPB    False          True        False          False  False   \n",
       "15  14SPE    False          True         True          False  False   \n",
       "16  14SPD    False          True         True          False  False   \n",
       "17  14SPF    False          True         True          False  False   \n",
       "18  14SQA    False          True         True          False  False   \n",
       "19  14SQC    False          True         True          False  False   \n",
       "20  14SQB    False          True        False          False  False   \n",
       "21  14SQF    False          True         True          False  False   \n",
       "22  14SQE    False          True         True          False  False   \n",
       "23  14SQD    False          True         True          False  False   \n",
       "24  15STA    False          True         True          False  False   \n",
       "25  15STV    False          True         True          False  False   \n",
       "26  15STU    False          True         True          False  False   \n",
       "27  15STT    False          True         True          False  False   \n",
       "28  15STS    False          True         True          False  False   \n",
       "29  15STR    False          True         True          False  False   \n",
       "30  15SUA    False          True         True          False  False   \n",
       "31  15SUV    False          True         True          False  False   \n",
       "32  15SUU    False          True         True          False  False   \n",
       "33  15SUT    False          True        False          False  False   \n",
       "34  15SUS    False          True         True          False  False   \n",
       "35  15SUR    False          True         True          False  False   \n",
       "36  15SVA    False          True         True          False  False   \n",
       "37  15SVV    False          True         True          False  False   \n",
       "38  15SVU    False          True         True          False  False   \n",
       "39  15SVT    False          True         True          False  False   \n",
       "40  15SVS    False          True         True          False  False   \n",
       "41  15SVR    False          True        False          False  False   \n",
       "\n",
       "    filter_chips  spatial_cov  \n",
       "0           True        100.0  \n",
       "1           True        100.0  \n",
       "2           True        100.0  \n",
       "3          False        100.0  \n",
       "4          False         90.0  \n",
       "5          False         90.0  \n",
       "6          False        100.0  \n",
       "7          False        100.0  \n",
       "8          False        100.0  \n",
       "9          False         90.0  \n",
       "10         False        100.0  \n",
       "11         False         90.0  \n",
       "12         False         90.0  \n",
       "13         False        100.0  \n",
       "14         False          NaN  \n",
       "15         False        100.0  \n",
       "16         False        100.0  \n",
       "17         False        100.0  \n",
       "18         False        100.0  \n",
       "19         False        100.0  \n",
       "20         False          NaN  \n",
       "21         False        100.0  \n",
       "22         False         90.0  \n",
       "23         False         90.0  \n",
       "24         False         80.0  \n",
       "25         False        100.0  \n",
       "26         False        100.0  \n",
       "27         False        100.0  \n",
       "28         False        100.0  \n",
       "29         False        100.0  \n",
       "30         False        100.0  \n",
       "31         False        100.0  \n",
       "32         False        100.0  \n",
       "33         False          NaN  \n",
       "34         False         60.0  \n",
       "35         False         80.0  \n",
       "36         False         90.0  \n",
       "37         False         80.0  \n",
       "38         False        100.0  \n",
       "39         False        100.0  \n",
       "40         False        100.0  \n",
       "41         False          NaN  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tile_tracker = pd.read_csv(tile_tracker_csv)\n",
    "tile_tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820e9b7d-2fde-48cd-8dd5-fb5976c7ec8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/data/tif/HLS.S30.T14SMC.2021077.v1.4', '/data/tif/HLS.S30.T14SMC.2021097.v1.4', '/data/tif/HLS.S30.T14SMC.2021272.v1.4']\n",
      "/data/tif/HLS.S30.T14SMC.2021077.v1.4\n",
      "/data/tif/HLS.S30.T14SMC.2021097.v1.4\n",
      "/data/tif/HLS.S30.T14SMC.2021272.v1.4\n",
      "['/data/tif/HLS.S30.T14SMB.2021077.v1.4', '/data/tif/HLS.S30.T14SMB.2021222.v1.4', '/data/tif/HLS.S30.T14SMB.2021272.v1.4']\n",
      "/data/tif/HLS.S30.T14SMB.2021077.v1.4\n",
      "/data/tif/HLS.S30.T14SMB.2021222.v1.4\n",
      "/data/tif/HLS.S30.T14SMB.2021272.v1.4\n",
      "['/data/tif/HLS.S30.T14SMA.2021064.v1.4', '/data/tif/HLS.S30.T14SMA.2021194.v1.4', '/data/tif/HLS.S30.T14SMA.2021254.v1.4']\n",
      "/data/tif/HLS.S30.T14SMA.2021064.v1.4\n",
      "/data/tif/HLS.S30.T14SMA.2021194.v1.4\n",
      "/data/tif/HLS.S30.T14SMA.2021254.v1.4\n",
      "['/data/tif/HLS.S30.T14SNC.2021069.v1.4', '/data/tif/HLS.S30.T14SNC.2021129.v1.4', '/data/tif/HLS.S30.T14SNC.2021254.v1.4']\n",
      "/data/tif/HLS.S30.T14SNC.2021069.v1.4\n",
      "/data/tif/HLS.S30.T14SNC.2021129.v1.4\n",
      "/data/tif/HLS.S30.T14SNC.2021254.v1.4\n",
      "['/data/tif/HLS.S30.T14SNB.2021079.v1.4', '/data/tif/HLS.S30.T14SNB.2021234.v1.4', '/data/tif/HLS.S30.T14SNB.2021244.v1.4']\n",
      "/data/tif/HLS.S30.T14SNB.2021079.v1.4\n",
      "/data/tif/HLS.S30.T14SNB.2021234.v1.4\n",
      "/data/tif/HLS.S30.T14SNB.2021244.v1.4\n",
      "['/data/tif/HLS.S30.T14SNA.2021064.v1.4', '/data/tif/HLS.S30.T14SNA.2021084.v1.4', '/data/tif/HLS.S30.T14SNA.2021194.v1.4']\n",
      "/data/tif/HLS.S30.T14SNA.2021064.v1.4\n",
      "/data/tif/HLS.S30.T14SNA.2021084.v1.4\n",
      "/data/tif/HLS.S30.T14SNA.2021194.v1.4\n",
      "['/data/tif/HLS.S30.T14SNE.2021069.v1.4', '/data/tif/HLS.S30.T14SNE.2021169.v1.4', '/data/tif/HLS.S30.T14SNE.2021244.v1.4']\n",
      "/data/tif/HLS.S30.T14SNE.2021069.v1.4\n",
      "/data/tif/HLS.S30.T14SNE.2021169.v1.4\n",
      "/data/tif/HLS.S30.T14SNE.2021244.v1.4\n",
      "['/data/tif/HLS.S30.T14SND.2021069.v1.4', '/data/tif/HLS.S30.T14SND.2021129.v1.4', '/data/tif/HLS.S30.T14SND.2021244.v1.4']\n",
      "/data/tif/HLS.S30.T14SND.2021069.v1.4\n",
      "/data/tif/HLS.S30.T14SND.2021129.v1.4\n",
      "/data/tif/HLS.S30.T14SND.2021244.v1.4\n",
      "['/data/tif/HLS.S30.T14SNF.2021087.v1.4', '/data/tif/HLS.S30.T14SNF.2021212.v1.4', '/data/tif/HLS.S30.T14SNF.2021262.v1.4']\n",
      "/data/tif/HLS.S30.T14SNF.2021087.v1.4\n",
      "/data/tif/HLS.S30.T14SNF.2021212.v1.4\n",
      "/data/tif/HLS.S30.T14SNF.2021262.v1.4\n",
      "['/data/tif/HLS.S30.T14SPA.2021064.v1.4', '/data/tif/HLS.S30.T14SPA.2021224.v1.4', '/data/tif/HLS.S30.T14SPA.2021254.v1.4']\n",
      "/data/tif/HLS.S30.T14SPA.2021064.v1.4\n",
      "/data/tif/HLS.S30.T14SPA.2021224.v1.4\n",
      "/data/tif/HLS.S30.T14SPA.2021254.v1.4\n",
      "['/data/tif/HLS.S30.T14SPC.2021079.v1.4', '/data/tif/HLS.S30.T14SPC.2021234.v1.4', '/data/tif/HLS.S30.T14SPC.2021244.v1.4']\n",
      "/data/tif/HLS.S30.T14SPC.2021079.v1.4\n",
      "/data/tif/HLS.S30.T14SPC.2021234.v1.4\n",
      "/data/tif/HLS.S30.T14SPC.2021244.v1.4\n",
      "['/data/tif/HLS.S30.T14SPE.2021074.v1.4', '/data/tif/HLS.S30.T14SPE.2021194.v1.4', '/data/tif/HLS.S30.T14SPE.2021254.v1.4']\n",
      "/data/tif/HLS.S30.T14SPE.2021074.v1.4\n",
      "/data/tif/HLS.S30.T14SPE.2021194.v1.4\n",
      "/data/tif/HLS.S30.T14SPE.2021254.v1.4\n",
      "['/data/tif/HLS.S30.T14SPD.2021074.v1.4', '/data/tif/HLS.S30.T14SPD.2021149.v1.4', '/data/tif/HLS.S30.T14SPD.2021254.v1.4']\n",
      "/data/tif/HLS.S30.T14SPD.2021074.v1.4\n",
      "/data/tif/HLS.S30.T14SPD.2021149.v1.4\n",
      "/data/tif/HLS.S30.T14SPD.2021254.v1.4\n",
      "['/data/tif/HLS.S30.T14SPF.2021109.v1.4', '/data/tif/HLS.S30.T14SPF.2021194.v1.4', '/data/tif/HLS.S30.T14SPF.2021249.v1.4']\n",
      "/data/tif/HLS.S30.T14SPF.2021109.v1.4\n",
      "/data/tif/HLS.S30.T14SPF.2021194.v1.4\n",
      "/data/tif/HLS.S30.T14SPF.2021249.v1.4\n",
      "['/data/tif/HLS.S30.T14SQA.2021061.v1.4', '/data/tif/HLS.S30.T14SQA.2021101.v1.4', '/data/tif/HLS.S30.T14SQA.2021126.v1.4']\n",
      "/data/tif/HLS.S30.T14SQA.2021061.v1.4\n",
      "/data/tif/HLS.S30.T14SQA.2021101.v1.4\n",
      "/data/tif/HLS.S30.T14SQA.2021126.v1.4\n",
      "['/data/tif/HLS.S30.T14SQC.2021061.v1.4', '/data/tif/HLS.S30.T14SQC.2021101.v1.4', '/data/tif/HLS.S30.T14SQC.2021236.v1.4']\n",
      "/data/tif/HLS.S30.T14SQC.2021061.v1.4\n",
      "/data/tif/HLS.S30.T14SQC.2021101.v1.4\n",
      "/data/tif/HLS.S30.T14SQC.2021236.v1.4\n",
      "['/data/tif/HLS.S30.T14SQF.2021074.v1.4', '/data/tif/HLS.S30.T14SQF.2021219.v1.4', '/data/tif/HLS.S30.T14SQF.2021254.v1.4']\n",
      "/data/tif/HLS.S30.T14SQF.2021074.v1.4\n",
      "/data/tif/HLS.S30.T14SQF.2021219.v1.4\n",
      "/data/tif/HLS.S30.T14SQF.2021254.v1.4\n",
      "['/data/tif/HLS.S30.T14SQE.2021074.v1.4', '/data/tif/HLS.S30.T14SQE.2021219.v1.4', '/data/tif/HLS.S30.T14SQE.2021249.v1.4']\n",
      "/data/tif/HLS.S30.T14SQE.2021074.v1.4\n",
      "/data/tif/HLS.S30.T14SQE.2021219.v1.4\n",
      "/data/tif/HLS.S30.T14SQE.2021249.v1.4\n",
      "['/data/tif/HLS.S30.T14SQD.2021061.v1.4', '/data/tif/HLS.S30.T14SQD.2021111.v1.4', '/data/tif/HLS.S30.T14SQD.2021206.v1.4']\n",
      "/data/tif/HLS.S30.T14SQD.2021061.v1.4\n",
      "/data/tif/HLS.S30.T14SQD.2021111.v1.4\n",
      "/data/tif/HLS.S30.T14SQD.2021206.v1.4\n",
      "['/data/tif/HLS.S30.T15STA.2021061.v1.4', '/data/tif/HLS.S30.T15STA.2021219.v1.4', '/data/tif/HLS.S30.T15STA.2021254.v1.4']\n",
      "/data/tif/HLS.S30.T15STA.2021061.v1.4\n",
      "/data/tif/HLS.S30.T15STA.2021219.v1.4\n",
      "/data/tif/HLS.S30.T15STA.2021254.v1.4\n",
      "['/data/tif/HLS.S30.T15STV.2021061.v1.4', '/data/tif/HLS.S30.T15STV.2021126.v1.4', '/data/tif/HLS.S30.T15STV.2021171.v1.4']\n",
      "/data/tif/HLS.S30.T15STV.2021061.v1.4\n",
      "/data/tif/HLS.S30.T15STV.2021126.v1.4\n",
      "/data/tif/HLS.S30.T15STV.2021171.v1.4\n",
      "['/data/tif/HLS.S30.T15STU.2021061.v1.4', '/data/tif/HLS.S30.T15STU.2021111.v1.4', '/data/tif/HLS.S30.T15STU.2021166.v1.4']\n",
      "/data/tif/HLS.S30.T15STU.2021061.v1.4\n",
      "/data/tif/HLS.S30.T15STU.2021111.v1.4\n",
      "/data/tif/HLS.S30.T15STU.2021166.v1.4\n",
      "['/data/tif/HLS.S30.T15STT.2021061.v1.4', '/data/tif/HLS.S30.T15STT.2021091.v1.4', '/data/tif/HLS.S30.T15STT.2021101.v1.4']\n",
      "/data/tif/HLS.S30.T15STT.2021061.v1.4\n",
      "/data/tif/HLS.S30.T15STT.2021091.v1.4\n",
      "/data/tif/HLS.S30.T15STT.2021101.v1.4\n",
      "['/data/tif/HLS.S30.T15STS.2021061.v1.4', '/data/tif/HLS.S30.T15STS.2021101.v1.4', '/data/tif/HLS.S30.T15STS.2021126.v1.4']\n",
      "/data/tif/HLS.S30.T15STS.2021061.v1.4\n",
      "/data/tif/HLS.S30.T15STS.2021101.v1.4\n",
      "/data/tif/HLS.S30.T15STS.2021126.v1.4\n",
      "['/data/tif/HLS.S30.T15STR.2021061.v1.4', '/data/tif/HLS.S30.T15STR.2021101.v1.4', '/data/tif/HLS.S30.T15STR.2021126.v1.4']\n",
      "/data/tif/HLS.S30.T15STR.2021061.v1.4\n",
      "/data/tif/HLS.S30.T15STR.2021101.v1.4\n",
      "/data/tif/HLS.S30.T15STR.2021126.v1.4\n",
      "['/data/tif/HLS.S30.T15SUA.2021061.v1.4', '/data/tif/HLS.S30.T15SUA.2021086.v1.4', '/data/tif/HLS.S30.T15SUA.2021101.v1.4']\n",
      "/data/tif/HLS.S30.T15SUA.2021061.v1.4\n",
      "/data/tif/HLS.S30.T15SUA.2021086.v1.4\n",
      "/data/tif/HLS.S30.T15SUA.2021101.v1.4\n",
      "['/data/tif/HLS.S30.T15SUV.2021101.v1.4', '/data/tif/HLS.S30.T15SUV.2021166.v1.4', '/data/tif/HLS.S30.T15SUV.2021236.v1.4']\n",
      "/data/tif/HLS.S30.T15SUV.2021101.v1.4\n",
      "/data/tif/HLS.S30.T15SUV.2021166.v1.4\n",
      "/data/tif/HLS.S30.T15SUV.2021236.v1.4\n",
      "['/data/tif/HLS.S30.T15SUU.2021101.v1.4', '/data/tif/HLS.S30.T15SUU.2021126.v1.4', '/data/tif/HLS.S30.T15SUU.2021166.v1.4']\n",
      "/data/tif/HLS.S30.T15SUU.2021101.v1.4\n"
     ]
    }
   ],
   "source": [
    "for tile in tiles_to_reproject:\n",
    "    selected_images = glob(tif_dir + '*')\n",
    "    #print(selected_images)\n",
    "    selected_images = [image for image in selected_images if image[19:24] == tile]\n",
    "    print(selected_images)\n",
    "        ## reproject to cdl\n",
    "    for k in range(len(selected_images)):\n",
    "        image_id = selected_images[k]\n",
    "        print(image_id)\n",
    "        reproject_hls_to_cdl(image_id)\n",
    "    tile_tracker = pd.read_csv(tile_tracker_csv)\n",
    "    tile_tracker.loc[tile_tracker.tile == tile , 'tif_reproject'] = True\n",
    "    tile_tracker.to_csv(tile_tracker_csv, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49307af-b57a-465f-95b7-0a5ef4e7ee91",
   "metadata": {},
   "source": [
    "4. chipping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1222194e-90cc-45bd-94ec-fe65537ca1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_tracker = pd.read_csv(tile_tracker_csv)\n",
    "tiles_to_chip = tile_tracker[(tile_tracker.exclude == False) & (tile_tracker.tif_reproject == True) & (tile_tracker.chip == False) ].tile.unique()\n",
    "tiles_to_chip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b179370-848c-4350-ac9e-7d49e201be3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_qa(qa_path, shape,  valid_qa = [0, 4, 32, 36, 64, 68, 96, 100, 128, 132, 160, 164, 192, 196, 224, 228]):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function receives a path to a qa file, and a geometry. It clips the QA file to the geometry. \n",
    "    It returns the number of valid QA pixels in the geometry, and the clipped values.\n",
    "    \n",
    "    Assumptions: The valid_qa values are taken from Ben Mack's post:\n",
    "    https://benmack.github.io/nasa_hls/build/html/tutorials/Working_with_HLS_datasets_and_nasa_hls.html\n",
    "    \n",
    "    Inputs:\n",
    "    - qa_path: full path to reprojected QA tif file\n",
    "    - shape: 'geometry' property of single polygon feature read by fiona\n",
    "    - valid_qa: list of integer values that are 'valid' for QA band.\n",
    "    \n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    with rasterio.open(qa_path) as src:\n",
    "        out_image, out_transform = rasterio.mask.mask(src, shape, crop=True)\n",
    "      #  print(out_image.shape)\n",
    "        vals = out_image.flatten()\n",
    "        unique, counts = np.unique(vals, return_counts=True)\n",
    "        qa_df = pd.DataFrame({\"qa_val\" : unique, \"counts\" : counts})\n",
    "        qa_df\n",
    "        qa_df[~ qa_df.qa_val.isin(valid_qa)].sort_values(['counts'], ascending = False)\n",
    "        qa_df['pct'] = (100 *qa_df['counts'])/(224.0 * 224.0)\n",
    "        \n",
    "        bad_qa = qa_df[~ qa_df.qa_val.isin(valid_qa)].sort_values(['counts'], ascending = False)\n",
    "        if len(bad_qa) > 0:\n",
    "            highest_invalid_percent = bad_qa.pct.tolist()[0]\n",
    "        else: \n",
    "            highest_invalid_percent = 0\n",
    "        #ncell = len(vals)\n",
    "        valid_count = sum(x in valid_qa for x in vals)\n",
    "        return(valid_count, highest_invalid_percent, out_image[0])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78b1dd6-6465-4a93-bb27-dbcc0555a1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## set up CDL reclass\n",
    "cdl_class_df = pd.read_csv(cdl_reclass_csv)\n",
    "crop_dict = dict(zip(cdl_class_df.CDL_val, cdl_class_df.new_class_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5849ef63-172a-4313-a4e7-6a1b5bb4bd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_reclass(x):\n",
    "    ## binary reclass\n",
    "    crop_classes = [1,2,3,4,5,6,10,11,12,13,14,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,66,67,68,69,70,71,72,74,75,76,77,92,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,236,237,238,240,241,242,243,244,245,246,247,248,249,250,254]\n",
    "    return(crop_classes.count(x))\n",
    "\n",
    "c_rcl = np.vectorize(crop_reclass)\n",
    "\n",
    "\n",
    "def crop_multi(x):\n",
    "    return(crop_dict[x])\n",
    "\n",
    "c_multi = np.vectorize(crop_multi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997eec43-0008-4380-9a16-57ac20b68226",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reorder_bands(file_list, band_order = [\"B02\", \"B03\", \"B04\", \"B8A\", \"B11\", \"B12\", \"QA\"]):\n",
    "    reordered = []\n",
    "    for band in band_order:\n",
    "        file_name = [s for s in file_list if band in s]\n",
    "        print('file_name')\n",
    "        print(file_name)\n",
    "        assert (len(file_name) == 1)\n",
    "        reordered.append(file_name[0])\n",
    "    print(reordered)\n",
    "    return(reordered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e60745-8c2e-4bcd-8130-2cf76a0e7e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_chip(chip_id, \n",
    "                 chip_tile,\n",
    "                 shape,\n",
    "                 bands = [\"B02\", \"B03\", \"B04\", \"B8A\", \"B11\", \"B12\", \"QA\"]):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function receives a chip id, HLS tile, chip geometry, and a list of bands to process. \n",
    "    \n",
    "    Assumptions:\n",
    "    \n",
    "    Inputs:\n",
    "    - chip_id: string of chip id, e.g. '000_001'\n",
    "    - chip_tile: string of HLS tile , e.g. '15ABC'\n",
    "    - shape: 'geometry' property of single polygon feature read by fiona\n",
    "    \n",
    "    The function writes out a multi-date TIF containing the bands for each of the three image dates for an HLS tile. \n",
    "    The function writes out a multi-date TIF containing the QA bands of each date.\n",
    "    The function writes out a chipped version of CDL. \n",
    "    The function calls check_qa(), which makes assumptions about what QA pixels are valid.\n",
    "    The function returns the number of valid QA pixels at each date, as a tuple.\n",
    "    \n",
    "    \"\"\"\n",
    "    ## get reprojected image paths\n",
    "    selected_image_folders = sorted(glob(f'/data/tif/*T{chip_tile}*'))\n",
    "   # print(selected_image_folders)\n",
    "    \n",
    "    assert len(selected_image_folders) == 3\n",
    "    \n",
    "    first_image_date = selected_image_folders[0][25:32]\n",
    "    second_image_date = selected_image_folders[1][25:32]\n",
    "    third_image_date = selected_image_folders[2][25:32]\n",
    "    \n",
    "    first_date_images = sorted(glob(selected_image_folders[0] + '/*.5070.tif'))\n",
    "    \n",
    "    first_date_images = reorder_bands(first_date_images, band_order = bands)\n",
    "    first_date_qa = [x for x in first_date_images if '.QA.' in x][0]\n",
    "    first_date_images.remove(first_date_qa)\n",
    "    \n",
    "    second_date_images = sorted(glob(selected_image_folders[1] + '/*.5070.tif'))\n",
    "    second_date_images = reorder_bands(second_date_images, band_order = bands)\n",
    "\n",
    "    second_date_qa = [x for x in second_date_images if '.QA.' in x][0]\n",
    "    second_date_images.remove(second_date_qa)\n",
    "    \n",
    "    third_date_images = sorted(glob(selected_image_folders[2] + '/*.5070.tif'))\n",
    "    third_date_images = reorder_bands(third_date_images, band_order = bands)\n",
    "\n",
    "    third_date_qa = [x for x in third_date_images if '.QA.' in x][0]\n",
    "    third_date_images.remove(third_date_qa)\n",
    "    all_date_images = first_date_images + second_date_images + third_date_images\n",
    "    \n",
    "    print('all date images')\n",
    "    print(all_date_images)\n",
    "  #  print(len(all_date_images))\n",
    "\n",
    "\n",
    "    valid_first, bad_pct_first, qa_first = check_qa(first_date_qa, shape)\n",
    "    valid_second, bad_pct_second, qa_second = check_qa(second_date_qa, shape)\n",
    "    valid_third, bad_pct_third, qa_third = check_qa(third_date_qa, shape)\n",
    "    \n",
    "    qa_bands = []\n",
    "    qa_bands.append(qa_first)\n",
    "    qa_bands.append(qa_second)\n",
    "    qa_bands.append(qa_third)\n",
    "    qa_bands = np.array(qa_bands).astype(np.int16)\n",
    "    \n",
    "  #  print(qa_bands.shape)\n",
    "   # print(first_date_qa)\n",
    "    assert len(all_date_images) == 3 * (len(bands) - 1)\n",
    "    \n",
    "    out_bands = []\n",
    "    print('out_bands_loop')\n",
    "    for img in all_date_images:\n",
    "        with rasterio.open(img) as src:\n",
    "            print(img)\n",
    "            out_image, out_transform = rasterio.mask.mask(src, shape, crop=True)\n",
    "            out_meta = src.meta\n",
    "            out_bands.append(out_image[0])\n",
    "    \n",
    "    out_bands = np.array(out_bands)\n",
    "    # print(out_bands.shape)\n",
    "    # print(out_image.shape)\n",
    "\n",
    "    out_meta.update({\"driver\": \"GTiff\",\n",
    "                     \"height\": out_bands.shape[1],\n",
    "                     \"width\": out_bands.shape[2],\n",
    "                     \"count\": out_bands.shape[0],\n",
    "                     \"transform\": out_transform})\n",
    "    \n",
    "    # get NA count for HLS\n",
    "    na_count = sum(out_bands.flatten() == -1000)\n",
    "    \n",
    "    # reclass negative HLS values to 0\n",
    "    out_bands = np.clip(out_bands, 0, None)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # write HLS chip to 'chips'\n",
    "    with rasterio.open(chip_dir + \"chip_\" + str(chip_id) + \"_merged.tif\", \"w\", **out_meta) as dest:\n",
    "        dest.write(out_bands)\n",
    "    # write HLS chip to 'chips_binary'\n",
    "    with rasterio.open(chip_dir_binary + \"chip_\" + str(chip_id) + \"_merged.tif\", \"w\", **out_meta) as dest:\n",
    "        dest.write(out_bands)\n",
    "    # write HLS chip to 'chips_multi'\n",
    "    with rasterio.open(chip_dir_multi + \"chip_\" + str(chip_id) + \"_merged.tif\", \"w\", **out_meta) as dest:\n",
    "        dest.write(out_bands)\n",
    "      \n",
    "    ## write QA bands\n",
    "    out_meta.update({\"driver\": \"GTiff\",\n",
    "                     \"height\": qa_bands.shape[1],\n",
    "                     \"width\": qa_bands.shape[2],\n",
    "                     \"count\": qa_bands.shape[0],\n",
    "                     \"transform\": out_transform})\n",
    "    \n",
    "    with rasterio.open(chip_qa_dir + \"chip_\" + str(chip_id) + \"_qa.tif\", \"w\", **out_meta) as dest:\n",
    "        dest.write(qa_bands)  \n",
    "    \n",
    "        \n",
    "    ## clip cdl to chip\n",
    "    with rasterio.open(\"/data/2021_30m_cdls_clipped.tif\") as src:\n",
    "        out_image, out_transform = rasterio.mask.mask(src, shape, crop=True)\n",
    "        out_meta = src.meta\n",
    "        colormap = src.colormap(1)\n",
    "\n",
    "    out_meta.update({\"driver\": \"GTiff\",\n",
    "                     \"height\": out_image.shape[1],\n",
    "                     \"width\": out_image.shape[2],\n",
    "                     \"transform\": out_transform})\n",
    "    # write CDL chip to 'chips'\n",
    "    with rasterio.open(chip_dir + \"chip_\" + str(chip_id) + \".mask.tif\", \"w\", **out_meta) as dest:\n",
    "        dest.write(out_image)\n",
    "        dest.write_colormap(1, colormap)\n",
    "        \n",
    "        \n",
    "    # write binary  reclassed CDL chip to chips_binary\n",
    "    out_image_binary = c_rcl(out_image).astype(np.uint8)\n",
    "    with rasterio.open(chip_dir_binary + \"chip_\" + str(chip_id) + \".mask.tif\", \"w\", **out_meta) as dest:\n",
    "        dest.write(out_image_binary)\n",
    "        dest.write_colormap(1, colormap)\n",
    "        \n",
    "    # write multiclass  reclassed CDL chip to chips_multi\n",
    "    out_image_multi = c_multi(out_image).astype(np.uint8)\n",
    "    with rasterio.open(chip_dir_multi + \"chip_\" + str(chip_id) + \".mask.tif\", \"w\", **out_meta) as dest:\n",
    "        dest.write(out_image_multi)\n",
    "        dest.write_colormap(1, colormap)\n",
    "    \n",
    "    \n",
    "    return(valid_first,\n",
    "           valid_second,\n",
    "           valid_third, \n",
    "           bad_pct_first,\n",
    "           bad_pct_second,\n",
    "           bad_pct_third,\n",
    "           qa_first,\n",
    "           qa_second,\n",
    "           qa_third,\n",
    "           na_count,\n",
    "           first_image_date,\n",
    "           second_image_date,\n",
    "           third_image_date)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e6df41-29d7-4a0b-917b-0628c25da424",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## process chips\n",
    "chip_df = pd.read_csv(chip_csv)\n",
    "\n",
    "for tile in tiles_to_chip:\n",
    "    print(tile)\n",
    "    chips_to_process = chip_df[chip_df.tile == tile].reset_index(drop = True)\n",
    "    for k in range(len(chips_to_process)):\n",
    "        current_id = chips_to_process.chip_id[k]\n",
    "        chip_tile = chips_to_process.tile[k]\n",
    "    #    print(current_id)\n",
    "        chip_index = chip_ids.index(current_id)\n",
    "\n",
    "        chip_feature = chips['features'][chip_index]\n",
    "\n",
    "        shape = [chip_feature['geometry']]\n",
    "\n",
    "        ## do we want to scale/clip reflectances?\n",
    "\n",
    "        valid_first,  valid_second, valid_third, bad_pct_first, bad_pct_second, bad_pct_third, qa_first, qa_second, qa_third, na_count, first_image_date, second_image_date, third_image_date = process_chip(current_id, chip_tile, shape)\n",
    "\n",
    "        chip_df_index = chip_df.index[chip_df['chip_id'] == current_id].tolist()[0]\n",
    "        chip_df.at[chip_df_index, 'valid_first'] = valid_first\n",
    "        chip_df.at[chip_df_index, 'valid_second'] = valid_second\n",
    "        chip_df.at[chip_df_index, 'valid_third'] = valid_third\n",
    "        chip_df.at[chip_df_index, 'bad_pct_first'] = bad_pct_first\n",
    "        chip_df.at[chip_df_index, 'bad_pct_second'] = bad_pct_second\n",
    "        chip_df.at[chip_df_index, 'bad_pct_third'] = bad_pct_third\n",
    "        chip_df.at[chip_df_index, 'first_image_date'] = first_image_date\n",
    "        chip_df.at[chip_df_index, 'second_image_date'] = second_image_date\n",
    "        chip_df.at[chip_df_index, 'third_image_date'] = third_image_date\n",
    "        chip_df['bad_pct_max'] = chip_df[['bad_pct_first', 'bad_pct_second', 'bad_pct_third']].max(axis=1)\n",
    "        chip_df.at[chip_df_index, 'na_count'] = na_count\n",
    "    tile_tracker = pd.read_csv(tile_tracker_csv)\n",
    "    tile_tracker.loc[tile_tracker.tile == tile , 'chip'] = True\n",
    "    tile_tracker.to_csv(tile_tracker_csv, index=False)\n",
    "chip_df.to_csv(chip_csv, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f356827-1720-4d4b-9187-11e4c23e3108",
   "metadata": {},
   "source": [
    "5. filter chips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5168c2d9-ec69-4a3d-95ab-a0bb2e248a4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['14SMF', '14SME', '14SMD'], dtype=object)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tile_tracker = pd.read_csv(tile_tracker_csv)\n",
    "tiles_to_filter = tile_tracker[(tile_tracker.exclude == False) & (tile_tracker.chip == True) & (tile_tracker.filter_chips == False) ].tile.unique()\n",
    "tiles_to_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4ae005b8-8ba1-42ac-838d-cf6eb3d38ad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14SMF\n",
      "35\n",
      "14SME\n",
      "36\n",
      "14SMD\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "chip_df = pd.read_csv(chip_csv)\n",
    "\n",
    "for tile in tiles_to_filter:\n",
    "    print(tile)\n",
    "    filtered_chips = chip_df[(chip_df.tile == tile) & (chip_df.bad_pct_max < 5) & (chip_df.na_count == 0)].chip_id.tolist()\n",
    "    print(len(filtered_chips))\n",
    "    for chip_id in filtered_chips:\n",
    "        chip_files = glob('/data/chips/*' + chip_id + '*')\n",
    "        for file in chip_files:\n",
    "            name = file.split('/')[-1]\n",
    "            shutil.copyfile(file, '/data/chips_filtered/' + name)\n",
    "        chip_files_b = glob('/data/chips_binary/*' + chip_id + '*')\n",
    "        for file in chip_files_b:\n",
    "            name = file.split('/')[-1]\n",
    "            shutil.copyfile(file, '/data/chips_binary_filtered/' + name)\n",
    "        chip_files_multi = glob('/data/chips_multi/*' + chip_id + '*')\n",
    "        for file in chip_files_multi:\n",
    "            name = file.split('/')[-1]\n",
    "            shutil.copyfile(file, '/data/chips_multi_filtered/' + name)\n",
    "    \n",
    "    tile_tracker = pd.read_csv(tile_tracker_csv)\n",
    "    tile_tracker.loc[tile_tracker.tile == tile , 'filter_chips'] = True\n",
    "    tile_tracker.to_csv(tile_tracker_csv, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c14533-4be1-4636-a237-c749fff3497a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# valid_qa = [0, 4, 32, 36, 64, 68, 96, 100, 128, 132, 160, 164, 192, 196, 224, 228]\n",
    "# qa_df_all['valid'] = qa_df_all.qa_val.isin(valid_qa)\n",
    "# qa_df_all\n",
    "# qa_df_all.to_csv(root_path + \"_\" + str(ct) + 'qa_vals.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232e31f6-cb5b-4e38-85a1-aeb5f59d8efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# valid_qa = [0, 4, 32, 36, 64, 68, 96, 100, 128, 132, 160, 164, 192, 196, 224, 228]\n",
    "\n",
    "# qa_df_all = pd.DataFrame(columns = [\"qa_val\", \"counts\", \"chip_id\", 'date'])\n",
    "\n",
    "# for chip in qa_chips[0:2]:\n",
    "#     vals = xarray.open_rasterio(chip)\n",
    "#     for k in range(3):\n",
    "#         date_vals = vals.data[k, :, :]\n",
    "#         unique, counts = np.unique(date_vals, return_counts=True)\n",
    "#         qa_df = pd.DataFrame({\"qa_val\" : unique, \"counts\" : counts})\n",
    "#         qa_df['pct'] = (100 *qa_df['counts'])/(224.0 * 224.0)\n",
    "#         qa_df['chip_id'] = chip.split('/')[-1][12:19]\n",
    "#         qa_df['date'] = str(k)\n",
    "#         qa_df_all = pd.concat([qa_df_all, qa_df])\n",
    "        \n",
    "# #qa_df_all.to_csv(root_path + 'qa_vals_date.csv')\n",
    "# qa_df_all[~ qa_df_all.qa_val.isin(valid_qa)].sort_values(['counts'], ascending = False).pct.tolist()[0]\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
