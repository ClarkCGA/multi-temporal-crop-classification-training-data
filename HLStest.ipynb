{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c8cde70-7cf0-49c8-a69e-3f2a45757876",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas\n",
    "import json\n",
    "import shapely\n",
    "import shapely.geometry\n",
    "import xarray\n",
    "import rasterio\n",
    "import rioxarray\n",
    "import os\n",
    "import fiona\n",
    "import nasa_hls\n",
    "import urllib.request as urlreq\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import xmltodict\n",
    "import shutil\n",
    "import datetime\n",
    "import boto3\n",
    "\n",
    "\n",
    "from shapely.ops import transform\n",
    "from shapely.geometry import Point\n",
    "from shapely.geometry import Polygon\n",
    "from pystac_client import Client \n",
    "from collections import defaultdict\n",
    "from glob import glob\n",
    "from rasterio.enums import Resampling\n",
    "from rasterio import Affine\n",
    "from rasterio.crs import CRS\n",
    "import matplotlib.pyplot as plt\n",
    "from subprocess import Popen, PIPE\n",
    "from tqdm import tqdm\n",
    "from netrc import netrc\n",
    "from subprocess import Popen\n",
    "from platform import system\n",
    "from getpass import getpass\n",
    "from rasterio.session import AWSSession\n",
    "from pathlib import Path\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c3ac4bcd-2c78-425d-a172-4194e29b4b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### START OPTIONS #####\n",
    "cloud_thres = 5\n",
    "\n",
    "root_path = \"/data/\"\n",
    "req_path = \"/data/requirements/\"\n",
    "## file paths\n",
    "# spath = root_path + f\"CDL_HLS_dataframe{yoi[0]}\"\n",
    "# image_index_file = root_path + f\"image_index{yoi[0]}\"\n",
    "chip_file =  req_path + \"chip_bbox.geojson\"\n",
    "chip_csv = req_path + \"chip_tracker.csv\"\n",
    "kml_file = req_path + 'sentinel_tile_grid.kml'\n",
    "cdl_reclass_csv = req_path + \"cdl_freq.csv\"\n",
    "# tile_tracker_csv = root_path + \"tile_tracker.csv\"\n",
    "\n",
    "## folder paths\n",
    "# hdf_dir = root_path + \"hdf/\"\n",
    "chip_dir = root_path + 'chips/'\n",
    "tile_dir = root_path + 'tiles/'\n",
    "# chip_dir_binary = root_path + 'chips_binary/'\n",
    "chip_dir_multi = chip_dir + 'chips_multi/'\n",
    "\n",
    "chip_dir_filt = chip_dir + 'chips_filtered/'\n",
    "# chip_dir_binary_filt = root_path + 'chips_binary_filtered/'\n",
    "chip_dir_multi_filt = chip_dir + 'chips_multi_filtered/'\n",
    "\n",
    "chip_fmask_dir = chip_dir + 'chips_fmask/'\n",
    "\n",
    "#####  END OPTIONS  #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2c5f6fe0-7f00-48a3-8df3-43a0a5ded939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pass\n",
      "pass\n",
      "pass\n",
      "pass\n"
     ]
    }
   ],
   "source": [
    "dirs_to_make = [tile_dir, chip_dir, chip_dir_multi, chip_fmask_dir]\n",
    "for folder in dirs_to_make:\n",
    "    try:\n",
    "        os.makedirs(folder)\n",
    "    except FileExistsError:\n",
    "        # directory already exists\n",
    "        print('pass')\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "572aad79-35fe-4640-85a0-a489fa18f09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(chip_file, \"r\") as file:\n",
    "    chips = json.load(file)\n",
    "    \n",
    "chip_ids = []\n",
    "chip_x = []\n",
    "chip_y = []\n",
    "for item in chips['features']:\n",
    "    #print(item)\n",
    "    chip_ids.append(item['properties']['id'])\n",
    "    chip_x.append(item['properties']['center'][0])\n",
    "    chip_y.append(item['properties']['center'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5d739262-045a-4ed9-8930-9dd5ea203e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/data/requirements/chip_ids.json\", \"w\") as f:\n",
    "    json.dump(chip_ids, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a56e07ac-9b0a-4d7c-bad1-51586770a1f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Description</th>\n",
       "      <th>geometry</th>\n",
       "      <th>minx</th>\n",
       "      <th>miny</th>\n",
       "      <th>maxx</th>\n",
       "      <th>maxy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01CCV</td>\n",
       "      <td>TILE PROPERTIES&lt;br&gt;&lt;table border=0 cellpadding...</td>\n",
       "      <td>GEOMETRYCOLLECTION Z (POLYGON Z ((180.00000 -7...</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-73.064633</td>\n",
       "      <td>180.0</td>\n",
       "      <td>-72.012478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01CDH</td>\n",
       "      <td>TILE PROPERTIES&lt;br&gt;&lt;table border=0 cellpadding...</td>\n",
       "      <td>GEOMETRYCOLLECTION Z (POLYGON Z ((180.00000 -8...</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-83.835334</td>\n",
       "      <td>180.0</td>\n",
       "      <td>-82.796720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01CDJ</td>\n",
       "      <td>TILE PROPERTIES&lt;br&gt;&lt;table border=0 cellpadding...</td>\n",
       "      <td>GEOMETRYCOLLECTION Z (POLYGON Z ((180.00000 -8...</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-82.939452</td>\n",
       "      <td>180.0</td>\n",
       "      <td>-81.906947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01CDK</td>\n",
       "      <td>TILE PROPERTIES&lt;br&gt;&lt;table border=0 cellpadding...</td>\n",
       "      <td>GEOMETRYCOLLECTION Z (POLYGON Z ((180.00000 -8...</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-82.044055</td>\n",
       "      <td>180.0</td>\n",
       "      <td>-81.016439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01CDL</td>\n",
       "      <td>TILE PROPERTIES&lt;br&gt;&lt;table border=0 cellpadding...</td>\n",
       "      <td>GEOMETRYCOLLECTION Z (POLYGON Z ((180.00000 -8...</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-81.148070</td>\n",
       "      <td>180.0</td>\n",
       "      <td>-80.124456</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Name                                        Description  \\\n",
       "0  01CCV  TILE PROPERTIES<br><table border=0 cellpadding...   \n",
       "1  01CDH  TILE PROPERTIES<br><table border=0 cellpadding...   \n",
       "2  01CDJ  TILE PROPERTIES<br><table border=0 cellpadding...   \n",
       "3  01CDK  TILE PROPERTIES<br><table border=0 cellpadding...   \n",
       "4  01CDL  TILE PROPERTIES<br><table border=0 cellpadding...   \n",
       "\n",
       "                                            geometry   minx       miny   maxx  \\\n",
       "0  GEOMETRYCOLLECTION Z (POLYGON Z ((180.00000 -7... -180.0 -73.064633  180.0   \n",
       "1  GEOMETRYCOLLECTION Z (POLYGON Z ((180.00000 -8... -180.0 -83.835334  180.0   \n",
       "2  GEOMETRYCOLLECTION Z (POLYGON Z ((180.00000 -8... -180.0 -82.939452  180.0   \n",
       "3  GEOMETRYCOLLECTION Z (POLYGON Z ((180.00000 -8... -180.0 -82.044055  180.0   \n",
       "4  GEOMETRYCOLLECTION Z (POLYGON Z ((180.00000 -8... -180.0 -81.148070  180.0   \n",
       "\n",
       "        maxy  \n",
       "0 -72.012478  \n",
       "1 -82.796720  \n",
       "2 -81.906947  \n",
       "3 -81.016439  \n",
       "4 -80.124456  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fiona.drvsupport.supported_drivers['KML'] = 'rw'\n",
    "tile_src = geopandas.read_file(kml_file, driver='KML')\n",
    "tile_name = []\n",
    "tile_x = []\n",
    "tile_y = []\n",
    "for tile_ind in range(tile_src.shape[0]):\n",
    "    tile_name.append(tile_src.iloc[tile_ind].Name)\n",
    "    tile_x.append(tile_src.iloc[tile_ind].geometry.centroid.x)\n",
    "    tile_y.append(tile_src.iloc[tile_ind].geometry.centroid.y)\n",
    "tile_name = np.array(tile_name)\n",
    "tile_x = np.array(tile_x)\n",
    "tile_y = np.array(tile_y)\n",
    "tile_src = pd.concat([tile_src, tile_src.bounds], axis = 1)\n",
    "tile_src.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "618cc2a5-678c-47fd-a324-0d89e8f74e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_tile(x,y):\n",
    "# Identify closest tile\n",
    "    s = (tile_x - x)**2+(tile_y - y)**2\n",
    "    tname = tile_name[np.argmin(s)]\n",
    "    return(tname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "923bcea3-efa4-41fc-90ef-0877dd270270",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chip_id</th>\n",
       "      <th>chip_x</th>\n",
       "      <th>chip_y</th>\n",
       "      <th>tile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>chip_090_484</td>\n",
       "      <td>-84.446559</td>\n",
       "      <td>45.575077</td>\n",
       "      <td>16TFR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>chip_177_428</td>\n",
       "      <td>-89.751220</td>\n",
       "      <td>40.674821</td>\n",
       "      <td>16TBL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>chip_106_429</td>\n",
       "      <td>-89.268425</td>\n",
       "      <td>44.931751</td>\n",
       "      <td>16TCQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>chip_312_160</td>\n",
       "      <td>-109.614541</td>\n",
       "      <td>31.902541</td>\n",
       "      <td>12SXA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>chip_198_312</td>\n",
       "      <td>-99.007068</td>\n",
       "      <td>39.532747</td>\n",
       "      <td>14SMJ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           chip_id      chip_x     chip_y   tile\n",
       "4995  chip_090_484  -84.446559  45.575077  16TFR\n",
       "4996  chip_177_428  -89.751220  40.674821  16TBL\n",
       "4997  chip_106_429  -89.268425  44.931751  16TCQ\n",
       "4998  chip_312_160 -109.614541  31.902541  12SXA\n",
       "4999  chip_198_312  -99.007068  39.532747  14SMJ"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chip_df = pd.DataFrame({\"chip_id\" : chip_ids, \"chip_x\" : chip_x, \"chip_y\" : chip_y})\n",
    "chip_df['tile'] = chip_df.apply(lambda row : find_tile(row['chip_x'], row['chip_y']), axis = 1)\n",
    "chip_df.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "be986eb5-6c6e-4834-8fa5-dc36134e7839",
   "metadata": {},
   "outputs": [],
   "source": [
    "chip_df.to_csv(req_path + \"chip_df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9ca55cff-659f-4d68-a894-278af32fb9a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['13TDE', '16SDD', '13SFV', '14TNS', '14UMU']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tiles = chip_df.tile.unique().tolist()\n",
    "tiles[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8679f41b-87b1-4b3d-a2f2-559b9df3fdfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "STAC_URL = 'https://cmr.earthdata.nasa.gov/stac'\n",
    "catalog = Client.open(f'{STAC_URL}/LPCLOUD/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c6d6080c-87aa-4ae8-bcee-71e9757b3dd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are a total of 491 tiles\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(0/491): 100%|██████████████████████████████████████████████████████████████████████████| 81/81 [00:05<00:00, 15.63it/s]\n"
     ]
    }
   ],
   "source": [
    "# Original 5 percentage query\n",
    "tile_list = []\n",
    "print(f\"There are a total of {len(tiles)} tiles\")\n",
    "tile_iter = 0\n",
    "for current_tile in tiles[0:1]:\n",
    "\n",
    "    chip_df_filt = chip_df.loc[chip_df.tile == current_tile]#.reset_index()\n",
    "    first_chip_id = chip_df_filt.chip_id.iloc[0]\n",
    "    first_chip_index_in_json = chip_ids.index(first_chip_id)\n",
    "    roi = chips['features'][first_chip_index_in_json]['geometry']\n",
    "\n",
    "    search = catalog.search(\n",
    "        collections = ['HLSS30.v2.0'],\n",
    "        intersects = roi,\n",
    "        datetime = '2022-03-01/2022-09-30',\n",
    "    ) \n",
    "    \n",
    "    num_results = search.matched()\n",
    "    item_collection = search.get_all_items()\n",
    "    \n",
    "    tile_name = \"T\" + current_tile\n",
    "    iter_items = 0\n",
    "    for i in tqdm(item_collection ,desc=f\"({tile_iter}/{len(tiles)})\"):\n",
    "        if i.id.split('.')[2] == tile_name:\n",
    "            if i.properties['eo:cloud_cover'] <= cloud_thres:\n",
    "                response = requests.get(i.assets['metadata'].href)\n",
    "                if response.status_code == 200:\n",
    "                    temp_xml = response.text\n",
    "                    temp_xml = xmltodict.parse(temp_xml)\n",
    "                    temp_dict = {\"tile_id\": tile_name, \"cloud_cover\": i.properties['eo:cloud_cover'],\n",
    "                                 \"date\": datetime.datetime.strptime(i.properties['datetime'].split('T')[0], \"%Y-%m-%d\"), \n",
    "                                 \"spatial_cover\": int(temp_xml['Granule']['AdditionalAttributes']['AdditionalAttribute'][3]['Values']['Value']),\n",
    "                                 \"http_links\": {\"B02\": i.assets['B02'].href, \"B03\": i.assets['B03'].href, \"B04\": i.assets['B04'].href,  \"B8A\": i.assets['B8A'].href,\n",
    "                                                \"B11\": i.assets['B11'].href, \"B12\": i.assets['B12'].href, \"Fmask\": i.assets['Fmask']},\n",
    "                                \"s3_links\": {\"B02\": i.assets['B02'].href.replace('https://data.lpdaac.earthdatacloud.nasa.gov/lp-prod-protected/', 's3:/'), \n",
    "                                             \"B03\": i.assets['B03'].href.replace('https://data.lpdaac.earthdatacloud.nasa.gov/lp-prod-protected/', 's3:/'), \n",
    "                                             \"B04\": i.assets['B04'].href.replace('https://data.lpdaac.earthdatacloud.nasa.gov/lp-prod-protected/', 's3:/'), \n",
    "                                             \"B8A\": i.assets['B8A'].href.replace('https://data.lpdaac.earthdatacloud.nasa.gov/lp-prod-protected/', 's3:/'),\n",
    "                                             \"B11\": i.assets['B11'].href.replace('https://data.lpdaac.earthdatacloud.nasa.gov/lp-prod-protected/', 's3:/'),\n",
    "                                             \"B12\": i.assets['B12'].href.replace('https://data.lpdaac.earthdatacloud.nasa.gov/lp-prod-protected/', 's3:/'),\n",
    "                                             \"Fmask\": i.assets['Fmask'].href.replace('https://data.lpdaac.earthdatacloud.nasa.gov/lp-prod-protected/', 's3:/')}}\n",
    "                    tile_list.append(temp_dict)\n",
    "                    iter_items += 1\n",
    "                else: \n",
    "                    assert False, f\"Failed to fetch XML from {i.assets['metadata'].href}. Error code: {response.status_code}\"\n",
    "            \n",
    "    tile_iter += 1\n",
    "    #print(f\"Information for tile {tile_name} is collected, a total of {iter_items} out of {num_results} tiles pass the filter ({tile_iter}/{len(tiles)})\")\n",
    "\n",
    "    \n",
    "tile_df = pd.DataFrame(tile_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7431fc8b-0f64-408b-8500-24a1bae5aa01",
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_df.to_csv(req_path + \"tile_df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "bf8f2617-3d4a-4651-92ba-6d82f4e39f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_df = pd.read_csv(\"/data/requirements/tile_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "dc20013c-a435-46ad-b533-19e5054920d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tile_id</th>\n",
       "      <th>cloud_cover</th>\n",
       "      <th>date</th>\n",
       "      <th>spatial_cover</th>\n",
       "      <th>http_links</th>\n",
       "      <th>s3_links</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T13TDE</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-03-14</td>\n",
       "      <td>25</td>\n",
       "      <td>{'B02': 'https://data.lpdaac.earthdatacloud.na...</td>\n",
       "      <td>{'B02': 's3:/HLSS30.020/HLS.S30.T13TDE.2022073...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T13TDE</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-04-08</td>\n",
       "      <td>25</td>\n",
       "      <td>{'B02': 'https://data.lpdaac.earthdatacloud.na...</td>\n",
       "      <td>{'B02': 's3:/HLSS30.020/HLS.S30.T13TDE.2022098...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T13TDE</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-04-18</td>\n",
       "      <td>25</td>\n",
       "      <td>{'B02': 'https://data.lpdaac.earthdatacloud.na...</td>\n",
       "      <td>{'B02': 's3:/HLSS30.020/HLS.S30.T13TDE.2022108...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T13TDE</td>\n",
       "      <td>3</td>\n",
       "      <td>2022-04-21</td>\n",
       "      <td>99</td>\n",
       "      <td>{'B02': 'https://data.lpdaac.earthdatacloud.na...</td>\n",
       "      <td>{'B02': 's3:/HLSS30.020/HLS.S30.T13TDE.2022111...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T13TDE</td>\n",
       "      <td>2</td>\n",
       "      <td>2022-05-26</td>\n",
       "      <td>99</td>\n",
       "      <td>{'B02': 'https://data.lpdaac.earthdatacloud.na...</td>\n",
       "      <td>{'B02': 's3:/HLSS30.020/HLS.S30.T13TDE.2022146...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>T13TDE</td>\n",
       "      <td>4</td>\n",
       "      <td>2022-06-15</td>\n",
       "      <td>100</td>\n",
       "      <td>{'B02': 'https://data.lpdaac.earthdatacloud.na...</td>\n",
       "      <td>{'B02': 's3:/HLSS30.020/HLS.S30.T13TDE.2022166...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>T13TDE</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-06-27</td>\n",
       "      <td>26</td>\n",
       "      <td>{'B02': 'https://data.lpdaac.earthdatacloud.na...</td>\n",
       "      <td>{'B02': 's3:/HLSS30.020/HLS.S30.T13TDE.2022178...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>T13TDE</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-07-02</td>\n",
       "      <td>26</td>\n",
       "      <td>{'B02': 'https://data.lpdaac.earthdatacloud.na...</td>\n",
       "      <td>{'B02': 's3:/HLSS30.020/HLS.S30.T13TDE.2022183...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>T13TDE</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-07-17</td>\n",
       "      <td>25</td>\n",
       "      <td>{'B02': 'https://data.lpdaac.earthdatacloud.na...</td>\n",
       "      <td>{'B02': 's3:/HLSS30.020/HLS.S30.T13TDE.2022198...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>T13TDE</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-08-06</td>\n",
       "      <td>25</td>\n",
       "      <td>{'B02': 'https://data.lpdaac.earthdatacloud.na...</td>\n",
       "      <td>{'B02': 's3:/HLSS30.020/HLS.S30.T13TDE.2022218...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>T13TDE</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-08-11</td>\n",
       "      <td>26</td>\n",
       "      <td>{'B02': 'https://data.lpdaac.earthdatacloud.na...</td>\n",
       "      <td>{'B02': 's3:/HLSS30.020/HLS.S30.T13TDE.2022223...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>T13TDE</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-09-05</td>\n",
       "      <td>25</td>\n",
       "      <td>{'B02': 'https://data.lpdaac.earthdatacloud.na...</td>\n",
       "      <td>{'B02': 's3:/HLSS30.020/HLS.S30.T13TDE.2022248...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>T13TDE</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-09-18</td>\n",
       "      <td>99</td>\n",
       "      <td>{'B02': 'https://data.lpdaac.earthdatacloud.na...</td>\n",
       "      <td>{'B02': 's3:/HLSS30.020/HLS.S30.T13TDE.2022261...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>T13TDE</td>\n",
       "      <td>5</td>\n",
       "      <td>2022-09-23</td>\n",
       "      <td>99</td>\n",
       "      <td>{'B02': 'https://data.lpdaac.earthdatacloud.na...</td>\n",
       "      <td>{'B02': 's3:/HLSS30.020/HLS.S30.T13TDE.2022266...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>T13TDE</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-09-25</td>\n",
       "      <td>25</td>\n",
       "      <td>{'B02': 'https://data.lpdaac.earthdatacloud.na...</td>\n",
       "      <td>{'B02': 's3:/HLSS30.020/HLS.S30.T13TDE.2022268...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tile_id  cloud_cover        date  spatial_cover  \\\n",
       "0   T13TDE            1  2022-03-14             25   \n",
       "1   T13TDE            0  2022-04-08             25   \n",
       "2   T13TDE            0  2022-04-18             25   \n",
       "3   T13TDE            3  2022-04-21             99   \n",
       "4   T13TDE            2  2022-05-26             99   \n",
       "5   T13TDE            4  2022-06-15            100   \n",
       "6   T13TDE            1  2022-06-27             26   \n",
       "7   T13TDE            1  2022-07-02             26   \n",
       "8   T13TDE            0  2022-07-17             25   \n",
       "9   T13TDE            1  2022-08-06             25   \n",
       "10  T13TDE            1  2022-08-11             26   \n",
       "11  T13TDE            0  2022-09-05             25   \n",
       "12  T13TDE            1  2022-09-18             99   \n",
       "13  T13TDE            5  2022-09-23             99   \n",
       "14  T13TDE            0  2022-09-25             25   \n",
       "\n",
       "                                           http_links  \\\n",
       "0   {'B02': 'https://data.lpdaac.earthdatacloud.na...   \n",
       "1   {'B02': 'https://data.lpdaac.earthdatacloud.na...   \n",
       "2   {'B02': 'https://data.lpdaac.earthdatacloud.na...   \n",
       "3   {'B02': 'https://data.lpdaac.earthdatacloud.na...   \n",
       "4   {'B02': 'https://data.lpdaac.earthdatacloud.na...   \n",
       "5   {'B02': 'https://data.lpdaac.earthdatacloud.na...   \n",
       "6   {'B02': 'https://data.lpdaac.earthdatacloud.na...   \n",
       "7   {'B02': 'https://data.lpdaac.earthdatacloud.na...   \n",
       "8   {'B02': 'https://data.lpdaac.earthdatacloud.na...   \n",
       "9   {'B02': 'https://data.lpdaac.earthdatacloud.na...   \n",
       "10  {'B02': 'https://data.lpdaac.earthdatacloud.na...   \n",
       "11  {'B02': 'https://data.lpdaac.earthdatacloud.na...   \n",
       "12  {'B02': 'https://data.lpdaac.earthdatacloud.na...   \n",
       "13  {'B02': 'https://data.lpdaac.earthdatacloud.na...   \n",
       "14  {'B02': 'https://data.lpdaac.earthdatacloud.na...   \n",
       "\n",
       "                                             s3_links  \n",
       "0   {'B02': 's3:/HLSS30.020/HLS.S30.T13TDE.2022073...  \n",
       "1   {'B02': 's3:/HLSS30.020/HLS.S30.T13TDE.2022098...  \n",
       "2   {'B02': 's3:/HLSS30.020/HLS.S30.T13TDE.2022108...  \n",
       "3   {'B02': 's3:/HLSS30.020/HLS.S30.T13TDE.2022111...  \n",
       "4   {'B02': 's3:/HLSS30.020/HLS.S30.T13TDE.2022146...  \n",
       "5   {'B02': 's3:/HLSS30.020/HLS.S30.T13TDE.2022166...  \n",
       "6   {'B02': 's3:/HLSS30.020/HLS.S30.T13TDE.2022178...  \n",
       "7   {'B02': 's3:/HLSS30.020/HLS.S30.T13TDE.2022183...  \n",
       "8   {'B02': 's3:/HLSS30.020/HLS.S30.T13TDE.2022198...  \n",
       "9   {'B02': 's3:/HLSS30.020/HLS.S30.T13TDE.2022218...  \n",
       "10  {'B02': 's3:/HLSS30.020/HLS.S30.T13TDE.2022223...  \n",
       "11  {'B02': 's3:/HLSS30.020/HLS.S30.T13TDE.2022248...  \n",
       "12  {'B02': 's3:/HLSS30.020/HLS.S30.T13TDE.2022261...  \n",
       "13  {'B02': 's3:/HLSS30.020/HLS.S30.T13TDE.2022266...  \n",
       "14  {'B02': 's3:/HLSS30.020/HLS.S30.T13TDE.2022268...  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tile_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "59767242-2158-4cd7-bdc7-1719207f0552",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tile_id</th>\n",
       "      <th>cloud_cover</th>\n",
       "      <th>date</th>\n",
       "      <th>spatial_cover</th>\n",
       "      <th>http_links</th>\n",
       "      <th>s3_links</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T13TDE</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-03-14</td>\n",
       "      <td>25</td>\n",
       "      <td>{'B02': 'https://data.lpdaac.earthdatacloud.na...</td>\n",
       "      <td>{'B02': 's3:/HLSS30.020/HLS.S30.T13TDE.2022073...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T13TDE</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-04-08</td>\n",
       "      <td>25</td>\n",
       "      <td>{'B02': 'https://data.lpdaac.earthdatacloud.na...</td>\n",
       "      <td>{'B02': 's3:/HLSS30.020/HLS.S30.T13TDE.2022098...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T13TDE</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-04-18</td>\n",
       "      <td>25</td>\n",
       "      <td>{'B02': 'https://data.lpdaac.earthdatacloud.na...</td>\n",
       "      <td>{'B02': 's3:/HLSS30.020/HLS.S30.T13TDE.2022108...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T13TDE</td>\n",
       "      <td>3</td>\n",
       "      <td>2022-04-21</td>\n",
       "      <td>99</td>\n",
       "      <td>{'B02': 'https://data.lpdaac.earthdatacloud.na...</td>\n",
       "      <td>{'B02': 's3:/HLSS30.020/HLS.S30.T13TDE.2022111...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T13TDE</td>\n",
       "      <td>2</td>\n",
       "      <td>2022-05-26</td>\n",
       "      <td>99</td>\n",
       "      <td>{'B02': 'https://data.lpdaac.earthdatacloud.na...</td>\n",
       "      <td>{'B02': 's3:/HLSS30.020/HLS.S30.T13TDE.2022146...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>T13TDE</td>\n",
       "      <td>4</td>\n",
       "      <td>2022-06-15</td>\n",
       "      <td>100</td>\n",
       "      <td>{'B02': 'https://data.lpdaac.earthdatacloud.na...</td>\n",
       "      <td>{'B02': 's3:/HLSS30.020/HLS.S30.T13TDE.2022166...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>T13TDE</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-06-27</td>\n",
       "      <td>26</td>\n",
       "      <td>{'B02': 'https://data.lpdaac.earthdatacloud.na...</td>\n",
       "      <td>{'B02': 's3:/HLSS30.020/HLS.S30.T13TDE.2022178...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>T13TDE</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-07-02</td>\n",
       "      <td>26</td>\n",
       "      <td>{'B02': 'https://data.lpdaac.earthdatacloud.na...</td>\n",
       "      <td>{'B02': 's3:/HLSS30.020/HLS.S30.T13TDE.2022183...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>T13TDE</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-07-17</td>\n",
       "      <td>25</td>\n",
       "      <td>{'B02': 'https://data.lpdaac.earthdatacloud.na...</td>\n",
       "      <td>{'B02': 's3:/HLSS30.020/HLS.S30.T13TDE.2022198...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>T13TDE</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-08-06</td>\n",
       "      <td>25</td>\n",
       "      <td>{'B02': 'https://data.lpdaac.earthdatacloud.na...</td>\n",
       "      <td>{'B02': 's3:/HLSS30.020/HLS.S30.T13TDE.2022218...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>T13TDE</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-08-11</td>\n",
       "      <td>26</td>\n",
       "      <td>{'B02': 'https://data.lpdaac.earthdatacloud.na...</td>\n",
       "      <td>{'B02': 's3:/HLSS30.020/HLS.S30.T13TDE.2022223...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>T13TDE</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-09-05</td>\n",
       "      <td>25</td>\n",
       "      <td>{'B02': 'https://data.lpdaac.earthdatacloud.na...</td>\n",
       "      <td>{'B02': 's3:/HLSS30.020/HLS.S30.T13TDE.2022248...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>T13TDE</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-09-18</td>\n",
       "      <td>99</td>\n",
       "      <td>{'B02': 'https://data.lpdaac.earthdatacloud.na...</td>\n",
       "      <td>{'B02': 's3:/HLSS30.020/HLS.S30.T13TDE.2022261...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>T13TDE</td>\n",
       "      <td>5</td>\n",
       "      <td>2022-09-23</td>\n",
       "      <td>99</td>\n",
       "      <td>{'B02': 'https://data.lpdaac.earthdatacloud.na...</td>\n",
       "      <td>{'B02': 's3:/HLSS30.020/HLS.S30.T13TDE.2022266...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>T13TDE</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-09-25</td>\n",
       "      <td>25</td>\n",
       "      <td>{'B02': 'https://data.lpdaac.earthdatacloud.na...</td>\n",
       "      <td>{'B02': 's3:/HLSS30.020/HLS.S30.T13TDE.2022268...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tile_id  cloud_cover        date  spatial_cover  \\\n",
       "0   T13TDE            1  2022-03-14             25   \n",
       "1   T13TDE            0  2022-04-08             25   \n",
       "2   T13TDE            0  2022-04-18             25   \n",
       "3   T13TDE            3  2022-04-21             99   \n",
       "4   T13TDE            2  2022-05-26             99   \n",
       "5   T13TDE            4  2022-06-15            100   \n",
       "6   T13TDE            1  2022-06-27             26   \n",
       "7   T13TDE            1  2022-07-02             26   \n",
       "8   T13TDE            0  2022-07-17             25   \n",
       "9   T13TDE            1  2022-08-06             25   \n",
       "10  T13TDE            1  2022-08-11             26   \n",
       "11  T13TDE            0  2022-09-05             25   \n",
       "12  T13TDE            1  2022-09-18             99   \n",
       "13  T13TDE            5  2022-09-23             99   \n",
       "14  T13TDE            0  2022-09-25             25   \n",
       "\n",
       "                                           http_links  \\\n",
       "0   {'B02': 'https://data.lpdaac.earthdatacloud.na...   \n",
       "1   {'B02': 'https://data.lpdaac.earthdatacloud.na...   \n",
       "2   {'B02': 'https://data.lpdaac.earthdatacloud.na...   \n",
       "3   {'B02': 'https://data.lpdaac.earthdatacloud.na...   \n",
       "4   {'B02': 'https://data.lpdaac.earthdatacloud.na...   \n",
       "5   {'B02': 'https://data.lpdaac.earthdatacloud.na...   \n",
       "6   {'B02': 'https://data.lpdaac.earthdatacloud.na...   \n",
       "7   {'B02': 'https://data.lpdaac.earthdatacloud.na...   \n",
       "8   {'B02': 'https://data.lpdaac.earthdatacloud.na...   \n",
       "9   {'B02': 'https://data.lpdaac.earthdatacloud.na...   \n",
       "10  {'B02': 'https://data.lpdaac.earthdatacloud.na...   \n",
       "11  {'B02': 'https://data.lpdaac.earthdatacloud.na...   \n",
       "12  {'B02': 'https://data.lpdaac.earthdatacloud.na...   \n",
       "13  {'B02': 'https://data.lpdaac.earthdatacloud.na...   \n",
       "14  {'B02': 'https://data.lpdaac.earthdatacloud.na...   \n",
       "\n",
       "                                             s3_links  \n",
       "0   {'B02': 's3:/HLSS30.020/HLS.S30.T13TDE.2022073...  \n",
       "1   {'B02': 's3:/HLSS30.020/HLS.S30.T13TDE.2022098...  \n",
       "2   {'B02': 's3:/HLSS30.020/HLS.S30.T13TDE.2022108...  \n",
       "3   {'B02': 's3:/HLSS30.020/HLS.S30.T13TDE.2022111...  \n",
       "4   {'B02': 's3:/HLSS30.020/HLS.S30.T13TDE.2022146...  \n",
       "5   {'B02': 's3:/HLSS30.020/HLS.S30.T13TDE.2022166...  \n",
       "6   {'B02': 's3:/HLSS30.020/HLS.S30.T13TDE.2022178...  \n",
       "7   {'B02': 's3:/HLSS30.020/HLS.S30.T13TDE.2022183...  \n",
       "8   {'B02': 's3:/HLSS30.020/HLS.S30.T13TDE.2022198...  \n",
       "9   {'B02': 's3:/HLSS30.020/HLS.S30.T13TDE.2022218...  \n",
       "10  {'B02': 's3:/HLSS30.020/HLS.S30.T13TDE.2022223...  \n",
       "11  {'B02': 's3:/HLSS30.020/HLS.S30.T13TDE.2022248...  \n",
       "12  {'B02': 's3:/HLSS30.020/HLS.S30.T13TDE.2022261...  \n",
       "13  {'B02': 's3:/HLSS30.020/HLS.S30.T13TDE.2022266...  \n",
       "14  {'B02': 's3:/HLSS30.020/HLS.S30.T13TDE.2022268...  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tile_df[tile_df.tile_id == \"T13TDE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ca6941b5-9241-4626-bbec-56118c91ba95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(tile_df.tile_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "ca1769c9-15b2-484b-b429-7df0434d6f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spatial_filtering (dataframe):\n",
    "    \"\"\"\n",
    "        Using spatial coverage percentage to filter chips\n",
    "\n",
    "        Args:\n",
    "            dataframe: A pandas dataframe that generated previously\n",
    "    \"\"\"\n",
    "    cover_list = [100, 90, 80, 70, 60, 50]\n",
    "    tile_list_ft = []\n",
    "    tile_list = dataframe.tile_id.unique().tolist()\n",
    "    \n",
    "    for tile in tqdm(tile_list):\n",
    "        temp_df = dataframe[dataframe.tile_id == tile]\n",
    "        for cover_pct in cover_list:\n",
    "            \n",
    "            temp_df_filtered = temp_df[temp_df.spatial_cover >= cover_pct]\n",
    "            if len(temp_df_filtered) >= 3:\n",
    "                for i in range(len(temp_df_filtered)):\n",
    "                    tile_list_ft.append(temp_df_filtered.iloc[i])\n",
    "                break\n",
    "    \n",
    "    tile_df_filtered = pd.DataFrame(tile_list_ft)\n",
    "    return tile_df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "1bd8234b-6750-4a4f-9e57-eb6144331454",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 216.27it/s]\n"
     ]
    }
   ],
   "source": [
    "# check_spatial_cover(tile_df, 90)\n",
    "cover_df = spatial_filtering(tile_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "2b02b75c-55cc-43a1-a6d9-913771eb3043",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_scenes(dataframe):\n",
    "    select_tiles = []\n",
    "    tile_list = dataframe.tile_id.unique().tolist()\n",
    "\n",
    "    for tile in tqdm(tile_list):\n",
    "        temp_df = dataframe[dataframe.tile_id == tile].sort_values('date').reset_index(drop=True)\n",
    "        select_tiles.extend([temp_df.iloc[0], temp_df.iloc[len(temp_df) // 2], temp_df.iloc[-1]])\n",
    "\n",
    "    return pd.DataFrame(select_tiles).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "b23da90c-e163-45fc-9ea6-ef8e3130bc95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 597.91it/s]\n"
     ]
    }
   ],
   "source": [
    "selected_tiles = select_scenes(cover_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f7caff71-b5be-4d54-be44-a0938bd55159",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tile_id</th>\n",
       "      <th>cloud_cover</th>\n",
       "      <th>date</th>\n",
       "      <th>spatial_cover</th>\n",
       "      <th>http_links</th>\n",
       "      <th>s3_links</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T13TDE</td>\n",
       "      <td>3</td>\n",
       "      <td>2022-04-21</td>\n",
       "      <td>99</td>\n",
       "      <td>{'B02': 'https://data.lpdaac.earthdatacloud.na...</td>\n",
       "      <td>{'B02': 's3:/HLSS30.020/HLS.S30.T13TDE.2022111...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T13TDE</td>\n",
       "      <td>4</td>\n",
       "      <td>2022-06-15</td>\n",
       "      <td>100</td>\n",
       "      <td>{'B02': 'https://data.lpdaac.earthdatacloud.na...</td>\n",
       "      <td>{'B02': 's3:/HLSS30.020/HLS.S30.T13TDE.2022166...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T13TDE</td>\n",
       "      <td>5</td>\n",
       "      <td>2022-09-23</td>\n",
       "      <td>99</td>\n",
       "      <td>{'B02': 'https://data.lpdaac.earthdatacloud.na...</td>\n",
       "      <td>{'B02': 's3:/HLSS30.020/HLS.S30.T13TDE.2022266...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  tile_id  cloud_cover        date  spatial_cover  \\\n",
       "0  T13TDE            3  2022-04-21             99   \n",
       "1  T13TDE            4  2022-06-15            100   \n",
       "2  T13TDE            5  2022-09-23             99   \n",
       "\n",
       "                                          http_links  \\\n",
       "0  {'B02': 'https://data.lpdaac.earthdatacloud.na...   \n",
       "1  {'B02': 'https://data.lpdaac.earthdatacloud.na...   \n",
       "2  {'B02': 'https://data.lpdaac.earthdatacloud.na...   \n",
       "\n",
       "                                            s3_links  \n",
       "0  {'B02': 's3:/HLSS30.020/HLS.S30.T13TDE.2022111...  \n",
       "1  {'B02': 's3:/HLSS30.020/HLS.S30.T13TDE.2022166...  \n",
       "2  {'B02': 's3:/HLSS30.020/HLS.S30.T13TDE.2022266...  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_tiles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "264fae95-6630-46e0-bd05-83f866cd7a41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tile_id</th>\n",
       "      <th>cloud_cover</th>\n",
       "      <th>date</th>\n",
       "      <th>spatial_cover</th>\n",
       "      <th>http_links</th>\n",
       "      <th>s3_links</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T13TDE</td>\n",
       "      <td>3</td>\n",
       "      <td>2022-04-21</td>\n",
       "      <td>99</td>\n",
       "      <td>{'B02': 'https://data.lpdaac.earthdatacloud.na...</td>\n",
       "      <td>{'B02': 's3:/HLSS30.020/HLS.S30.T13TDE.2022111...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T13TDE</td>\n",
       "      <td>4</td>\n",
       "      <td>2022-06-15</td>\n",
       "      <td>100</td>\n",
       "      <td>{'B02': 'https://data.lpdaac.earthdatacloud.na...</td>\n",
       "      <td>{'B02': 's3:/HLSS30.020/HLS.S30.T13TDE.2022166...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T13TDE</td>\n",
       "      <td>5</td>\n",
       "      <td>2022-09-23</td>\n",
       "      <td>99</td>\n",
       "      <td>{'B02': 'https://data.lpdaac.earthdatacloud.na...</td>\n",
       "      <td>{'B02': 's3:/HLSS30.020/HLS.S30.T13TDE.2022266...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  tile_id  cloud_cover        date  spatial_cover  \\\n",
       "0  T13TDE            3  2022-04-21             99   \n",
       "1  T13TDE            4  2022-06-15            100   \n",
       "2  T13TDE            5  2022-09-23             99   \n",
       "\n",
       "                                          http_links  \\\n",
       "0  {'B02': 'https://data.lpdaac.earthdatacloud.na...   \n",
       "1  {'B02': 'https://data.lpdaac.earthdatacloud.na...   \n",
       "2  {'B02': 'https://data.lpdaac.earthdatacloud.na...   \n",
       "\n",
       "                                            s3_links  \n",
       "0  {'B02': 's3:/HLSS30.020/HLS.S30.T13TDE.2022111...  \n",
       "1  {'B02': 's3:/HLSS30.020/HLS.S30.T13TDE.2022166...  \n",
       "2  {'B02': 's3:/HLSS30.020/HLS.S30.T13TDE.2022266...  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_tiles[selected_tiles.tile_id == \"T13TDE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a8a9fe-b3c5-4187-995d-52f478db67f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# selected_tiles.iloc[0].s3_links['Fmask'].split(\"/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "e024b411-d60b-4f5a-bb65-3ff960363646",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"{'B02': 's3:/HLSS30.020/HLS.S30.T13TDE.2022111T174859.v2.0/HLS.S30.T13TDE.2022111T174859.v2.0.B02.tif', 'B03': 's3:/HLSS30.020/HLS.S30.T13TDE.2022111T174859.v2.0/HLS.S30.T13TDE.2022111T174859.v2.0.B03.tif', 'B04': 's3:/HLSS30.020/HLS.S30.T13TDE.2022111T174859.v2.0/HLS.S30.T13TDE.2022111T174859.v2.0.B04.tif', 'B8A': 's3:/HLSS30.020/HLS.S30.T13TDE.2022111T174859.v2.0/HLS.S30.T13TDE.2022111T174859.v2.0.B8A.tif', 'B11': 's3:/HLSS30.020/HLS.S30.T13TDE.2022111T174859.v2.0/HLS.S30.T13TDE.2022111T174859.v2.0.B11.tif', 'B12': 's3:/HLSS30.020/HLS.S30.T13TDE.2022111T174859.v2.0/HLS.S30.T13TDE.2022111T174859.v2.0.B12.tif', 'Fmask': 's3:/HLSS30.020/HLS.S30.T13TDE.2022111T174859.v2.0/HLS.S30.T13TDE.2022111T174859.v2.0.Fmask.tif'}\""
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1 = selected_tiles.iloc[0].s3_links\n",
    "test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0102a6-f96b-431d-ba64-baade3e97767",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test1['B02']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "6f14f5ab-fac6-4143-90ca-a8cc880bc674",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_tiles.to_csv(req_path + \"selected_tiles.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "38664ffa-cd57-4f1b-a7f3-cdb63554ad94",
   "metadata": {},
   "outputs": [],
   "source": [
    "urs = 'urs.earthdata.nasa.gov'    # Earthdata URL endpoint for authentication\n",
    "prompts = ['Enter NASA Earthdata Login Username: ',\n",
    "           'Enter NASA Earthdata Login Password: ']\n",
    "\n",
    "# Determine the OS (Windows machines usually use an '_netrc' file)\n",
    "netrc_name = \"_netrc\" if system()==\"Windows\" else \".netrc\"\n",
    "\n",
    "# Determine if netrc file exists, and if so, if it includes NASA Earthdata Login Credentials\n",
    "try:\n",
    "    netrcDir = os.path.expanduser(f\"~/{netrc_name}\")\n",
    "    netrc(netrcDir).authenticators(urs)[0]\n",
    "\n",
    "# Below, create a netrc file and prompt user for NASA Earthdata Login Username and Password\n",
    "except FileNotFoundError:\n",
    "    homeDir = os.path.expanduser(\"~\")\n",
    "    Popen('touch {0}{2} | echo machine {1} >> {0}{2}'.format(homeDir + os.sep, urs, netrc_name), shell=True)\n",
    "    Popen('echo login {} >> {}{}'.format(getpass(prompt=prompts[0]), homeDir + os.sep, netrc_name), shell=True)\n",
    "    Popen('echo \\'password {} \\'>> {}{}'.format(getpass(prompt=prompts[1]), homeDir + os.sep, netrc_name), shell=True)\n",
    "    # Set restrictive permissions\n",
    "    Popen('chmod 0600 {0}{1}'.format(homeDir + os.sep, netrc_name), shell=True)\n",
    "\n",
    "    # Determine OS and edit netrc file if it exists but is not set up for NASA Earthdata Login\n",
    "except TypeError:\n",
    "    homeDir = os.path.expanduser(\"~\")\n",
    "    Popen('echo machine {1} >> {0}{2}'.format(homeDir + os.sep, urs, netrc_name), shell=True)\n",
    "    Popen('echo login {} >> {}{}'.format(getpass(prompt=prompts[0]), homeDir + os.sep, netrc_name), shell=True)\n",
    "    Popen('echo \\'password {} \\'>> {}{}'.format(getpass(prompt=prompts[1]), homeDir + os.sep, netrc_name), shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "fadfd603-27d5-4354-912a-f5f7ebdb799f",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_cred_endpoint = 'https://data.lpdaac.earthdatacloud.nasa.gov/s3credentials'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "23b5232e-2040-40de-8915-875c13925ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_temp_creds():\n",
    "    temp_creds_url = s3_cred_endpoint\n",
    "    return requests.get(temp_creds_url).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886b408b-2ee6-4f5c-91bc-1c73aec98cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp_creds_req = get_temp_creds()\n",
    "#temp_creds_req                      # !!! BEWARE, removing the # on this line will print your temporary S3 credentials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899bcf98-4239-48d9-917f-917191d3f974",
   "metadata": {},
   "outputs": [],
   "source": [
    "session = boto3.Session(aws_access_key_id=temp_creds_req['accessKeyId'], \n",
    "                        aws_secret_access_key=temp_creds_req['secretAccessKey'],\n",
    "                        aws_session_token=temp_creds_req['sessionToken'],\n",
    "                        region_name='us-west-2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eadb6ff-5b4a-4579-bbef-a3a3e2b8212a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rio_env = rio.Env(AWSSession(session),\n",
    "                  GDAL_DISABLE_READDIR_ON_OPEN='EMPTY_DIR',\n",
    "                  GDAL_HTTP_COOKIEFILE=os.path.expanduser('~/cookies.txt'),\n",
    "                  GDAL_HTTP_COOKIEJAR=os.path.expanduser('~/cookies.txt'))\n",
    "rio_env.__enter__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "4b6b5fec-57ee-4afa-9715-c5231e1322b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tile_download(table, boto3_session):\n",
    "    bucket = boto3_session\n",
    "    info_list = []\n",
    "    bands = [\"B02\",\"B03\",\"B04\",\"B8A\",\"B11\",\"B12\",\"Fmask\"]\n",
    "    accept_tiles = np.unique(table.tile_id)\n",
    "    for tile in tqdm(accept_tiles):\n",
    "        temp_tb = table[table.tile_id == tile]\n",
    "        for i in range(3):\n",
    "            bands_dict = temp_tb.iloc[i].s3_links\n",
    "            for band in bands:\n",
    "                temp_key = bands_dict[band].replace(\"s3:/\", \"\")\n",
    "                temp_sav_path = f\"/data/tiles/{bands_dict[band].split('/')[2]}/{bands_dict[band].split('/')[3]}\"\n",
    "                os.makedirs(f\"/data/tiles/{bands_dict[band].split('/')[2]}\", exist_ok=True)\n",
    "                if not Path(temp_sav_path).is_file():\n",
    "                    boto3_session.resource('s3').Bucket('lp-prod-protected').download_file(Key = temp_key, Filename = temp_sav_path)\n",
    "            temp_dict = {\"tile\":tile, \"timestep\":i, \"date\":temp_tb.iloc[i].date, \"save_path\":f\"/data/tiles/{bands_dict[band].split('/')[2]}/\", \"filename\":bands_dict[\"B02\"].split('/')[3].replace(\".B02.tif\",\"\")}\n",
    "            info_list.append(temp_dict)\n",
    "    return pd.DataFrame(info_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e5a786-2fc1-48de-9931-b2cbb7ccef67",
   "metadata": {},
   "outputs": [],
   "source": [
    "track_df = tile_download(selected_tiles, session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d8a34d-61e6-42ca-a71e-7e85a2fd67d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "track_df.to_csv(req_path + \"track_df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed22b30a-5958-46f9-9763-4bb7014dcd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "track_df[temp_df.tile == \"T13TDE\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba97cf62-7517-4488-84fe-9102039c1e3e",
   "metadata": {},
   "source": [
    "#############################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3686898-7d99-48d6-bf93-2b013dbfc8a8",
   "metadata": {},
   "source": [
    "reproject selected cog to cdl crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45baa42e-6c56-43ff-a543-df2da87574c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reproject_hls_to_cdl(scene_folder,\n",
    "                         bands = [\"B02\", \"B03\", \"B04\", \"B08A\",\"B11\",\"B12\", \"Fmask\"],\n",
    "                         cdl_file = \"/data/2021_30m_cdls_clipped.tif\"):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function receives the path to a folder that contains all GeoTIFF files (for various bands)\n",
    "    of a HLS scene, and reprojects those to the target CDL CRS and grid. \n",
    "    \n",
    "    Assumptions:\n",
    "    - scene_folder has a file structure like: \".../<scene_id>/<scene_id>.<band_id>.tiff\n",
    "    - scene_folder should not have a \"/\" at the end\n",
    "    \n",
    "    Inputs:\n",
    "    - scene_folder: is the path to the folder that contains HLS GeoTIFF files for all bands of HLS\n",
    "    - bands: list of bands of HLS that should be reprojected (default is all bands)\n",
    "    - cdl_file: contains the path to the clipped CDL GeoTIFF file\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    for band in bands:\n",
    "        xds = xarray.open_rasterio(f\"{scene_folder}/{scene_folder.split('/')[-1]}.{band}.tif\")\n",
    "        cdl = xarray.open_rasterio(cdl_file)\n",
    "        xds_new = xds.rio.reproject_match(cdl, resampling = Resampling.bilinear)\n",
    "        xds_new.rio.to_raster(raster_path = f\"{scene_folder}/{scene_folder.split('/')[-1]}.{band}.5070.tif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2523362-10fa-48fa-bfea-1ee2198279b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for tile in tiles_to_reproject:\n",
    "    selected_images = glob(tif_dir + '*')\n",
    "    #print(selected_images)\n",
    "    selected_images = [image for image in selected_images if image[19:24] == tile]\n",
    "    print(selected_images)\n",
    "        ## reproject to cdl\n",
    "    for k in range(len(selected_images)):\n",
    "        image_id = selected_images[k]\n",
    "        print(image_id)\n",
    "        reproject_hls_to_cdl(image_id)\n",
    "    tile_tracker = pd.read_csv(tile_tracker_csv)\n",
    "    tile_tracker.loc[tile_tracker.tile == tile , 'tif_reproject'] = True\n",
    "    tile_tracker.to_csv(tile_tracker_csv, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c184a355-0016-4627-a3ec-4ccaf5c5eb2c",
   "metadata": {},
   "source": [
    "chipping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebd925c-abe4-4461-b2be-1bb28f05a46d",
   "metadata": {},
   "outputs": [],
   "source": [
    " def check_qa(qa_path, shape,  valid_qa = [0, 4, 32, 36, 64, 68, 96, 100, 128, 132, 160, 164, 192, 196, 224, 228]):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function receives a path to a qa file, and a geometry. It clips the QA file to the geometry. \n",
    "    It returns the number of valid QA pixels in the geometry, and the clipped values.\n",
    "    \n",
    "    Assumptions: The valid_qa values are taken from Ben Mack's post:\n",
    "    https://benmack.github.io/nasa_hls/build/html/tutorials/Working_with_HLS_datasets_and_nasa_hls.html\n",
    "    \n",
    "    Inputs:\n",
    "    - qa_path: full path to reprojected QA tif file\n",
    "    - shape: 'geometry' property of single polygon feature read by fiona\n",
    "    - valid_qa: list of integer values that are 'valid' for QA band.\n",
    "    \n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    with rasterio.open(qa_path) as src:\n",
    "        out_image, out_transform = rasterio.mask.mask(src, shape, crop=True)\n",
    "      #  print(out_image.shape)\n",
    "        vals = out_image.flatten()\n",
    "        unique, counts = np.unique(vals, return_counts=True)\n",
    "        qa_df = pd.DataFrame({\"qa_val\" : unique, \"counts\" : counts})\n",
    "        qa_df\n",
    "        qa_df[~ qa_df.qa_val.isin(valid_qa)].sort_values(['counts'], ascending = False)\n",
    "        qa_df['pct'] = (100 *qa_df['counts'])/(224.0 * 224.0)\n",
    "        \n",
    "        bad_qa = qa_df[~ qa_df.qa_val.isin(valid_qa)].sort_values(['counts'], ascending = False)\n",
    "        if len(bad_qa) > 0:\n",
    "            highest_invalid_percent = bad_qa.pct.tolist()[0]\n",
    "        else: \n",
    "            highest_invalid_percent = 0\n",
    "        #ncell = len(vals)\n",
    "        valid_count = sum(x in valid_qa for x in vals)\n",
    "        return(valid_count, highest_invalid_percent, out_image[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936452c3-5c5e-48f1-aa49-5d203e71f0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## set up CDL reclass\n",
    "cdl_class_df = pd.read_csv(cdl_reclass_csv)\n",
    "crop_dict = dict(zip(cdl_class_df.CDL_val, cdl_class_df.new_class_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc29d10-8078-46be-b947-b3310ca4b782",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_reclass(x):\n",
    "    ## binary reclass\n",
    "    crop_classes = [1,2,3,4,5,6,10,11,12,13,14,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,66,67,68,69,70,71,72,74,75,76,77,92,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,236,237,238,240,241,242,243,244,245,246,247,248,249,250,254]\n",
    "    return(crop_classes.count(x))\n",
    "\n",
    "c_rcl = np.vectorize(crop_reclass)\n",
    "\n",
    "\n",
    "def crop_multi(x):\n",
    "    return(crop_dict[x])\n",
    "\n",
    "c_multi = np.vectorize(crop_multi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2cf5e9-7e66-4b84-872e-b8e7428fadac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_chip(chip_id, \n",
    "                 chip_tile,\n",
    "                 shape,\n",
    "                 track_csv,\n",
    "                 bands = [\"B02\", \"B03\", \"B04\", \"B8A\", \"B11\", \"B12\"]):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function receives a chip id, HLS tile, chip geometry, and a list of bands to process. \n",
    "    \n",
    "    Assumptions:\n",
    "    \n",
    "    Inputs:\n",
    "    - chip_id: string of chip id, e.g. '000_001'\n",
    "    - chip_tile: string of HLS tile , e.g. '15ABC'\n",
    "    - shape: 'geometry' property of single polygon feature read by fiona\n",
    "    \n",
    "    The function writes out a multi-date TIF containing the bands for each of the three image dates for an HLS tile. \n",
    "    The function writes out a multi-date TIF containing the QA bands of each date.\n",
    "    The function writes out a chipped version of CDL. \n",
    "    The function calls check_qa(), which makes assumptions about what QA pixels are valid.\n",
    "    The function returns the number of valid QA pixels at each date, as a tuple.\n",
    "    \n",
    "    \"\"\"\n",
    "    ## get reprojected image paths\n",
    "    tile_info_df = track_csv[track_csv.tile == chip_tile]\n",
    "    \n",
    "    # selected_image_folders = sorted(glob(f'/data/tif/*T{chip_tile}*'))\n",
    "    selected_image_folders = tile_info_df.save_path.to_list()\n",
    "   # print(selected_image_folders)\n",
    "    \n",
    "    assert len(selected_image_folders) == 3\n",
    "    \n",
    "    # first_image_date = selected_image_folders[0][25:32]\n",
    "    # second_image_date = selected_image_folders[1][25:32]\n",
    "    # third_image_date = selected_image_folders[2][25:32]\n",
    "                     \n",
    "    first_image_date = tile_info_df.iloc[0].date\n",
    "    second_image_date = tile_info_df.iloc[1].date\n",
    "    third_image_date = tile_info_df.iloc[2].date\n",
    "    \n",
    "    # first_date_images = sorted(glob(selected_image_folders[0] + '/*.5070.tif')) \n",
    "    # first_date_qa = [x for x in first_date_images if '.QA.' in x][0]\n",
    "    # first_date_images.remove(first_date_qa)\n",
    "\n",
    "    # second_date_images = sorted(glob(selected_image_folders[1] + '/*.5070.tif'))\n",
    "    # second_date_qa = [x for x in second_date_images if '.QA.' in x][0]\n",
    "    # second_date_images.remove(second_date_qa)\n",
    "    \n",
    "    # third_date_images = sorted(glob(selected_image_folders[2] + '/*.5070.tif'))\n",
    "    # third_date_qa = [x for x in third_date_images if '.QA.' in x][0]\n",
    "    # third_date_images.remove(third_date_qa)\n",
    "    # all_date_images = first_date_images + second_date_images + third_date_images\n",
    "\n",
    "    all_date_images = []\n",
    "    all_date_qa = []\n",
    "                     \n",
    "    for i in range(3):\n",
    "        for band in bands:\n",
    "            all_date_images.append(tile_info_df.iloc[i].save_path + f\"{tile_info_df.iloc[i].filename}.{band}.tif\")\n",
    "        all_date_qa.append(tile_info_df.iloc[i].save_path + f\"{tile_info_df.iloc[i].filename}.Fmask.tif\")\n",
    "    \n",
    "    # print(all_date_images)\n",
    "    # print(len(all_date_images))\n",
    "\n",
    "\n",
    "    # valid_first, bad_pct_first, qa_first = check_qa(first_date_qa, shape)\n",
    "    # valid_second, bad_pct_second, qa_second = check_qa(second_date_qa, shape)\n",
    "    # valid_third, bad_pct_third, qa_third = check_qa(third_date_qa, shape)\n",
    "    print(all_date_qa[0:2])\n",
    "    valid_first, bad_pct_first, qa_first = check_qa(all_date_qa[0], shape)\n",
    "    valid_second, bad_pct_second, qa_second = check_qa(all_date_qa[1], shape)\n",
    "    valid_third, bad_pct_third, qa_third = check_qa(all_date_qa[2], shape)\n",
    "    \n",
    "    qa_bands = []\n",
    "    qa_bands.append(qa_first)\n",
    "    qa_bands.append(qa_second)\n",
    "    qa_bands.append(qa_third)\n",
    "    qa_bands = np.array(qa_bands).astype(np.int16)\n",
    "    \n",
    "    # print(qa_bands.shape)\n",
    "    # print(first_date_qa)\n",
    "    assert len(all_date_images) == 3 * len(bands)\n",
    "    \n",
    "    out_bands = []\n",
    "    \n",
    "    for img in all_date_images:\n",
    "        with rasterio.open(img) as src:\n",
    "            out_image, out_transform = rasterio.mask.mask(src, shape, crop=True)\n",
    "            out_meta = src.meta\n",
    "            out_bands.append(out_image[0])\n",
    "    \n",
    "    out_bands = np.array(out_bands)\n",
    "    # print(out_bands.shape)\n",
    "    # print(out_image.shape)\n",
    "\n",
    "    out_meta.update({\"driver\": \"GTiff\",\n",
    "                     \"height\": out_bands.shape[1],\n",
    "                     \"width\": out_bands.shape[2],\n",
    "                     \"count\": out_bands.shape[0],\n",
    "                     \"transform\": out_transform})\n",
    "    \n",
    "    # get NA count for HLS\n",
    "    na_count = sum(out_bands.flatten() == -1000)\n",
    "    \n",
    "    # reclass negative HLS values to 0\n",
    "    out_bands = np.clip(out_bands, 0, None)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # write HLS chip to 'chips'\n",
    "    with rasterio.open(chip_dir + \"chip_\" + str(chip_id) + \"_merged.tif\", \"w\", **out_meta) as dest:\n",
    "        dest.write(out_bands)\n",
    "    # # write HLS chip to 'chips_binary'\n",
    "    # with rasterio.open(chip_dir_binary + \"chip_\" + str(chip_id) + \"_merged.tif\", \"w\", **out_meta) as dest:\n",
    "    #     dest.write(out_bands)\n",
    "    # # write HLS chip to 'chips_multi'\n",
    "    # with rasterio.open(chip_dir_multi + \"chip_\" + str(chip_id) + \"_merged.tif\", \"w\", **out_meta) as dest:\n",
    "    #     dest.write(out_bands)\n",
    "      \n",
    "    ## write QA bands\n",
    "    out_meta.update({\"driver\": \"GTiff\",\n",
    "                     \"height\": qa_bands.shape[1],\n",
    "                     \"width\": qa_bands.shape[2],\n",
    "                     \"count\": qa_bands.shape[0],\n",
    "                     \"transform\": out_transform})\n",
    "    \n",
    "    with rasterio.open(chip_qa_dir + \"chip_\" + str(chip_id) + \"_Fmask.tif\", \"w\", **out_meta) as dest:\n",
    "        dest.write(qa_bands)  \n",
    "    \n",
    "        \n",
    "    # ## clip cdl to chip\n",
    "    # with rasterio.open(\"/data/2021_30m_cdls_clipped.tif\") as src:\n",
    "    #     out_image, out_transform = rasterio.mask.mask(src, shape, crop=True)\n",
    "    #     out_meta = src.meta\n",
    "    #     colormap = src.colormap(1)\n",
    "\n",
    "    # out_meta.update({\"driver\": \"GTiff\",\n",
    "    #                  \"height\": out_image.shape[1],\n",
    "    #                  \"width\": out_image.shape[2],\n",
    "    #                  \"transform\": out_transform})\n",
    "    # # write CDL chip to 'chips'\n",
    "    # with rasterio.open(chip_dir + \"chip_\" + str(chip_id) + \".mask.tif\", \"w\", **out_meta) as dest:\n",
    "    #     dest.write(out_image)\n",
    "    #     dest.write_colormap(1, colormap)\n",
    "        \n",
    "        \n",
    "    # # write binary  reclassed CDL chip to chips_binary\n",
    "    # out_image_binary = c_rcl(out_image).astype(np.uint8)\n",
    "    # with rasterio.open(chip_dir_binary + \"chip_\" + str(chip_id) + \".mask.tif\", \"w\", **out_meta) as dest:\n",
    "    #     dest.write(out_image_binary)\n",
    "    #     dest.write_colormap(1, colormap)\n",
    "        \n",
    "    # # write multiclass  reclassed CDL chip to chips_multi\n",
    "    # out_image_multi = c_multi(out_image).astype(np.uint8)\n",
    "    # with rasterio.open(chip_dir_multi + \"chip_\" + str(chip_id) + \".mask.tif\", \"w\", **out_meta) as dest:\n",
    "    #     dest.write(out_image_multi)\n",
    "    #     dest.write_colormap(1, colormap)\n",
    "    \n",
    "    \n",
    "    return(valid_first,\n",
    "           valid_second,\n",
    "           valid_third, \n",
    "           bad_pct_first,\n",
    "           bad_pct_second,\n",
    "           bad_pct_third,\n",
    "           qa_first,\n",
    "           qa_second,\n",
    "           qa_third,\n",
    "           na_count,\n",
    "           first_image_date,\n",
    "           second_image_date,\n",
    "           third_image_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe472a2b-0e00-45b7-bf17-301d95ff0b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "tiles_to_chip = temp_df.tile.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629eff96-a75e-4195-9b12-ee84539a7118",
   "metadata": {},
   "outputs": [],
   "source": [
    "## process chips\n",
    "\n",
    "for tile in tiles_to_chip:\n",
    "    print(tile)\n",
    "    chips_to_process = chip_df[chip_df.tile == tile.replace(\"T\", \"\")].reset_index(drop = True)\n",
    "    for k in range(len(chips_to_process)):\n",
    "        current_id = chips_to_process.chip_id[k]\n",
    "        chip_tile = chips_to_process.tile[k]\n",
    "        # print(current_id)\n",
    "        chip_index = chip_ids.index(current_id)\n",
    "\n",
    "        chip_feature = chips['features'][chip_index]\n",
    "\n",
    "        shape = [chip_feature['geometry']]\n",
    "\n",
    "        ## do we want to scale/clip reflectances?\n",
    "        full_tile_name = \"T\" + chip_tile\n",
    "        valid_first,  valid_second, valid_third, bad_pct_first, bad_pct_second, bad_pct_third, qa_first, qa_second, qa_third, na_count, first_image_date, second_image_date, third_image_date = process_chip(current_id, full_tile_name, shape, track_df)\n",
    "\n",
    "        chip_df_index = chip_df.index[chip_df['chip_id'] == current_id].tolist()[0]\n",
    "        chip_df.at[chip_df_index, 'valid_first'] = valid_first\n",
    "        chip_df.at[chip_df_index, 'valid_second'] = valid_second\n",
    "        chip_df.at[chip_df_index, 'valid_third'] = valid_third\n",
    "        chip_df.at[chip_df_index, 'bad_pct_first'] = bad_pct_first\n",
    "        chip_df.at[chip_df_index, 'bad_pct_second'] = bad_pct_second\n",
    "        chip_df.at[chip_df_index, 'bad_pct_third'] = bad_pct_third\n",
    "        chip_df.at[chip_df_index, 'first_image_date'] = first_image_date\n",
    "        chip_df.at[chip_df_index, 'second_image_date'] = second_image_date\n",
    "        chip_df.at[chip_df_index, 'third_image_date'] = third_image_date\n",
    "        chip_df['bad_pct_max'] = chip_df[['bad_pct_first', 'bad_pct_second', 'bad_pct_third']].max(axis=1)\n",
    "        chip_df.at[chip_df_index, 'na_count'] = na_count\n",
    "    # tile_tracker = pd.read_csv(tile_tracker_csv)\n",
    "    # tile_tracker.loc[tile_tracker.tile == tile , 'chip'] = True\n",
    "    # tile_tracker.to_csv(tile_tracker_csv, index=False)\n",
    "chip_df.to_csv(chip_csv, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3559be60-dd8d-4508-8e5a-dce8edb80dd1",
   "metadata": {},
   "source": [
    "filter chips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7db3cb4-82b1-4f43-84af-d0081d7a41b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "chip_df = pd.read_csv(chip_csv)\n",
    "\n",
    "for tile in tiles_to_filter:\n",
    "    print(tile)\n",
    "    filtered_chips = chip_df[(chip_df.tile == tile) & (chip_df.bad_pct_max < 5) & (chip_df.na_count == 0)].chip_id.tolist()\n",
    "    print(len(filtered_chips))\n",
    "    for chip_id in filtered_chips:\n",
    "        chip_files = glob('/data/chips/*' + chip_id + '*')\n",
    "        for file in chip_files:\n",
    "            name = file.split('/')[-1]\n",
    "            shutil.copyfile(file, '/data/chips_filtered/' + name)\n",
    "        chip_files_b = glob('/data/chips_binary/*' + chip_id + '*')\n",
    "        for file in chip_files_b:\n",
    "            name = file.split('/')[-1]\n",
    "            shutil.copyfile(file, '/data/chips_binary_filtered/' + name)\n",
    "        chip_files_multi = glob('/data/chips_multi/*' + chip_id + '*')\n",
    "        for file in chip_files_multi:\n",
    "            name = file.split('/')[-1]\n",
    "            shutil.copyfile(file, '/data/chips_multi_filtered/' + name)\n",
    "    \n",
    "    tile_tracker = pd.read_csv(tile_tracker_csv)\n",
    "    tile_tracker.loc[tile_tracker.tile == tile , 'filter_chips'] = True\n",
    "    tile_tracker.to_csv(tile_tracker_csv, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59521d7-0573-4d99-be3b-8df8c6675442",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
