{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d515919-1b62-4748-9810-a941fb3317e2",
   "metadata": {},
   "source": [
    "**Importing Packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "5c8cde70-7cf0-49c8-a69e-3f2a45757876",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas\n",
    "import json\n",
    "import shapely\n",
    "import shapely.geometry\n",
    "import xarray\n",
    "import rasterio\n",
    "import rioxarray\n",
    "import os\n",
    "import fiona\n",
    "import urllib.request as urlreq\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import xmltodict\n",
    "import shutil\n",
    "import datetime\n",
    "import boto3\n",
    "import pyproj\n",
    "\n",
    "from shapely.ops import transform\n",
    "from shapely.geometry import Point\n",
    "from shapely.geometry import Polygon\n",
    "from pystac_client import Client \n",
    "from collections import defaultdict\n",
    "from glob import glob\n",
    "from rasterio.enums import Resampling\n",
    "from rasterio import Affine\n",
    "from rasterio.crs import CRS\n",
    "import matplotlib.pyplot as plt\n",
    "from subprocess import Popen, PIPE\n",
    "from tqdm import tqdm\n",
    "from netrc import netrc\n",
    "from subprocess import Popen\n",
    "from platform import system\n",
    "from getpass import getpass\n",
    "from rasterio.session import AWSSession\n",
    "from pathlib import Path\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a6db73-e1af-470e-8a13-e923fcd74fc0",
   "metadata": {},
   "source": [
    "**Setting folder pathes and file paths**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "d9f65500-9fc0-4b7f-8e4f-46c40a079acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### START OPTIONS #####\n",
    "cloud_thres = 5\n",
    "\n",
    "root_path = \"/data/\"\n",
    "req_path = \"/cdl_training_data/data/\"\n",
    "extra_files = \"/cdl_training_data/data/requirements/\"\n",
    "\n",
    "## file paths\n",
    "chip_file =  req_path + \"chip_bbox_task_1.geojson\"\n",
    "chipping_json = req_path + \"chip_bbox_task_1_5070.geojson\"\n",
    "chip_csv = req_path + \"chip_tracker.csv\"\n",
    "kml_file = extra_files + 'sentinel_tile_grid.kml'\n",
    "tile_tracker_csv = req_path + \"tile_tracker.csv\"\n",
    "\n",
    "## folder paths\n",
    "tif_dir = root_path + 'tif/'\n",
    "chip_dir = root_path + 'chips/'\n",
    "tile_dir = root_path + 'tiles/'\n",
    "chip_dir_filt = chip_dir + 'chips_filtered/'\n",
    "chip_fmask_dir = root_path + 'chips_fmask/'\n",
    "#####  END OPTIONS  #####"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2291ef-8954-45fe-9d77-41048a58ecaa",
   "metadata": {},
   "source": [
    "**Data Processing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "572aad79-35fe-4640-85a0-a489fa18f09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading chips bounding boxes from geojson\n",
    "with open(chip_file, \"r\") as file:\n",
    "    chips = json.load(file)\n",
    "    # print(chips)\n",
    "\n",
    "# Create lists about chip information to find tiles corresponding to it later\n",
    "chip_ids = []\n",
    "chip_x = []\n",
    "chip_y = []\n",
    "for item in chips['features']:\n",
    "    #print(item)\n",
    "    chip_ids.append(item['properties']['id'])\n",
    "    chip_x.append(item['properties']['center'][0])\n",
    "    chip_y.append(item['properties']['center'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "5d739262-045a-4ed9-8930-9dd5ea203e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/data/chip_ids.json\", \"w\") as f:\n",
    "    json.dump(chip_ids, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "a56e07ac-9b0a-4d7c-bad1-51586770a1f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Description</th>\n",
       "      <th>geometry</th>\n",
       "      <th>minx</th>\n",
       "      <th>miny</th>\n",
       "      <th>maxx</th>\n",
       "      <th>maxy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01CCV</td>\n",
       "      <td>TILE PROPERTIES&lt;br&gt;&lt;table border=0 cellpadding...</td>\n",
       "      <td>GEOMETRYCOLLECTION Z (POLYGON Z ((180.00000 -7...</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-73.064633</td>\n",
       "      <td>180.0</td>\n",
       "      <td>-72.012478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01CDH</td>\n",
       "      <td>TILE PROPERTIES&lt;br&gt;&lt;table border=0 cellpadding...</td>\n",
       "      <td>GEOMETRYCOLLECTION Z (POLYGON Z ((180.00000 -8...</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-83.835334</td>\n",
       "      <td>180.0</td>\n",
       "      <td>-82.796720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01CDJ</td>\n",
       "      <td>TILE PROPERTIES&lt;br&gt;&lt;table border=0 cellpadding...</td>\n",
       "      <td>GEOMETRYCOLLECTION Z (POLYGON Z ((180.00000 -8...</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-82.939452</td>\n",
       "      <td>180.0</td>\n",
       "      <td>-81.906947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01CDK</td>\n",
       "      <td>TILE PROPERTIES&lt;br&gt;&lt;table border=0 cellpadding...</td>\n",
       "      <td>GEOMETRYCOLLECTION Z (POLYGON Z ((180.00000 -8...</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-82.044055</td>\n",
       "      <td>180.0</td>\n",
       "      <td>-81.016439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01CDL</td>\n",
       "      <td>TILE PROPERTIES&lt;br&gt;&lt;table border=0 cellpadding...</td>\n",
       "      <td>GEOMETRYCOLLECTION Z (POLYGON Z ((180.00000 -8...</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-81.148070</td>\n",
       "      <td>180.0</td>\n",
       "      <td>-80.124456</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Name                                        Description  \\\n",
       "0  01CCV  TILE PROPERTIES<br><table border=0 cellpadding...   \n",
       "1  01CDH  TILE PROPERTIES<br><table border=0 cellpadding...   \n",
       "2  01CDJ  TILE PROPERTIES<br><table border=0 cellpadding...   \n",
       "3  01CDK  TILE PROPERTIES<br><table border=0 cellpadding...   \n",
       "4  01CDL  TILE PROPERTIES<br><table border=0 cellpadding...   \n",
       "\n",
       "                                            geometry   minx       miny   maxx  \\\n",
       "0  GEOMETRYCOLLECTION Z (POLYGON Z ((180.00000 -7... -180.0 -73.064633  180.0   \n",
       "1  GEOMETRYCOLLECTION Z (POLYGON Z ((180.00000 -8... -180.0 -83.835334  180.0   \n",
       "2  GEOMETRYCOLLECTION Z (POLYGON Z ((180.00000 -8... -180.0 -82.939452  180.0   \n",
       "3  GEOMETRYCOLLECTION Z (POLYGON Z ((180.00000 -8... -180.0 -82.044055  180.0   \n",
       "4  GEOMETRYCOLLECTION Z (POLYGON Z ((180.00000 -8... -180.0 -81.148070  180.0   \n",
       "\n",
       "        maxy  \n",
       "0 -72.012478  \n",
       "1 -82.796720  \n",
       "2 -81.906947  \n",
       "3 -81.016439  \n",
       "4 -80.124456  "
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in sentinel kml file\n",
    "fiona.drvsupport.supported_drivers['KML'] = 'rw'\n",
    "tile_src = geopandas.read_file(kml_file, driver='KML')\n",
    "\n",
    "# Create table containing information about sentinel tiles\n",
    "tile_name = []\n",
    "tile_x = []\n",
    "tile_y = []\n",
    "for tile_ind in range(tile_src.shape[0]):\n",
    "    tile_name.append(tile_src.iloc[tile_ind].Name)\n",
    "    tile_x.append(tile_src.iloc[tile_ind].geometry.centroid.x)\n",
    "    tile_y.append(tile_src.iloc[tile_ind].geometry.centroid.y)\n",
    "tile_name = np.array(tile_name)\n",
    "tile_x = np.array(tile_x)\n",
    "tile_y = np.array(tile_y)\n",
    "tile_src = pd.concat([tile_src, tile_src.bounds], axis = 1)\n",
    "tile_src.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "618cc2a5-678c-47fd-a324-0d89e8f74e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_tile(x,y):\n",
    "# Identify closest tile\n",
    "    s = (tile_x - x)**2+(tile_y - y)**2\n",
    "    tname = tile_name[np.argmin(s)]\n",
    "    return(tname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "923bcea3-efa4-41fc-90ef-0877dd270270",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chip_id</th>\n",
       "      <th>chip_x</th>\n",
       "      <th>chip_y</th>\n",
       "      <th>tile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>chip_090_484</td>\n",
       "      <td>-84.446559</td>\n",
       "      <td>45.575077</td>\n",
       "      <td>16TFR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>chip_177_428</td>\n",
       "      <td>-89.751220</td>\n",
       "      <td>40.674821</td>\n",
       "      <td>16TBL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>chip_106_429</td>\n",
       "      <td>-89.268425</td>\n",
       "      <td>44.931751</td>\n",
       "      <td>16TCQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>chip_312_160</td>\n",
       "      <td>-109.614541</td>\n",
       "      <td>31.902541</td>\n",
       "      <td>12SXA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>chip_198_312</td>\n",
       "      <td>-99.007068</td>\n",
       "      <td>39.532747</td>\n",
       "      <td>14SMJ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           chip_id      chip_x     chip_y   tile\n",
       "4995  chip_090_484  -84.446559  45.575077  16TFR\n",
       "4996  chip_177_428  -89.751220  40.674821  16TBL\n",
       "4997  chip_106_429  -89.268425  44.931751  16TCQ\n",
       "4998  chip_312_160 -109.614541  31.902541  12SXA\n",
       "4999  chip_198_312  -99.007068  39.532747  14SMJ"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chip_df = pd.DataFrame({\"chip_id\" : chip_ids, \"chip_x\" : chip_x, \"chip_y\" : chip_y})\n",
    "chip_df['tile'] = chip_df.apply(lambda row : find_tile(row['chip_x'], row['chip_y']), axis = 1)\n",
    "chip_df.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "be986eb5-6c6e-4834-8fa5-dc36134e7839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dataframe to csv for later uses\n",
    "chip_df.to_csv(req_path + \"chip_df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "9ca55cff-659f-4d68-a894-278af32fb9a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['13TDE', '16SDD', '13SFV', '14TNS', '14UMU']"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tiles = chip_df.tile.unique().tolist()\n",
    "tiles[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bbb2c70-318c-4be9-ab9a-c4f04fa4ca52",
   "metadata": {},
   "source": [
    "***Make tile tracker***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "4fb55057-378d-4226-b3c6-96f3f929692a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_tracker = pd.DataFrame({\"tile\":tiles})\n",
    "tile_tracker['exclude'] = False\n",
    "tile_tracker['tif_download'] = False\n",
    "tile_tracker['tif_reproject'] = False\n",
    "tile_tracker['chip'] = False\n",
    "tile_tracker['filter_chips'] = False\n",
    "#tile_tracker.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "563bb20c-15f6-4236-a47d-6a21a30058cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tile</th>\n",
       "      <th>exclude</th>\n",
       "      <th>tif_download</th>\n",
       "      <th>tif_reproject</th>\n",
       "      <th>chip</th>\n",
       "      <th>filter_chips</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13TDE</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16SDD</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13SFV</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14TNS</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14UMU</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    tile  exclude  tif_download  tif_reproject   chip  filter_chips\n",
       "0  13TDE    False         False          False  False         False\n",
       "1  16SDD    False         False          False  False         False\n",
       "2  13SFV    False         False          False  False         False\n",
       "3  14TNS    False         False          False  False         False\n",
       "4  14UMU    False         False          False  False         False"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## update tracker\n",
    "tiles_already_downloaded = glob(tif_dir + '*')\n",
    "tiles_already_downloaded = set([i[19:24] for i in tiles_already_downloaded])\n",
    "tiles_already_downloaded\n",
    "tile_tracker.loc[tile_tracker.tile.isin(tiles_already_downloaded) , 'tif_download'] = True\n",
    "\n",
    "chips_already_chipped = glob(chip_dir + '*')\n",
    "chips_already_chipped = set([i[17:24] for i in chips_already_chipped])\n",
    "#print(chips_already_chipped)\n",
    "tiles_already_chipped = chip_df[chip_df.chip_id.isin(chips_already_chipped)].tile.unique()\n",
    "#print(tiles_already_chipped)\n",
    "tile_tracker.loc[tile_tracker.tile.isin(tiles_already_chipped) , 'tif_reproject'] = True\n",
    "tile_tracker.loc[tile_tracker.tile.isin(tiles_already_chipped) , 'chip'] = True\n",
    "                                        \n",
    "chips_already_filtered = glob(chip_dir_filt + '*')\n",
    "chips_already_filtered = set([i[26:33] for i in chips_already_filtered])\n",
    "tiles_already_filtered = chip_df[chip_df.chip_id.isin(chips_already_filtered)].tile.unique()\n",
    "tile_tracker.loc[tile_tracker.tile.isin(tiles_already_filtered), 'filter_chips'] = True\n",
    "\n",
    "tile_tracker.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "4bfede41-a78e-4890-96cf-cd56fb53d4ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file exists\n"
     ]
    }
   ],
   "source": [
    "## write to csv\n",
    "check_file = glob(tile_tracker_csv)\n",
    "if len(check_file) == 0:\n",
    "    tile_tracker.to_csv(tile_tracker_csv, index=False)\n",
    "else:\n",
    "    print('file exists')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8575471-42cb-47e2-86c3-15068d840868",
   "metadata": {},
   "source": [
    "**Querying tile links based on geometry of chips**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "8679f41b-87b1-4b3d-a2f2-559b9df3fdfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "STAC_URL = 'https://cmr.earthdata.nasa.gov/stac'\n",
    "catalog = Client.open(f'{STAC_URL}/LPCLOUD/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "c6d6080c-87aa-4ae8-bcee-71e9757b3dd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are a total of 491 tiles\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/pystac_client/item_search.py:841: FutureWarning: get_all_items() is deprecated, use item_collection() instead.\n",
      "  warnings.warn(\n",
      "(0/491): 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 81/81 [00:03<00:00, 20.35it/s]\n"
     ]
    }
   ],
   "source": [
    "# Original 5 percentage query\n",
    "tile_list = []\n",
    "print(f\"There are a total of {len(tiles)} tiles\")\n",
    "tile_iter = 0\n",
    "for current_tile in tiles[0:1]:\n",
    "\n",
    "    chip_df_filt = chip_df.loc[chip_df.tile == current_tile]#.reset_index()\n",
    "    first_chip_id = chip_df_filt.chip_id.iloc[0]\n",
    "    first_chip_index_in_json = chip_ids.index(first_chip_id)\n",
    "    roi = chips['features'][first_chip_index_in_json]['geometry']\n",
    "\n",
    "    search = catalog.search(\n",
    "        collections = ['HLSS30.v2.0'],\n",
    "        intersects = roi,\n",
    "        datetime = '2022-03-01/2022-09-30',\n",
    "    ) \n",
    "    \n",
    "    num_results = search.matched()\n",
    "    item_collection = search.get_all_items()\n",
    "    \n",
    "    tile_name = \"T\" + current_tile\n",
    "    iter_items = 0\n",
    "    for i in tqdm(item_collection ,desc=f\"({tile_iter}/{len(tiles)})\"):\n",
    "        if i.id.split('.')[2] == tile_name:\n",
    "            if i.properties['eo:cloud_cover'] <= cloud_thres:\n",
    "                response = requests.get(i.assets['metadata'].href)\n",
    "                if response.status_code == 200:\n",
    "                    temp_xml = response.text\n",
    "                    temp_xml = xmltodict.parse(temp_xml)\n",
    "                    temp_dict = {\"tile_id\": tile_name, \"cloud_cover\": i.properties['eo:cloud_cover'],\n",
    "                                 \"date\": datetime.datetime.strptime(i.properties['datetime'].split('T')[0], \"%Y-%m-%d\"), \n",
    "                                 \"spatial_cover\": int(temp_xml['Granule']['AdditionalAttributes']['AdditionalAttribute'][3]['Values']['Value']),\n",
    "                                 \"http_links\": {\"B02\": i.assets['B02'].href, \"B03\": i.assets['B03'].href, \"B04\": i.assets['B04'].href,  \"B8A\": i.assets['B8A'].href,\n",
    "                                                \"B11\": i.assets['B11'].href, \"B12\": i.assets['B12'].href, \"Fmask\": i.assets['Fmask']},\n",
    "                                \"s3_links\": {\"B02\": i.assets['B02'].href.replace('https://data.lpdaac.earthdatacloud.nasa.gov/lp-prod-protected/', 's3:/'), \n",
    "                                             \"B03\": i.assets['B03'].href.replace('https://data.lpdaac.earthdatacloud.nasa.gov/lp-prod-protected/', 's3:/'), \n",
    "                                             \"B04\": i.assets['B04'].href.replace('https://data.lpdaac.earthdatacloud.nasa.gov/lp-prod-protected/', 's3:/'), \n",
    "                                             \"B8A\": i.assets['B8A'].href.replace('https://data.lpdaac.earthdatacloud.nasa.gov/lp-prod-protected/', 's3:/'),\n",
    "                                             \"B11\": i.assets['B11'].href.replace('https://data.lpdaac.earthdatacloud.nasa.gov/lp-prod-protected/', 's3:/'),\n",
    "                                             \"B12\": i.assets['B12'].href.replace('https://data.lpdaac.earthdatacloud.nasa.gov/lp-prod-protected/', 's3:/'),\n",
    "                                             \"Fmask\": i.assets['Fmask'].href.replace('https://data.lpdaac.earthdatacloud.nasa.gov/lp-prod-protected/', 's3:/')}}\n",
    "                    tile_list.append(temp_dict)\n",
    "                    iter_items += 1\n",
    "                else: \n",
    "                    assert False, f\"Failed to fetch XML from {i.assets['metadata'].href}. Error code: {response.status_code}\"\n",
    "            \n",
    "    tile_iter += 1\n",
    "    #print(f\"Information for tile {tile_name} is collected, a total of {iter_items} out of {num_results} tiles pass the filter ({tile_iter}/{len(tiles)})\")\n",
    "\n",
    "    \n",
    "tile_df = pd.DataFrame(tile_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "7431fc8b-0f64-408b-8500-24a1bae5aa01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to csv for later uses\n",
    "tile_df.to_csv(req_path + \"tile_df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "bf8f2617-3d4a-4651-92ba-6d82f4e39f35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tile_id</th>\n",
       "      <th>cloud_cover</th>\n",
       "      <th>date</th>\n",
       "      <th>spatial_cover</th>\n",
       "      <th>http_links</th>\n",
       "      <th>s3_links</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T13TDE</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-03-14</td>\n",
       "      <td>25</td>\n",
       "      <td>{'B02': 'https://data.lpdaac.earthdatacloud.na...</td>\n",
       "      <td>{'B02': 's3:/HLSS30.020/HLS.S30.T13TDE.2022073...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T13TDE</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-04-08</td>\n",
       "      <td>25</td>\n",
       "      <td>{'B02': 'https://data.lpdaac.earthdatacloud.na...</td>\n",
       "      <td>{'B02': 's3:/HLSS30.020/HLS.S30.T13TDE.2022098...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T13TDE</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-04-18</td>\n",
       "      <td>25</td>\n",
       "      <td>{'B02': 'https://data.lpdaac.earthdatacloud.na...</td>\n",
       "      <td>{'B02': 's3:/HLSS30.020/HLS.S30.T13TDE.2022108...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T13TDE</td>\n",
       "      <td>3</td>\n",
       "      <td>2022-04-21</td>\n",
       "      <td>99</td>\n",
       "      <td>{'B02': 'https://data.lpdaac.earthdatacloud.na...</td>\n",
       "      <td>{'B02': 's3:/HLSS30.020/HLS.S30.T13TDE.2022111...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T13TDE</td>\n",
       "      <td>2</td>\n",
       "      <td>2022-05-26</td>\n",
       "      <td>99</td>\n",
       "      <td>{'B02': 'https://data.lpdaac.earthdatacloud.na...</td>\n",
       "      <td>{'B02': 's3:/HLSS30.020/HLS.S30.T13TDE.2022146...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  tile_id  cloud_cover       date  spatial_cover  \\\n",
       "0  T13TDE            1 2022-03-14             25   \n",
       "1  T13TDE            0 2022-04-08             25   \n",
       "2  T13TDE            0 2022-04-18             25   \n",
       "3  T13TDE            3 2022-04-21             99   \n",
       "4  T13TDE            2 2022-05-26             99   \n",
       "\n",
       "                                          http_links  \\\n",
       "0  {'B02': 'https://data.lpdaac.earthdatacloud.na...   \n",
       "1  {'B02': 'https://data.lpdaac.earthdatacloud.na...   \n",
       "2  {'B02': 'https://data.lpdaac.earthdatacloud.na...   \n",
       "3  {'B02': 'https://data.lpdaac.earthdatacloud.na...   \n",
       "4  {'B02': 'https://data.lpdaac.earthdatacloud.na...   \n",
       "\n",
       "                                            s3_links  \n",
       "0  {'B02': 's3:/HLSS30.020/HLS.S30.T13TDE.2022073...  \n",
       "1  {'B02': 's3:/HLSS30.020/HLS.S30.T13TDE.2022098...  \n",
       "2  {'B02': 's3:/HLSS30.020/HLS.S30.T13TDE.2022108...  \n",
       "3  {'B02': 's3:/HLSS30.020/HLS.S30.T13TDE.2022111...  \n",
       "4  {'B02': 's3:/HLSS30.020/HLS.S30.T13TDE.2022146...  "
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tile_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8a157d-9e4a-4a79-b98e-d94e8f1916bf",
   "metadata": {},
   "source": [
    "**Filtering based on could and spatial coverage of the tiles we gathered earlier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "59767242-2158-4cd7-bdc7-1719207f0552",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spatial_filtering (dataframe):\n",
    "    \"\"\"\n",
    "        Using spatial coverage percentage to filter chips\n",
    "\n",
    "        Args:\n",
    "            dataframe: A pandas dataframe that generated previously\n",
    "    \"\"\"\n",
    "    cover_list = [100, 90, 80, 70, 60, 50]\n",
    "    tile_list_ft = []\n",
    "    tile_list = dataframe.tile_id.unique().tolist()\n",
    "    \n",
    "    for tile in tqdm(tile_list):\n",
    "        temp_df = dataframe[dataframe.tile_id == tile]\n",
    "        for cover_pct in cover_list:\n",
    "            \n",
    "            temp_df_filtered = temp_df[temp_df.spatial_cover >= cover_pct]\n",
    "            if len(temp_df_filtered) >= 3:\n",
    "                for i in range(len(temp_df_filtered)):\n",
    "                    tile_list_ft.append(temp_df_filtered.iloc[i])\n",
    "                break\n",
    "    \n",
    "    tile_df_filtered = pd.DataFrame(tile_list_ft)\n",
    "    return tile_df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "ca6941b5-9241-4626-bbec-56118c91ba95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 385.19it/s]\n"
     ]
    }
   ],
   "source": [
    "cover_df = spatial_filtering(tile_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "2b02b75c-55cc-43a1-a6d9-913771eb3043",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_scenes(dataframe):\n",
    "    \"\"\"\n",
    "        Selecting best spatial covered scenes based on timesteps\n",
    "\n",
    "        Args:\n",
    "            dataframe: A pandas dataframe that generated previously\n",
    "    \"\"\"\n",
    "    select_tiles = []\n",
    "    tile_list = dataframe.tile_id.unique().tolist()\n",
    "\n",
    "    for tile in tqdm(tile_list):\n",
    "        temp_df = dataframe[dataframe.tile_id == tile].sort_values('date').reset_index(drop=True)\n",
    "        select_tiles.extend([temp_df.iloc[0], temp_df.iloc[len(temp_df) // 2], temp_df.iloc[-1]])\n",
    "\n",
    "    return pd.DataFrame(select_tiles).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "b23da90c-e163-45fc-9ea6-ef8e3130bc95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 681.67it/s]\n"
     ]
    }
   ],
   "source": [
    "selected_tiles = select_scenes(cover_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "f7caff71-b5be-4d54-be44-a0938bd55159",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tile_id</th>\n",
       "      <th>cloud_cover</th>\n",
       "      <th>date</th>\n",
       "      <th>spatial_cover</th>\n",
       "      <th>http_links</th>\n",
       "      <th>s3_links</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T13TDE</td>\n",
       "      <td>3</td>\n",
       "      <td>2022-04-21</td>\n",
       "      <td>99</td>\n",
       "      <td>{'B02': 'https://data.lpdaac.earthdatacloud.na...</td>\n",
       "      <td>{'B02': 's3:/HLSS30.020/HLS.S30.T13TDE.2022111...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T13TDE</td>\n",
       "      <td>4</td>\n",
       "      <td>2022-06-15</td>\n",
       "      <td>100</td>\n",
       "      <td>{'B02': 'https://data.lpdaac.earthdatacloud.na...</td>\n",
       "      <td>{'B02': 's3:/HLSS30.020/HLS.S30.T13TDE.2022166...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T13TDE</td>\n",
       "      <td>5</td>\n",
       "      <td>2022-09-23</td>\n",
       "      <td>99</td>\n",
       "      <td>{'B02': 'https://data.lpdaac.earthdatacloud.na...</td>\n",
       "      <td>{'B02': 's3:/HLSS30.020/HLS.S30.T13TDE.2022266...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  tile_id  cloud_cover       date  spatial_cover  \\\n",
       "0  T13TDE            3 2022-04-21             99   \n",
       "1  T13TDE            4 2022-06-15            100   \n",
       "2  T13TDE            5 2022-09-23             99   \n",
       "\n",
       "                                          http_links  \\\n",
       "0  {'B02': 'https://data.lpdaac.earthdatacloud.na...   \n",
       "1  {'B02': 'https://data.lpdaac.earthdatacloud.na...   \n",
       "2  {'B02': 'https://data.lpdaac.earthdatacloud.na...   \n",
       "\n",
       "                                            s3_links  \n",
       "0  {'B02': 's3:/HLSS30.020/HLS.S30.T13TDE.2022111...  \n",
       "1  {'B02': 's3:/HLSS30.020/HLS.S30.T13TDE.2022166...  \n",
       "2  {'B02': 's3:/HLSS30.020/HLS.S30.T13TDE.2022266...  "
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_tiles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "264fae95-6630-46e0-bd05-83f866cd7a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to csv for later uses\n",
    "selected_tiles.to_csv(req_path + \"selected_tiles.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e34d499-1a6e-483f-9f19-8daa6b1dd4c3",
   "metadata": {},
   "source": [
    "**Data downloading**\n",
    "\n",
    "*Creating netrc file on root for credentials (Run Once each session)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "38664ffa-cd57-4f1b-a7f3-cdb63554ad94",
   "metadata": {},
   "outputs": [],
   "source": [
    "urs = 'urs.earthdata.nasa.gov'    # Earthdata URL endpoint for authentication\n",
    "prompts = ['Enter NASA Earthdata Login Username: ',\n",
    "           'Enter NASA Earthdata Login Password: ']\n",
    "\n",
    "# Determine the OS (Windows machines usually use an '_netrc' file)\n",
    "netrc_name = \"_netrc\" if system()==\"Windows\" else \".netrc\"\n",
    "\n",
    "# Determine if netrc file exists, and if so, if it includes NASA Earthdata Login Credentials\n",
    "try:\n",
    "    netrcDir = os.path.expanduser(f\"~/{netrc_name}\")\n",
    "    netrc(netrcDir).authenticators(urs)[0]\n",
    "\n",
    "# Below, create a netrc file and prompt user for NASA Earthdata Login Username and Password\n",
    "except FileNotFoundError:\n",
    "    homeDir = os.path.expanduser(\"~\")\n",
    "    Popen('touch {0}{2} | echo machine {1} >> {0}{2}'.format(homeDir + os.sep, urs, netrc_name), shell=True)\n",
    "    Popen('echo login {} >> {}{}'.format(getpass(prompt=prompts[0]), homeDir + os.sep, netrc_name), shell=True)\n",
    "    Popen('echo \\'password {} \\'>> {}{}'.format(getpass(prompt=prompts[1]), homeDir + os.sep, netrc_name), shell=True)\n",
    "    # Set restrictive permissions\n",
    "    Popen('chmod 0600 {0}{1}'.format(homeDir + os.sep, netrc_name), shell=True)\n",
    "\n",
    "    # Determine OS and edit netrc file if it exists but is not set up for NASA Earthdata Login\n",
    "except TypeError:\n",
    "    homeDir = os.path.expanduser(\"~\")\n",
    "    Popen('echo machine {1} >> {0}{2}'.format(homeDir + os.sep, urs, netrc_name), shell=True)\n",
    "    Popen('echo login {} >> {}{}'.format(getpass(prompt=prompts[0]), homeDir + os.sep, netrc_name), shell=True)\n",
    "    Popen('echo \\'password {} \\'>> {}{}'.format(getpass(prompt=prompts[1]), homeDir + os.sep, netrc_name), shell=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aace234-4fba-4cb2-adb6-8e17601b067c",
   "metadata": {},
   "source": [
    "**Getting temporary credentials from NASA's S3 Bucket(Run once every 1 hrs)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "fadfd603-27d5-4354-912a-f5f7ebdb799f",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_cred_endpoint = 'https://data.lpdaac.earthdatacloud.nasa.gov/s3credentials'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "23b5232e-2040-40de-8915-875c13925ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_temp_creds():\n",
    "    temp_creds_url = s3_cred_endpoint\n",
    "    return requests.get(temp_creds_url).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "886b408b-2ee6-4f5c-91bc-1c73aec98cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_creds_req = get_temp_creds()\n",
    "#temp_creds_req                      # !!! BEWARE, removing the # on this line will print your temporary S3 credentials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "899bcf98-4239-48d9-917f-917191d3f974",
   "metadata": {},
   "outputs": [],
   "source": [
    "session = boto3.Session(aws_access_key_id=temp_creds_req['accessKeyId'], \n",
    "                        aws_secret_access_key=temp_creds_req['secretAccessKey'],\n",
    "                        aws_session_token=temp_creds_req['sessionToken'],\n",
    "                        region_name='us-west-2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "6eadb6ff-5b4a-4579-bbef-a3a3e2b8212a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<rasterio.env.Env at 0x7f4078579d80>"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rio_env = rasterio.Env(AWSSession(session),\n",
    "                  GDAL_DISABLE_READDIR_ON_OPEN='EMPTY_DIR',\n",
    "                  GDAL_HTTP_COOKIEFILE=os.path.expanduser('~/cookies.txt'),\n",
    "                  GDAL_HTTP_COOKIEJAR=os.path.expanduser('~/cookies.txt'))\n",
    "rio_env.__enter__()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcda5481-8823-4e02-8535-67f490da9782",
   "metadata": {},
   "source": [
    "**Tile downloading (Run the crendentials chunk if connecting error)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "4b6b5fec-57ee-4afa-9715-c5231e1322b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tile_download(table, boto3_session, from_csv = True):\n",
    "    \"\"\"\n",
    "        Downloading tiles by reading from the metadata information gathered earlier\n",
    "\n",
    "        Args:\n",
    "            table: A pandas dataframe that generated previously\n",
    "            boto3_session: The session that set earlier when getting credentials\n",
    "            from_csv: If the tile information is from a csv, then True\n",
    "    \"\"\"\n",
    "    bucket = boto3_session\n",
    "    info_list = []\n",
    "    bands = [\"B02\",\"B03\",\"B04\",\"B8A\",\"B11\",\"B12\",\"Fmask\"]\n",
    "    accept_tiles = np.unique(table.tile_id)\n",
    "    for tile in tqdm(accept_tiles):\n",
    "        temp_tb = table[table.tile_id == tile]\n",
    "        for i in range(3):\n",
    "            if from_csv:\n",
    "                bands_dict = json.loads(temp_tb.iloc[i].s3_links.replace(\"'\", '\"'))\n",
    "            else:\n",
    "                bands_dict = temp_tb.iloc[i].s3_links\n",
    "            for band in bands:\n",
    "                temp_key = bands_dict[band].replace(\"s3:/\", \"\")\n",
    "                temp_sav_path = f\"/data/tiles/{bands_dict[band].split('/')[2]}/{bands_dict[band].split('/')[3]}\"\n",
    "                os.makedirs(f\"/data/tiles/{bands_dict[band].split('/')[2]}\", exist_ok=True)\n",
    "                if not Path(temp_sav_path).is_file():\n",
    "                    boto3_session.resource('s3').Bucket('lp-prod-protected').download_file(Key = temp_key, Filename = temp_sav_path)\n",
    "            temp_dict = {\"tile\":tile, \"timestep\":i, \"date\":temp_tb.iloc[i].date, \"save_path\":f\"/data/tiles/{bands_dict[band].split('/')[2]}/\", \"filename\":bands_dict[\"B02\"].split('/')[3].replace(\".B02.tif\",\"\")}\n",
    "            info_list.append(temp_dict)\n",
    "        break\n",
    "    return pd.DataFrame(info_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "90e5a786-2fc1-48de-9931-b2cbb7ccef67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# track_df = tile_download(selected_tiles, session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "57d8a34d-61e6-42ca-a71e-7e85a2fd67d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "track_df.to_csv(req_path + \"track_df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fafaa7d-c9fc-46b1-8311-b5bb9b829fc8",
   "metadata": {},
   "source": [
    "**Chipping the CDL layer based on a geojson of area of interest. Produce a new chipped CDL tif file to use for reprojecting HLS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "fa066a53-f9d1-4a4a-b4f1-86a34d436004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this cell is clipping CDL CONUS layer to a smaller area captured in `cdl_aoi.geojson`\n",
    "with fiona.open(\"/cdl_training_data/data/requirements/cdl_aoi.geojson\", \"r\") as shapefile:\n",
    "    shapes = [feature[\"geometry\"] for feature in shapefile]\n",
    "    \n",
    "with rasterio.open(\"/cdl_training_data/data/requirements/2021_30m_cdls_clipped.tif\") as src:\n",
    "    out_image, out_transform = rasterio.mask.mask(src, shapes, crop=True)\n",
    "    out_meta = src.meta\n",
    "    colormap = src.colormap(1)\n",
    "    \n",
    "out_meta.update({\"driver\": \"GTiff\",\n",
    "                 \"height\": out_image.shape[1],\n",
    "                 \"width\": out_image.shape[2],\n",
    "                 \"transform\": out_transform})\n",
    "\n",
    "with rasterio.open(\"/cdl_training_data/data/requirements/2021_30m_cdls_clipped.tif\", \"w\", **out_meta) as dest:\n",
    "    dest.write(out_image)\n",
    "    dest.write_colormap(1, colormap)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468880b3-37e1-41c4-98fd-70944d92e2bd",
   "metadata": {},
   "source": [
    "**Using the CDL tif to reproject each HLS scene to CDL projection. Run cdl_generate.ipynb before doing this to get the cdl tif file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "127469e1-4464-483d-a9fa-ec61b4844f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "cdl_file = \"/cdl_training_data/data/requirements/2021_30m_cdls_clipped.tif\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "7f8fa877-023b-47c0-85cd-eddb65e222d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "track_df = pd.read_csv(req_path + \"track_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "6a3f20ce-bffe-4fb3-bb29-4a1c90c99820",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reproject_hls(tile_path, \n",
    "                  target_crs =\"EPSG:5070\", \n",
    "                  remove_original = True, \n",
    "                  resampling_method = Resampling.bilinear):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function receives the path to a specific HLS tile and reproject it to the targeting crs.\n",
    "    The option of removing the raw HLS tile is provided\n",
    "    \n",
    "    Assumptions:\n",
    "    - tile_path is a full path that end with .tif\n",
    "    \n",
    "    \n",
    "    Inputs:\n",
    "    - tile_path: The full path to a specific HLS tile\n",
    "    - target_crs: The crs that you wish to reproject the tile to, default is EPSG 4326\n",
    "    - remove_original: The option to remove raw HLS tile after reprojecting, default is True\n",
    "    - resampling_method: The method that rioxarray use to reproject, default is bilinear\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    xds = rioxarray.open_rasterio(tile_path)\n",
    "    cdl = rioxarray.open_rasterio(cdl_file)\n",
    "    xds_new = xds.rio.reproject_match(cdl, resampling = resampling_method)\n",
    "    if remove_original:\n",
    "        if Path(tile_path).is_file():\n",
    "            os.remove(tile_path)\n",
    "        xds_new.rio.to_raster(raster_path = tile_path)\n",
    "    else:\n",
    "        xds_new.rio.to_raster(raster_path = tile_path.replace(\".tif\", \".reproject.tif\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "524e4a00-1773-4615-b844-f60d4ba52eff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tile</th>\n",
       "      <th>timestep</th>\n",
       "      <th>date</th>\n",
       "      <th>save_path</th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T13TDE</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-04-21</td>\n",
       "      <td>/data/tiles/HLS.S30.T13TDE.2022111T174859.v2.0/</td>\n",
       "      <td>HLS.S30.T13TDE.2022111T174859.v2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T13TDE</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-06-15</td>\n",
       "      <td>/data/tiles/HLS.S30.T13TDE.2022166T174921.v2.0/</td>\n",
       "      <td>HLS.S30.T13TDE.2022166T174921.v2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T13TDE</td>\n",
       "      <td>2</td>\n",
       "      <td>2022-09-23</td>\n",
       "      <td>/data/tiles/HLS.S30.T13TDE.2022266T175051.v2.0/</td>\n",
       "      <td>HLS.S30.T13TDE.2022266T175051.v2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     tile  timestep        date  \\\n",
       "0  T13TDE         0  2022-04-21   \n",
       "1  T13TDE         1  2022-06-15   \n",
       "2  T13TDE         2  2022-09-23   \n",
       "\n",
       "                                         save_path  \\\n",
       "0  /data/tiles/HLS.S30.T13TDE.2022111T174859.v2.0/   \n",
       "1  /data/tiles/HLS.S30.T13TDE.2022166T174921.v2.0/   \n",
       "2  /data/tiles/HLS.S30.T13TDE.2022266T175051.v2.0/   \n",
       "\n",
       "                             filename  \n",
       "0  HLS.S30.T13TDE.2022111T174859.v2.0  \n",
       "1  HLS.S30.T13TDE.2022166T174921.v2.0  \n",
       "2  HLS.S30.T13TDE.2022266T175051.v2.0  "
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "track_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "49c28179-f419-4e52-9f29-12fed3458552",
   "metadata": {},
   "outputs": [],
   "source": [
    "tiles_to_reproj = track_df.tile.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "4530d1d2-a04d-431e-8b89-51651163537d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hls_process (dataframe, \n",
    "                 bands = [\"B02\", \"B03\", \"B04\", \"B8A\", \"B11\", \"B12\", \"Fmask\"],\n",
    "                 remove_original = True):\n",
    "    tiles_to_reproj = dataframe.tile.tolist()\n",
    "    for tile in tqdm(tiles_to_reproj):\n",
    "        path_df = dataframe[dataframe.tile == tile]\n",
    "        assert len(path_df) == 3 \n",
    "        for i in range(3):\n",
    "            for band in bands:\n",
    "                tile_path = f\"{path_df.iloc[i].save_path}{path_df.iloc[i].filename}.{band}.tif\"\n",
    "                if band == \"Fmask\":\n",
    "                    reproject_hls(tile_path, remove_original, resampling_method = Resampling.nearest)\n",
    "                else :\n",
    "                    reproject_hls(tile_path, remove_original)\n",
    "        break\n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "283baa4e-5df7-47ad-9026-6efc7bed6145",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                                                  | 0/3 [03:17<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "hls_process(track_df, remove_original = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fba840c-33c6-4fb3-917f-538411ba38da",
   "metadata": {},
   "source": [
    "**Chipping**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "28119f07-521e-4356-a803-6c5e894ebe16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting all saved dataframes and json\n",
    "chip_df = pd.read_csv(req_path + \"chip_df.csv\")\n",
    "with open(\"/data/chip_ids.json\", 'r') as f:\n",
    "    chip_ids = json.load(f)\n",
    "track_df = pd.read_csv(req_path + \"track_df.csv\")\n",
    "with open(chip_file, \"r\") as file:\n",
    "    chips = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "38d86289-e212-41b3-9381-a30ae0ebb171",
   "metadata": {},
   "outputs": [],
   "source": [
    "tiles_to_chip = track_df.tile.tolist()\n",
    "with open(chipping_json, \"r\") as file_chip:\n",
    "    chipping_js = json.load(file_chip)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c217d609-c453-46d1-9411-b5383cb04319",
   "metadata": {},
   "source": [
    "**Chipping functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "a2c4dbdf-ece0-45f8-803a-cfe36abb41c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_qa(qa_path, shape,  valid_qa = [0, 4, 32, 36, 64, 68, 96, 100, 128, 132, 160, 164, 192, 196, 224, 228]):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function receives a path to a qa file, and a geometry. It clips the QA file to the geometry. \n",
    "    It returns the number of valid QA pixels in the geometry, and the clipped values.\n",
    "    \n",
    "    Assumptions: The valid_qa values are taken from Ben Mack's post:\n",
    "    https://benmack.github.io/nasa_hls/build/html/tutorials/Working_with_HLS_datasets_and_nasa_hls.html\n",
    "    \n",
    "    Inputs:\n",
    "    - qa_path: full path to reprojected QA tif file\n",
    "    - shape: 'geometry' property of single polygon feature read by fiona\n",
    "    - valid_qa: list of integer values that are 'valid' for QA band.\n",
    "    \n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    with rasterio.open(qa_path) as src:\n",
    "        out_image, out_transform = rasterio.mask.mask(src, shape, crop=True)\n",
    "        print(out_image[0].shape)\n",
    "        vals = out_image.flatten()\n",
    "        unique, counts = np.unique(vals, return_counts=True)\n",
    "        qa_df = pd.DataFrame({\"qa_val\" : unique, \"counts\" : counts})\n",
    "        qa_df\n",
    "        qa_df[~ qa_df.qa_val.isin(valid_qa)].sort_values(['counts'], ascending = False)\n",
    "        qa_df['pct'] = (100 *qa_df['counts'])/(224.0 * 224.0)\n",
    "        \n",
    "        bad_qa = qa_df[~ qa_df.qa_val.isin(valid_qa)].sort_values(['counts'], ascending = False)\n",
    "        if len(bad_qa) > 0:\n",
    "            highest_invalid_percent = bad_qa.pct.tolist()[0]\n",
    "        else: \n",
    "            highest_invalid_percent = 0\n",
    "        # ncell = len(vals)\n",
    "        valid_count = sum(x in valid_qa for x in vals)\n",
    "        return(valid_count, highest_invalid_percent, out_image[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "354ebe46-35c7-473a-8827-7348fa2a0249",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_chip(chip_id, \n",
    "                 chip_tile,\n",
    "                 shape,\n",
    "                 track_csv,\n",
    "                 bands = [\"B02\", \"B03\", \"B04\", \"B8A\", \"B11\", \"B12\"]):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function receives a chip id, HLS tile, chip geometry, and a list of bands to process. \n",
    "    \n",
    "    Assumptions:\n",
    "    \n",
    "    Inputs:\n",
    "    - chip_id: string of chip id, e.g. '000_001'\n",
    "    - chip_tile: string of HLS tile , e.g. '15ABC'\n",
    "    - shape: 'geometry' property of single polygon feature read by fiona\n",
    "    \n",
    "    The function writes out a multi-date TIF containing the bands for each of the three image dates for an HLS tile. \n",
    "    The function writes out a multi-date TIF containing the QA bands of each date.\n",
    "    The function writes out a chipped version of CDL. \n",
    "    The function calls check_qa(), which makes assumptions about what QA pixels are valid.\n",
    "    The function returns the number of valid QA pixels at each date, as a tuple.\n",
    "    \n",
    "    \"\"\"\n",
    "    ## get reprojected image paths\n",
    "    tile_info_df = track_csv[track_csv.tile == chip_tile]\n",
    "    \n",
    "    selected_image_folders = tile_info_df.save_path.to_list()\n",
    "\n",
    "    \n",
    "    assert len(selected_image_folders) == 3\n",
    "    \n",
    "                     \n",
    "    first_image_date = tile_info_df.iloc[0].date\n",
    "    second_image_date = tile_info_df.iloc[1].date\n",
    "    third_image_date = tile_info_df.iloc[2].date\n",
    "    \n",
    "\n",
    "    all_date_images = []\n",
    "    all_date_qa = []\n",
    "                     \n",
    "    for i in range(3):\n",
    "        for band in bands:\n",
    "            all_date_images.append(tile_info_df.iloc[i].save_path + f\"{tile_info_df.iloc[i].filename}.{band}.tif\")\n",
    "        all_date_qa.append(tile_info_df.iloc[i].save_path + f\"{tile_info_df.iloc[i].filename}.Fmask.tif\")\n",
    "        \n",
    "    # temp_xds = rioxarray.open_rasterio(all_date_images[0])\n",
    "    # temp_proj = pyproj.Transformer.from_crs(4326, 5070, always_xy=True)\n",
    "    # for i in range(len(shape[0][\"coordinates\"][0][0])):\n",
    "    #     src_coords = shape[0][\"coordinates\"][0][0][i]\n",
    "    #     target_coords = temp_proj.transform(src_coords[0], src_coords[1])\n",
    "    #     shape[0][\"coordinates\"][0][0][i][0] = target_coords[0]\n",
    "    #     shape[0][\"coordinates\"][0][0][i][1] = target_coords[1]\n",
    "    # print(shape)\n",
    "\n",
    "    valid_first, bad_pct_first, qa_first = check_qa(all_date_qa[0], shape)\n",
    "    valid_second, bad_pct_second, qa_second = check_qa(all_date_qa[1], shape)\n",
    "    valid_third, bad_pct_third, qa_third = check_qa(all_date_qa[2], shape)\n",
    "    \n",
    "    qa_bands = []\n",
    "    qa_bands.append(qa_first)\n",
    "    qa_bands.append(qa_second)\n",
    "    qa_bands.append(qa_third)\n",
    "    qa_bands = np.array(qa_bands).astype(np.uint8)\n",
    "    \n",
    "\n",
    "    assert len(all_date_images) == 3 * len(bands)\n",
    "    \n",
    "    out_bands = []\n",
    "    \n",
    "    for img in all_date_images:\n",
    "        with rasterio.open(img) as src:\n",
    "            out_image, out_transform = rasterio.mask.mask(src, shape, crop=True)\n",
    "            out_meta = src.meta\n",
    "            out_bands.append(out_image[0])\n",
    "    \n",
    "    out_bands = np.array(out_bands)\n",
    "    print(out_bands.shape)\n",
    "\n",
    "\n",
    "    out_meta.update({\"driver\": \"GTiff\",\n",
    "                     \"height\": out_bands.shape[1],\n",
    "                     \"width\": out_bands.shape[2],\n",
    "                     \"count\": out_bands.shape[0],\n",
    "                     \"transform\": out_transform})\n",
    "    \n",
    "    # get NA count for HLS\n",
    "    na_count = sum(out_bands.flatten() == -1000)\n",
    "    \n",
    "    # reclass negative HLS values to 0\n",
    "    out_bands = np.clip(out_bands, 0, None)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # write HLS chip to 'chips'\n",
    "    with rasterio.open(chip_dir + \"chip_\" + str(chip_id) + \"_merged.tif\", \"w\", **out_meta) as dest:\n",
    "        dest.write(out_bands)\n",
    "\n",
    "      \n",
    "    ## write QA bands\n",
    "    out_meta.update({\"driver\": \"GTiff\",\n",
    "                     \"height\": qa_bands.shape[1],\n",
    "                     \"width\": qa_bands.shape[2],\n",
    "                     \"count\": qa_bands.shape[0],\n",
    "                     \"transform\": out_transform})\n",
    "    \n",
    "    with rasterio.open(chip_fmask_dir + \"chip_\" + str(chip_id) + \"_Fmask.tif\", \"w\", **out_meta) as dest:\n",
    "        dest.write(qa_bands)  \n",
    "\n",
    "                     \n",
    "    return(valid_first,\n",
    "           valid_second,\n",
    "           valid_third, \n",
    "           bad_pct_first,\n",
    "           bad_pct_second,\n",
    "           bad_pct_third,\n",
    "           qa_first,\n",
    "           qa_second,\n",
    "           qa_third,\n",
    "           na_count,\n",
    "           first_image_date,\n",
    "           second_image_date,\n",
    "           third_image_date)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5dfd6c6-f41c-4a57-a198-f9f283ba3677",
   "metadata": {},
   "source": [
    "**Chipping process**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "0e2a2fba-44f1-4c34-b1da-f01dc65f5f86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T13TDE\n"
     ]
    }
   ],
   "source": [
    "## process chips\n",
    "\n",
    "for tile in tiles_to_chip:\n",
    "    print(tile)\n",
    "    chips_to_process = chip_df[chip_df.tile == tile.replace(\"T\", \"\")].reset_index(drop = True)\n",
    "    for k in range(len(chips_to_process)):\n",
    "        current_id = chips_to_process.chip_id[k]\n",
    "        chip_tile = chips_to_process.tile[k]\n",
    "        # print(current_id)\n",
    "        chip_index = chip_ids.index(current_id)\n",
    "\n",
    "        chip_feature = chipping_js['features'][chip_index]\n",
    "\n",
    "        shape = [chip_feature['geometry']]\n",
    "\n",
    "        ## do we want to scale/clip reflectances?\n",
    "        full_tile_name = \"T\" + chip_tile\n",
    "        valid_first, valid_second, valid_third, bad_pct_first, bad_pct_second, bad_pct_third, qa_first, qa_second, qa_third, na_count, first_image_date, second_image_date, third_image_date = process_chip(current_id, full_tile_name, shape, track_df)\n",
    "\n",
    "        chip_df_index = chip_df.index[chip_df['chip_id'] == current_id].tolist()[0]\n",
    "        chip_df.at[chip_df_index, 'valid_first'] = valid_first\n",
    "        chip_df.at[chip_df_index, 'valid_second'] = valid_second\n",
    "        chip_df.at[chip_df_index, 'valid_third'] = valid_third\n",
    "        chip_df.at[chip_df_index, 'bad_pct_first'] = bad_pct_first\n",
    "        chip_df.at[chip_df_index, 'bad_pct_second'] = bad_pct_second\n",
    "        chip_df.at[chip_df_index, 'bad_pct_third'] = bad_pct_third\n",
    "        chip_df.at[chip_df_index, 'first_image_date'] = first_image_date\n",
    "        chip_df.at[chip_df_index, 'second_image_date'] = second_image_date\n",
    "        chip_df.at[chip_df_index, 'third_image_date'] = third_image_date\n",
    "        chip_df['bad_pct_max'] = chip_df[['bad_pct_first', 'bad_pct_second', 'bad_pct_third']].max(axis=1)\n",
    "        chip_df.at[chip_df_index, 'na_count'] = na_count\n",
    "    tile_tracker = pd.read_csv(tile_tracker_csv)\n",
    "    tile_tracker.loc[tile_tracker.tile == tile , 'chip'] = True\n",
    "    tile_tracker.to_csv(tile_tracker_csv, index=False)\n",
    "    break\n",
    "chip_df.to_csv(chip_csv, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "92c193dd-4761-4c26-b440-c214fbf79a3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chip_id</th>\n",
       "      <th>chip_x</th>\n",
       "      <th>chip_y</th>\n",
       "      <th>tile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chip_184_236</td>\n",
       "      <td>-105.085494</td>\n",
       "      <td>40.081130</td>\n",
       "      <td>13TDE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chip_273_471</td>\n",
       "      <td>-87.043304</td>\n",
       "      <td>34.727874</td>\n",
       "      <td>16SDD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chip_254_259</td>\n",
       "      <td>-102.860147</td>\n",
       "      <td>36.013440</td>\n",
       "      <td>13SFV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chip_085_328</td>\n",
       "      <td>-97.925573</td>\n",
       "      <td>46.357542</td>\n",
       "      <td>14TNS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chip_056_317</td>\n",
       "      <td>-98.961892</td>\n",
       "      <td>48.102315</td>\n",
       "      <td>14UMU</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        chip_id      chip_x     chip_y   tile\n",
       "0  chip_184_236 -105.085494  40.081130  13TDE\n",
       "1  chip_273_471  -87.043304  34.727874  16SDD\n",
       "2  chip_254_259 -102.860147  36.013440  13SFV\n",
       "3  chip_085_328  -97.925573  46.357542  14TNS\n",
       "4  chip_056_317  -98.961892  48.102315  14UMU"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chip_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdfb667c-d9e4-446a-9149-3b7990e60753",
   "metadata": {},
   "source": [
    "**filter chips**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "8960db6e-d89f-4da7-a878-ff05824f4bab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=object)"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tile_tracker = pd.read_csv(tile_tracker_csv)\n",
    "tiles_to_filter = tile_tracker[(tile_tracker.exclude == False) & (tile_tracker.chip == True) & (tile_tracker.filter_chips == False) ].tile.unique()\n",
    "tiles_to_filter\n",
    "# ask Mike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "0029c420-5b71-4600-9838-c0b878835fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "chip_df = pd.read_csv(chip_csv)\n",
    "\n",
    "for tile in tiles_to_filter:\n",
    "    print(tile)\n",
    "    filtered_chips = chip_df[(chip_df.tile == tile) & (chip_df.bad_pct_max < 5) & (chip_df.na_count == 0)].chip_id.tolist()\n",
    "    print(len(filtered_chips))\n",
    "    for chip_id in filtered_chips:\n",
    "        chip_files = glob('/data/chips/*' + chip_id + '*')\n",
    "        for file in chip_files:\n",
    "            name = file.split('/')[-1]\n",
    "            shutil.copyfile(file, '/data/chips_filtered/' + name)\n",
    "        chip_files_b = glob('/data/chips_binary/*' + chip_id + '*')\n",
    "        for file in chip_files_b:\n",
    "            name = file.split('/')[-1]\n",
    "\n",
    "    \n",
    "    tile_tracker = pd.read_csv(tile_tracker_csv)\n",
    "    tile_tracker.loc[tile_tracker.tile == tile , 'filter_chips'] = True\n",
    "    tile_tracker.to_csv(tile_tracker_csv, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa07838-badb-41fc-98e1-3966e2c3ef46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
