{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "106a866f-39a2-4b20-8ba6-f5ec3d556561",
   "metadata": {},
   "outputs": [],
   "source": [
    "yoi = [2020]\n",
    "toi = ['15RTN', '15RTP', '14RNS']\n",
    "root_path = \"C:/Users/mcecil/CGA/CDL/\"\n",
    "spath = root_path + f\"CDL_HLS_dataframe{yoi[0]}.csv\"\n",
    "url_file = root_path + f'CDL_HLS_dataframe{yoi[0]}.csv'\n",
    "index_file = root_path + f'mask_index_{yoi[0]}.csv'\n",
    "kml_file = root_path + 'sentinel_tile_grid.kml'\n",
    "geojson_file = root_path + 'aoi.geojson'  ## chip file, lat-long\n",
    "geojson_rpj_file = root_path + 'aoi_rpj.geojson'\n",
    "hdf_dir = root_path + 'hdf/'\n",
    "tiff_dir = root_path + 'tif/'\n",
    "mask_dir = root_path + 'mask/'\n",
    "\n",
    "tile_src_path = root_path + \"tile_src.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "890a508e-f65d-4df7-84e9-172ba05b627d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Switch plotting backend\n",
    "import matplotlib\n",
    "matplotlib.use('agg')\n",
    "\n",
    "# Import required modules\n",
    "#import cartopy.crs as ccrs\n",
    "import os\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import geopandas\n",
    "#import pyhdf\n",
    "import rasterio\n",
    "import rasterio.mask\n",
    "import matplotlib.pyplot as pp\n",
    "import nasa_hls\n",
    "import numpy as np\n",
    "import time\n",
    "import fiona\n",
    "from pathlib import Path\n",
    "import time\n",
    "import urllib.request as urlreq\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa8f8c1-9dc4-4f23-ace8-e0d66a590474",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebe70bd-0292-4732-b791-63848284189c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6b3f202f-e825-493a-b9a3-504867970f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize df for storing QA info\n",
    "chip_image_df = pd.DataFrame(columns = ['chip_id', 'tile', 'minx', 'miny', 'maxx', 'maxy', 'image_id', 'date', 'month', 'ncell', 'QA_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f880d9ec-28dc-4ff1-8a8b-9e6fef8cd4b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7855ba-133d-45d6-be29-1c06e1483642",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "94492d6e-242f-49aa-a8a8-ca1ccbbb3ced",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Description</th>\n",
       "      <th>geometry</th>\n",
       "      <th>minx</th>\n",
       "      <th>miny</th>\n",
       "      <th>maxx</th>\n",
       "      <th>maxy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01CCV</td>\n",
       "      <td>TILE PROPERTIES&lt;br&gt;&lt;table border=0 cellpadding...</td>\n",
       "      <td>GEOMETRYCOLLECTION Z (POLYGON Z ((180.00000 -7...</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-73.064633</td>\n",
       "      <td>180.0</td>\n",
       "      <td>-72.012478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01CDH</td>\n",
       "      <td>TILE PROPERTIES&lt;br&gt;&lt;table border=0 cellpadding...</td>\n",
       "      <td>GEOMETRYCOLLECTION Z (POLYGON Z ((180.00000 -8...</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-83.835334</td>\n",
       "      <td>180.0</td>\n",
       "      <td>-82.796720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01CDJ</td>\n",
       "      <td>TILE PROPERTIES&lt;br&gt;&lt;table border=0 cellpadding...</td>\n",
       "      <td>GEOMETRYCOLLECTION Z (POLYGON Z ((180.00000 -8...</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-82.939452</td>\n",
       "      <td>180.0</td>\n",
       "      <td>-81.906947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01CDK</td>\n",
       "      <td>TILE PROPERTIES&lt;br&gt;&lt;table border=0 cellpadding...</td>\n",
       "      <td>GEOMETRYCOLLECTION Z (POLYGON Z ((180.00000 -8...</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-82.044055</td>\n",
       "      <td>180.0</td>\n",
       "      <td>-81.016439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01CDL</td>\n",
       "      <td>TILE PROPERTIES&lt;br&gt;&lt;table border=0 cellpadding...</td>\n",
       "      <td>GEOMETRYCOLLECTION Z (POLYGON Z ((180.00000 -8...</td>\n",
       "      <td>-180.0</td>\n",
       "      <td>-81.148070</td>\n",
       "      <td>180.0</td>\n",
       "      <td>-80.124456</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Name                                        Description   \n",
       "0  01CCV  TILE PROPERTIES<br><table border=0 cellpadding...  \\\n",
       "1  01CDH  TILE PROPERTIES<br><table border=0 cellpadding...   \n",
       "2  01CDJ  TILE PROPERTIES<br><table border=0 cellpadding...   \n",
       "3  01CDK  TILE PROPERTIES<br><table border=0 cellpadding...   \n",
       "4  01CDL  TILE PROPERTIES<br><table border=0 cellpadding...   \n",
       "\n",
       "                                            geometry   minx       miny   maxx   \n",
       "0  GEOMETRYCOLLECTION Z (POLYGON Z ((180.00000 -7... -180.0 -73.064633  180.0  \\\n",
       "1  GEOMETRYCOLLECTION Z (POLYGON Z ((180.00000 -8... -180.0 -83.835334  180.0   \n",
       "2  GEOMETRYCOLLECTION Z (POLYGON Z ((180.00000 -8... -180.0 -82.939452  180.0   \n",
       "3  GEOMETRYCOLLECTION Z (POLYGON Z ((180.00000 -8... -180.0 -82.044055  180.0   \n",
       "4  GEOMETRYCOLLECTION Z (POLYGON Z ((180.00000 -8... -180.0 -81.148070  180.0   \n",
       "\n",
       "        maxy  \n",
       "0 -72.012478  \n",
       "1 -82.796720  \n",
       "2 -81.906947  \n",
       "3 -81.016439  \n",
       "4 -80.124456  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the HLS tiles and place there coordinates into a numpy array for processing later\n",
    "fiona.drvsupport.supported_drivers['KML'] = 'rw'\n",
    "tile_src = geopandas.read_file(kml_file, driver='KML')\n",
    "tile_name = []\n",
    "tile_x = []\n",
    "tile_y = []\n",
    "for tile_ind in range(tile_src.shape[0]):\n",
    "    tile_name.append(tile_src.iloc[tile_ind].Name)\n",
    "    tile_x.append(tile_src.iloc[tile_ind].geometry.centroid.x)\n",
    "    tile_y.append(tile_src.iloc[tile_ind].geometry.centroid.y)\n",
    "tile_name = np.array(tile_name)\n",
    "tile_x = np.array(tile_x)\n",
    "tile_y = np.array(tile_y)\n",
    "tile_src = pd.concat([tile_src, tile_src.bounds], axis = 1)\n",
    "#del tile_src\n",
    "tile_src.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ae1ee1ab-d276-4bd8-ad3d-fe29d7182664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the HLS query csv for this year\n",
    "qfn = open(url_file)\n",
    "qtile = []\n",
    "qyear = []\n",
    "qmonth = []\n",
    "qday = []\n",
    "qdate = []\n",
    "qurl = []\n",
    "for i, line in enumerate(qfn):\n",
    "    if (i == 0): # Skip header\n",
    "        continue\n",
    "    dummy = line.split(\",\")\n",
    "    qtile.append(dummy[2])\n",
    "    qdate.append(dummy[3])\n",
    "    qurl.append(dummy[4])\n",
    "    \n",
    "    qday.append(int(dummy[3].split(\"-\")[2]))\n",
    "    qmonth.append(int(dummy[3].split(\"-\")[1]))\n",
    "    qyear.append(int(dummy[3].split(\"-\")[0]))\n",
    "qfn.close()\n",
    "qdate = np.array(qdate)\n",
    "qtile = np.array(qtile)\n",
    "qurl = np.array(qurl)\n",
    "qmonth = np.array(qmonth)\n",
    "qyear = np.array(qyear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "db83c256-6c7b-4f86-86e0-afcbe0c1e1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the index file\n",
    "# fn_index = open(index_file, \"w\")\n",
    "# fn_index.write('EventID,Name,FireDate,MaskDate,BurnAcres,Tile,MaskFile')\n",
    "# fn_index.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ecd3a8f-73b7-400c-a0ae-0cff713066d3",
   "metadata": {},
   "source": [
    "Load geojson used for query. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f600d0ca-467b-4ec2-a8f3-8f4b76434d6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mcecil\\AppData\\Local\\Temp\\ipykernel_5544\\513036168.py:4: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  aoi_src['centroid_x'] = aoi_src.centroid.x\n",
      "C:\\Users\\mcecil\\AppData\\Local\\Temp\\ipykernel_5544\\513036168.py:5: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  aoi_src['centroid_y'] = aoi_src.centroid.y\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geometry</th>\n",
       "      <th>minx</th>\n",
       "      <th>miny</th>\n",
       "      <th>maxx</th>\n",
       "      <th>maxy</th>\n",
       "      <th>centroid_x</th>\n",
       "      <th>centroid_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>POLYGON ((-98.46590 28.48216, -98.46590 28.491...</td>\n",
       "      <td>-98.492844</td>\n",
       "      <td>28.482162</td>\n",
       "      <td>-98.465904</td>\n",
       "      <td>28.491892</td>\n",
       "      <td>-98.479374</td>\n",
       "      <td>28.487027</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            geometry       minx       miny   \n",
       "0  POLYGON ((-98.46590 28.48216, -98.46590 28.491... -98.492844  28.482162  \\\n",
       "\n",
       "        maxx       maxy  centroid_x  centroid_y  \n",
       "0 -98.465904  28.491892  -98.479374   28.487027  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aoi_src = geopandas.read_file(geojson_file) ## this could be a list\n",
    "nfeatures = aoi_src.shape[0]\n",
    "aoi_src = pd.concat([aoi_src, aoi_src.bounds], axis = 1)\n",
    "aoi_src['centroid_x'] = aoi_src.centroid.x\n",
    "aoi_src['centroid_y'] = aoi_src.centroid.y\n",
    "aoi_src.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0319bc23-2006-4d35-b46e-d6d037a70f76",
   "metadata": {},
   "source": [
    "Loop through aoi_src (chips), associate closest tile, add ID field, download hdf (WORKING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81f4f7d-d6b9-46b9-a4a5-f58f16b9700f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for aoi_ind in range(nfeatures):\n",
    "    aoi_row = aoi_src.iloc[aoi_ind]\n",
    "    print(aoi_row)\n",
    "    print(aoi_src.bounds)\n",
    "    aoi_x = float(aoi_row.centroid_x)\n",
    "    aoi_y = float(aoi_row.centroid_y)\n",
    "        \n",
    "    # Identify what tile the burn scar is in\n",
    "    s = (tile_x-aoi_x)**2+(tile_y-aoi_y)**2\n",
    "    tname = tile_name[np.argmin(s)]\n",
    "    print(s)\n",
    "    print(tname)\n",
    "    aoi_src.at[aoi_ind, 'tile'] = tname\n",
    "    aoi_src.at[aoi_ind, 'chip_id'] = 'chip_' + str(aoi_ind)\n",
    "    \n",
    "    \n",
    "    # Subset potential images based on tile and date\n",
    "    tile_mask = qtile == tname\n",
    "    # Subset based on date\n",
    "    date_mask1 = (qyear == yoi[0])\n",
    "  #  diff = (qmonth-aoi_month)%12\n",
    "   # date_mask2 = ((diff <= month_threshold[1]) & (diff >= month_threshold[0]))\n",
    "    date_mask = date_mask1  #& date_mask2\n",
    "    \n",
    "    mask = tile_mask & date_mask\n",
    "    candidate_dates = qdate[mask]\n",
    "    candidate_tiles = qtile[mask]\n",
    "    candidate_urls = qurl[mask]\n",
    "    # Loop through images and check cloud cover\n",
    "    for cd, ct, cu in zip(candidate_dates, candidate_tiles, candidate_urls):     \n",
    "        local_name = cu.split('/')[-1].replace(\"\\n\", \"\")\n",
    "        # Download a candidate file to check cloud cover\n",
    "        try:\n",
    "            urlreq.urlretrieve(cu, filename=hdf_dir+local_name)\n",
    "        except:\n",
    "            continue\n",
    "#aoi_src.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104f3200-7d45-4911-91ea-527a67e56f27",
   "metadata": {},
   "source": [
    "Extract cloud cover and spatial coverage from metadata (NOT WORKING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4fa0074-2fca-42f6-8ed3-545a8e05e3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for aoi_ind in range(nfeatures):\n",
    "    aoi_row = aoi_src.iloc[aoi_ind]\n",
    "    print(aoi_row)\n",
    "    print(aoi_src.bounds)\n",
    "    aoi_x = float(aoi_row.centroid_x)\n",
    "    aoi_y = float(aoi_row.centroid_y)\n",
    "        \n",
    "    # Identify what tile the burn scar is in\n",
    "    s = (tile_x-aoi_x)**2+(tile_y-aoi_y)**2\n",
    "    tname = tile_name[np.argmin(s)]\n",
    "    print(s)\n",
    "    print(tname)\n",
    "    aoi_src.at[aoi_ind, 'tile'] = tname\n",
    "    aoi_src.at[aoi_ind, 'chip_id'] = 'chip_' + str(aoi_ind)\n",
    "    \n",
    "    # Subset potential images based on tile and date\n",
    "    tile_mask = qtile == tname\n",
    "    # Subset based on date\n",
    "    date_mask1 = (qyear == yoi[0])\n",
    "  #  diff = (qmonth-aoi_month)%12\n",
    "   # date_mask2 = ((diff <= month_threshold[1]) & (diff >= month_threshold[0]))\n",
    "    date_mask = date_mask1  #& date_mask2\n",
    "    \n",
    "    mask = tile_mask & date_mask\n",
    "    candidate_dates = qdate[mask]\n",
    "    candidate_tiles = qtile[mask]\n",
    "    candidate_urls = qurl[mask]\n",
    "    # Loop through images and check cloud cover\n",
    "    for cd, ct, cu in zip(candidate_dates, candidate_tiles, candidate_urls):\n",
    "       # print(cu)\n",
    "        local_name = cu.split('/')[-1].replace(\"\\n\", \"\")\n",
    "        \n",
    "        if local_name != \"HLS.S30.T14RNS.2020117.v1.4.hdf\":\n",
    "            continue\n",
    "        # Download a candidate file to check cloud cover\n",
    "        try:\n",
    "            md = nasa_hls.get_metadata_from_hdf(hdf_dir+local_name, fields=['cloud_cover', 'spatial_coverage'])\n",
    "            print(md)\n",
    "       #     if ((md[\"cloud_cover\"] < cldfrac_threshold) and (md['spatial_coverage'] > spacecov_threshold)):\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "aoi_src.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8e2252-4cf9-44ea-bb3c-84628f7d1f10",
   "metadata": {},
   "source": [
    "Convert HDF to single-layer TIF (Using HLS library, DOES NOT WORK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9654ff4a-7955-4dbe-9978-8b6f61ac5d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for aoi_ind in range(nfeatures):\n",
    "    aoi_row = aoi_src.iloc[aoi_ind]\n",
    "    print(aoi_row)\n",
    "    print(aoi_src.bounds)\n",
    "    aoi_x = float(aoi_row.centroid_x)\n",
    "    aoi_y = float(aoi_row.centroid_y)\n",
    "        \n",
    "    # Identify what tile the burn scar is in\n",
    "    s = (tile_x-aoi_x)**2+(tile_y-aoi_y)**2\n",
    "    tname = tile_name[np.argmin(s)]\n",
    "    print(s)\n",
    "    print(tname)\n",
    "    aoi_src.at[aoi_ind, 'tile'] = tname\n",
    "    aoi_src.at[aoi_ind, 'chip_id'] = 'chip_' + str(aoi_ind)\n",
    "    \n",
    "    # Subset potential images based on tile and date\n",
    "    tile_mask = qtile == tname\n",
    "    # Subset based on date\n",
    "    date_mask1 = (qyear == yoi[0])\n",
    "  #  diff = (qmonth-aoi_month)%12\n",
    "   # date_mask2 = ((diff <= month_threshold[1]) & (diff >= month_threshold[0]))\n",
    "    date_mask = date_mask1  #& date_mask2\n",
    "    \n",
    "    mask = tile_mask & date_mask\n",
    "    candidate_dates = qdate[mask]\n",
    "    candidate_tiles = qtile[mask]\n",
    "    candidate_urls = qurl[mask]\n",
    "    # Loop through images and check cloud cover\n",
    "    for cd, ct, cu in zip(candidate_dates, candidate_tiles, candidate_urls):\n",
    "        print(cu)\n",
    "        local_name = cu.split('/')[-1].replace(\"\\n\", \"\")\n",
    "        \n",
    "        if local_name != \"HLS.S30.T14RNS.2020117.v1.4.hdf\":\n",
    "            continue\n",
    "        \n",
    "        nasa_hls.convert_hdf2tiffs(Path(hdf_dir+local_name), Path(tiff_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26661253-3d2e-4441-83f4-7f60c19838b9",
   "metadata": {},
   "source": [
    "Convert HDF to single-layer TIF (Mike's way - works)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177418f1-9c60-493d-9f88-106c992964d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import osgeo\n",
    "from osgeo import gdal\n",
    "import glob\n",
    "from subprocess import Popen, PIPE\n",
    "\n",
    "bands = ['B01', 'B02', 'B03', 'B04', 'B05', 'B06', 'B07', 'B08', 'B8A', 'B09', 'B10', 'B11', 'B12', 'QA']\n",
    "\n",
    "\n",
    "hdf_files = glob.glob(hdf_dir + \"*.hdf\")\n",
    "for hdf_file in hdf_files:\n",
    "    print(hdf_file)\n",
    "    file_name = hdf_file.split('\\\\')[-1].replace('.hdf', '')\n",
    "    if file_name != \"HLS.S30.T14RNS.2020117.v1.4\":\n",
    "        continue\n",
    "    print('valid')\n",
    "    for long_band_name in bands:\n",
    "        cmd = f'gdal_translate HDF4_EOS:EOS_GRID:\"' + hdf_file + '\":Grid:' + long_band_name + ' ' + tiff_dir + file_name + '__' + long_band_name + '.tif'\n",
    "      #  print(cmd)\n",
    "        p = Popen(cmd, stdout=PIPE, shell=True)\n",
    "       # print(p)\n",
    "        output, err = p.communicate()\n",
    "        #print(output)\n",
    "        #print(err)\n",
    "  #  nasa_hls.convert_hdf2tif_dirfs(Path(hdf_file), Path(tif_dir_dir))\n",
    "    # ds = gdal.Open(hdf_file)\n",
    "    # ds_t = gdal.Translate('output.tif', hdf_file)\n",
    "#ds = None\n",
    "#print(ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64161c5c-c37c-4237-9f99-2bd726c43491",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de35d55-f75d-48eb-be26-03fcb4b4bfa9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1d7e6012-7614-415a-bd87-b94e7b705f6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "geometry      POLYGON ((-98.46590447567304 28.48216163356960...\n",
      "minx                                                 -98.492844\n",
      "miny                                                  28.482162\n",
      "maxx                                                 -98.465904\n",
      "maxy                                                  28.491892\n",
      "centroid_x                                           -98.479374\n",
      "centroid_y                                            28.487027\n",
      "tile                                                      14RNS\n",
      "chip_id                                                  chip_0\n",
      "Name: 0, dtype: object\n",
      "        minx       miny       maxx       maxy\n",
      "0 -98.492844  28.482162 -98.465904  28.491892\n",
      "[69873.57854445 26546.24690202 22692.05707804 ... 15908.73972509\n",
      " 12442.80659328  9532.39628432]\n",
      "14RNS\n",
      "HLS.S30.T14RNS.2020002.v1.4.hdf\n",
      "HLS.S30.T14RNS.2020005.v1.4.hdf\n",
      "HLS.S30.T14RNS.2020007.v1.4.hdf\n",
      "HLS.S30.T14RNS.2020010.v1.4.hdf\n",
      "HLS.S30.T14RNS.2020012.v1.4.hdf\n",
      "HLS.S30.T14RNS.2020015.v1.4.hdf\n",
      "HLS.S30.T14RNS.2020017.v1.4.hdf\n",
      "HLS.S30.T14RNS.2020020.v1.4.hdf\n",
      "HLS.S30.T14RNS.2020022.v1.4.hdf\n",
      "HLS.S30.T14RNS.2020027.v1.4.hdf\n",
      "HLS.S30.T14RNS.2020032.v1.4.hdf\n",
      "HLS.S30.T14RNS.2020035.v1.4.hdf\n",
      "HLS.S30.T14RNS.2020040.v1.4.hdf\n",
      "HLS.S30.T14RNS.2020042.v1.4.hdf\n",
      "HLS.S30.T14RNS.2020045.v1.4.hdf\n",
      "HLS.S30.T14RNS.2020047.v1.4.hdf\n",
      "HLS.S30.T14RNS.2020052.v1.4.hdf\n",
      "HLS.S30.T14RNS.2020057.v1.4.hdf\n",
      "HLS.S30.T14RNS.2020060.v1.4.hdf\n",
      "HLS.S30.T14RNS.2020062.v1.4.hdf\n",
      "HLS.S30.T14RNS.2020065.v1.4.hdf\n",
      "HLS.S30.T14RNS.2020067.v1.4.hdf\n",
      "HLS.S30.T14RNS.2020070.v1.4.hdf\n",
      "HLS.S30.T14RNS.2020072.v1.4.hdf\n",
      "HLS.S30.T14RNS.2020075.v1.4.hdf\n",
      "HLS.S30.T14RNS.2020077.v1.4.hdf\n",
      "HLS.S30.T14RNS.2020080.v1.4.hdf\n",
      "HLS.S30.T14RNS.2020082.v1.4.hdf\n",
      "HLS.S30.T14RNS.2020085.v1.4.hdf\n",
      "HLS.S30.T14RNS.2020087.v1.4.hdf\n",
      "HLS.S30.T14RNS.2020092.v1.4.hdf\n",
      "HLS.S30.T14RNS.2020097.v1.4.hdf\n",
      "HLS.S30.T14RNS.2020100.v1.4.hdf\n",
      "HLS.S30.T14RNS.2020102.v1.4.hdf\n",
      "HLS.S30.T14RNS.2020107.v1.4.hdf\n",
      "HLS.S30.T14RNS.2020110.v1.4.hdf\n",
      "HLS.S30.T14RNS.2020112.v1.4.hdf\n",
      "HLS.S30.T14RNS.2020115.v1.4.hdf\n",
      "HLS.S30.T14RNS.2020117.v1.4.hdf\n",
      "HLS.S30.T14RNS.2020120.v1.4.hdf\n",
      "HLS.S30.T14RNS.2020122.v1.4.hdf\n",
      "HLS.S30.T14RNS.2020125.v1.4.hdf\n",
      "HLS.S30.T14RNS.2020127.v1.4.hdf\n",
      "HLS.S30.T14RNS.2020130.v1.4.hdf\n",
      "HLS.S30.T14RNS.2020132.v1.4.hdf\n",
      "HLS.S30.T14RNS.2020135.v1.4.hdf\n",
      "HLS.S30.T14RNS.2020137.v1.4.hdf\n",
      "HLS.S30.T14RNS.2020140.v1.4.hdf\n",
      "HLS.S30.T14RNS.2020142.v1.4.hdf\n",
      "HLS.S30.T14RNS.2020145.v1.4.hdf\n",
      "HLS.S30.T14RNS.2020147.v1.4.hdf\n",
      "HLS.S30.T14RNS.2020150.v1.4.hdf\n",
      "HLS.S30.T14RNS.2020152.v1.4.hdf\n",
      "HLS.S30.T14RNS.2020155.v1.4.hdf\n",
      "HLS.S30.T14RNS.2020157.v1.4.hdf\n",
      "HLS.S30.T14RNS.2020160.v1.4.hdf\n",
      "HLS.S30.T14RNS.2020162.v1.4.hdf\n",
      "HLS.S30.T14RNS.2020165.v1.4.hdf\n",
      "HLS.S30.T14RNS.2020167.v1.4.hdf\n",
      "HLS.S30.T14RNS.2020170.v1.4.hdf\n",
      "HLS.S30.T14RNS.2020172.v1.4.hdf\n",
      "HLS.S30.T14RNS.2020175.v1.4.hdf\n",
      "HLS.S30.T14RNS.2020177.v1.4.hdf\n",
      "HLS.S30.T14RNS.2020180.v1.4.hdf\n",
      "HLS.S30.T14RNS.2020182.v1.4.hdf\n",
      "HLS.S30.T14RNS.2020185.v1.4.hdf\n",
      "HLS.S30.T14RNS.2020187.v1.4.hdf\n",
      "HLS.S30.T14RNS.2020190.v1.4.hdf\n",
      "HLS.S30.T14RNS.2020192.v1.4.hdf\n",
      "HLS.S30.T14RNS.2020195.v1.4.hdf\n",
      "HLS.S30.T14RNS.2020197.v1.4.hdf\n",
      "HLS.S30.T14RNS.2020200.v1.4.hdf\n",
      "HLS.S30.T14RNS.2020202.v1.4.hdf\n",
      "HLS.S30.T14RNS.2020205.v1.4.hdf\n",
      "HLS.S30.T14RNS.2020207.v1.4.hdf\n",
      "HLS.S30.T14RNS.2020210.v1.4.hdf\n",
      "HLS.S30.T14RNS.2020212.v1.4.hdf\n",
      "HLS.S30.T14RNS.2020215.v1.4.hdf\n",
      "HLS.S30.T14RNS.2020217.v1.4.hdf\n",
      "HLS.S30.T14RNS.2020220.v1.4.hdf\n",
      "HLS.S30.T14RNS.2020222.v1.4.hdf\n",
      "HLS.S30.T14RNS.2020225.v1.4.hdf\n",
      "HLS.S30.T14RNS.2020227.v1.4.hdf\n",
      "HLS.S30.T14RNS.2020230.v1.4.hdf\n",
      "HLS.S30.T14RNS.2020232.v1.4.hdf\n",
      "HLS.S30.T14RNS.2020235.v1.4.hdf\n",
      "HLS.S30.T14RNS.2020237.v1.4.hdf\n",
      "HLS.S30.T14RNS.2020240.v1.4.hdf\n",
      "HLS.S30.T14RNS.2020242.v1.4.hdf\n",
      "HLS.S30.T14RNS.2020245.v1.4.hdf\n",
      "HLS.S30.T14RNS.2020247.v1.4.hdf\n",
      "HLS.S30.T14RNS.2020250.v1.4.hdf\n",
      "HLS.S30.T14RNS.2020252.v1.4.hdf\n",
      "HLS.S30.T14RNS.2020255.v1.4.hdf\n",
      "HLS.S30.T14RNS.2020257.v1.4.hdf\n",
      "HLS.S30.T14RNS.2020267.v1.4.hdf\n",
      "HLS.S30.T14RNS.2020270.v1.4.hdf\n",
      "HLS.S30.T14RNS.2020272.v1.4.hdf\n",
      "HLS.S30.T14RNS.2020275.v1.4.hdf\n",
      "HLS.S30.T14RNS.2020277.v1.4.hdf\n",
      "HLS.S30.T14RNS.2020280.v1.4.hdf\n",
      "HLS.S30.T14RNS.2020282.v1.4.hdf\n",
      "HLS.S30.T14RNS.2020285.v1.4.hdf\n",
      "HLS.S30.T14RNS.2020287.v1.4.hdf\n",
      "HLS.S30.T14RNS.2020290.v1.4.hdf\n",
      "HLS.S30.T14RNS.2020292.v1.4.hdf\n",
      "HLS.S30.T14RNS.2020295.v1.4.hdf\n",
      "HLS.S30.T14RNS.2020297.v1.4.hdf\n",
      "HLS.S30.T14RNS.2020300.v1.4.hdf\n",
      "HLS.S30.T14RNS.2020302.v1.4.hdf\n",
      "HLS.S30.T14RNS.2020305.v1.4.hdf\n",
      "HLS.S30.T14RNS.2020307.v1.4.hdf\n",
      "HLS.S30.T14RNS.2020310.v1.4.hdf\n",
      "HLS.S30.T14RNS.2020312.v1.4.hdf\n",
      "HLS.S30.T14RNS.2020317.v1.4.hdf\n",
      "HLS.S30.T14RNS.2020320.v1.4.hdf\n",
      "HLS.S30.T14RNS.2020322.v1.4.hdf\n",
      "HLS.S30.T14RNS.2020325.v1.4.hdf\n",
      "HLS.S30.T14RNS.2020327.v1.4.hdf\n",
      "HLS.S30.T14RNS.2020330.v1.4.hdf\n",
      "HLS.S30.T14RNS.2020332.v1.4.hdf\n",
      "HLS.S30.T14RNS.2020335.v1.4.hdf\n",
      "HLS.S30.T14RNS.2020337.v1.4.hdf\n",
      "HLS.S30.T14RNS.2020342.v1.4.hdf\n",
      "HLS.S30.T14RNS.2020345.v1.4.hdf\n",
      "valid\n",
      "<open DatasetReader name='C:/Users/mcecil/CGA/CDL/tif/HLS.S30.T14RNS.2020345.v1.4__B04.tif' mode='r'>\n",
      "[[ 1933  1573   729 ...  1308  1260  1211]\n",
      " [ 1172   984   919 ...  1323  1199  1250]\n",
      " [  659   652   755 ...  1243  1226  1211]\n",
      " ...\n",
      " [  769   599   571 ... -1000 -1000 -1000]\n",
      " [  791   632   572 ... -1000 -1000 -1000]\n",
      " [ 1109  1133  1107 ... -1000 -1000 -1000]]\n",
      "<open DatasetReader name='C:/Users/mcecil/CGA/CDL/tif/HLS.S30.T14RNS.2020345.v1.4__QA.tif' mode='r'>\n",
      "[[194 194 130 ... 130 130 130]\n",
      " [130 130 130 ... 130 130 130]\n",
      " [192 192 128 ... 130 130 130]\n",
      " ...\n",
      " [192  64  64 ... 255 255 255]\n",
      " [192  64  64 ... 255 255 255]\n",
      " [192  64  64 ... 255 255 255]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mcecil\\AppData\\Local\\Temp\\ipykernel_5544\\1435243893.py:73: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ndvi = np.clip((nir-red)/(nir+red), 0, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "geometry      POLYGON ((552278.43611174 3150731.966929977, 5...\n",
      "minx                                                 -98.492844\n",
      "miny                                                  28.482162\n",
      "maxx                                                 -98.465904\n",
      "maxy                                                  28.491892\n",
      "centroid_x                                           -98.479374\n",
      "centroid_y                                            28.487027\n",
      "tile                                                      14RNS\n",
      "chip_id                                                  chip_0\n",
      "Name: 0, dtype: object\n",
      "-1000 2601\n",
      "0 1\n"
     ]
    }
   ],
   "source": [
    "for aoi_ind in range(nfeatures):\n",
    "    aoi_row = aoi_src.iloc[aoi_ind]\n",
    "    print(aoi_row)\n",
    "    print(aoi_src.bounds)\n",
    "    aoi_x = float(aoi_row.centroid_x)\n",
    "    aoi_y = float(aoi_row.centroid_y)\n",
    "        \n",
    "    # Identify what tile the burn scar is in\n",
    "    s = (tile_x-aoi_x)**2+(tile_y-aoi_y)**2\n",
    "    tname = tile_name[np.argmin(s)]\n",
    "    print(s)\n",
    "    print(tname)\n",
    "    aoi_src.at[aoi_ind, 'tile'] = tname\n",
    "    aoi_src.at[aoi_ind, 'chip_id'] = 'chip_' + str(aoi_ind)\n",
    "    \n",
    "    # Subset potential images based on tile and date\n",
    "    tile_mask = qtile == tname\n",
    "    # Subset based on date\n",
    "    date_mask1 = (qyear == yoi[0])\n",
    "  #  diff = (qmonth-aoi_month)%12\n",
    "   # date_mask2 = ((diff <= month_threshold[1]) & (diff >= month_threshold[0]))\n",
    "    date_mask = date_mask1  #& date_mask2\n",
    "    \n",
    "    mask = tile_mask & date_mask\n",
    "    candidate_dates = qdate[mask]\n",
    "    candidate_tiles = qtile[mask]\n",
    "    candidate_urls = qurl[mask]\n",
    "    # Loop through images and check cloud cover\n",
    "    for cd, ct, cu in zip(candidate_dates, candidate_tiles, candidate_urls):\n",
    "       # print(cu)\n",
    "        local_name = cu.split('/')[-1].replace(\"\\n\", \"\")\n",
    "        print(local_name)\n",
    "        if local_name != \"HLS.S30.T14RNS.2020345.v1.4.hdf\":\n",
    "            continue\n",
    "        print('valid')\n",
    "        # Download a candidate file to check cloud cover\n",
    "        # try:\n",
    "        #     urlreq.urlretrieve(cu, filename=hdf_dir+local_name)\n",
    "        # except:\n",
    "        #     continue\n",
    "    \n",
    "        # Check cloud cover and spacial coverage\n",
    "      #  try:\n",
    "            # md = nasa_hls.get_metadata_from_hdf(hdf_dir+local_name, fields=['cloud_cover', 'spatial_coverage'])\n",
    "            # if ((md[\"cloud_cover\"] < cldfrac_threshold) and (md['spatial_coverage'] > spacecov_threshold)):\n",
    "            \n",
    "                # Convert to a geotiff            \n",
    "                # nasa_hls.convert_hdf2tiffs(Path(hdf_dir+local_name), Path(tiff_dir))\n",
    "\n",
    "            # Open the new geotiff\n",
    "        date = datetime.strptime(cd, '%Y-%m-%d')\n",
    "        doy = (date-datetime(date.year, 1, 1)).days+1\n",
    "        fp = f'HLS.S30.T{ct}.{date.year}{doy:03d}.v1.4'\n",
    "        src = rasterio.open(f'{tiff_dir}/{fp}__B04.tif')\n",
    "        red = src.read(1)\n",
    "        print(src)\n",
    "        print(red)\n",
    "\n",
    "        # Open NIR too to compute NDVI\n",
    "        nir_src = rasterio.open(f'{tiff_dir}/{fp}__B08.tif')\n",
    "        nir = nir_src.read(1)\n",
    "\n",
    "        \n",
    "        qa_src = rasterio.open(f'{tiff_dir}/{fp}__QA.tif')\n",
    "        qa = qa_src.read(1)\n",
    "        \n",
    "        print(qa_src)\n",
    "        print(qa)\n",
    "        \n",
    "        # Compute NDVI\n",
    "        red = np.clip(red/15000, 0, 1)\n",
    "        nir = np.clip(nir/15000, 0, 1)\n",
    "        ndvi = np.clip((nir-red)/(nir+red), 0, 1)\n",
    "\n",
    "        # Convert burn scar shape to proper geometry\n",
    "        aoi_shape = aoi_src.to_crs(src.crs).iloc[aoi_ind]\n",
    "\n",
    "        print(aoi_shape)\n",
    "        # Build the mask\n",
    "        out_image, out_transform = rasterio.mask.mask(src, [aoi_shape.geometry], crop=False)\n",
    "        print(np.min(out_image), np.max(out_image))\n",
    "        out_image = np.clip(out_image, 0, 1)\n",
    "        print(np.min(out_image), np.max(out_image))\n",
    "\n",
    "        out_meta = src.meta\n",
    "        out_meta.update({'driver':'GTiff', 'height':out_image.shape[1],\n",
    "            'width':out_image.shape[2], 'transform':out_transform})\n",
    "\n",
    "        with rasterio.open(f'{mask_dir}/{fp}.mask.tif', 'w', **out_meta) as dest:\n",
    "            dest.write(out_image)\n",
    "\n",
    "        # Plot the original and mask\n",
    "        fig, [ax1, ax2] = pp.subplots(ncols=2)\n",
    "        ax1.imshow(ndvi, cmap='YlGn', vmin=0, vmax=1)\n",
    "        ax2.imshow(np.squeeze(out_image), cmap='Greys')\n",
    "        pp.savefig(f'{mask_dir}/{fp}.mask.jpg')\n",
    "        pp.close()\n",
    "\n",
    "        # Save in index file\n",
    "#         fn_index = open(index_file, 'a')\n",
    "#         fn_index.write(f'\\n{aoi_row.Event_ID},{aoi_row.Incid_Name},{aoi_row.Ig_Date},{cd},{aoi_row.BurnBndAc},{ct},{fp}.mask.tif')\n",
    "#         fn_index.close()\n",
    "\n",
    "#         # Move onto the next burn scar\n",
    "#         del src\n",
    "#         del nir_src\n",
    "        break\n",
    "        # except:\n",
    "        #     print('error')\n",
    "        #     continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a930625-f857-4d47-b84a-a5d4d693f093",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419bfa3f-7682-426c-95a2-b8acb2301c20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
